---
title: Оценка моделей Python в режиме реального времени
titleSuffix: Azure Reference Architectures
description: Эта эталонная архитектура демонстрирует, как развернуть модель Python в качестве веб-службы в Azure для прогнозирования в реальном времени.
author: msalvaris
ms.date: 01/28/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: ba2d9a295e5a231f0ffca9e3cf2d53ace4deddfe
ms.sourcegitcommit: 1ee873aaf40010eb2a38314ac56974bc9e227736
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/28/2019
ms.locfileid: "55141032"
---
# <a name="real-time-scoring-of-python-scikit-learn-and-deep-learning-models-on-azure"></a>Оценка в реальном времени моделей Python scikit-learn и глубокого обучения в Azure

Эта эталонная архитектура демонстрирует, как развернуть модель Python в качестве веб-службы в Azure для прогнозирования в реальном времени с помощью Службы машинного обучения Azure. Рассматриваются два сценария: развертывание обычных моделей Python и развертывание моделей глубокого обучения с определенными требованиями. Оба сценария используют показанную на рисунке архитектуру.

Два примера реализации этой архитектуры можно найти на сайте GitHub: один для [обычных моделей Python][github-python] и один для [моделей глубокого обучения][github-dl].

![Схема архитектуры для оценки моделей Python в Azure в реальном времени](./_images/python-model-architecture.png)

## <a name="scenarios"></a>Сценарии

Примеры реализации демонстрируют два сценария использования этой архитектуры.

**Сценарий 1: сопоставление часто задаваемых вопросов**. Этот сценарий демонстрирует, как развернуть модель сопоставления часто задаваемых вопросов в качестве веб-службы для прогнозирования вопросов пользователей. В этом сценарии входными данными на схеме архитектуры служат текстовые строки, содержащие вопросы пользователей, сопоставляемые со списком часто задаваемых вопросов. В этом сценарии используется библиотека машинного обучения [scikit-learn][scikit] для Python, но также поддерживаются любые сценарии работы с моделями Python для прогнозирования в реальном времени.

В этом сценарии используется набор данных вопросов Stack Overflow , которые содержат исходные вопросы, помеченные тегами JavaScript, дублирующиеся вопросы и ответы на них. В сценарии конвейер scikit-learn обучается прогнозировать возможность соответствия дублирующихся и исходных вопросов. Прогнозирование осуществляется в реальном времени с использованием конечной точки REST API.

Архитектура предполагает такой алгоритм работы:

1. Обученная модель регистрируется в реестре моделей Машинного обучения.
2. Служба машинного обучения создает образ Docker, в который входят модель и скрипт оценки.
3. Решение "Машинное обучение" развертывает образ оценки в службе контейнеров Azure (AKS) в качестве веб-службы.
4. Клиент отправляет запрос HTTP POST с закодированными данными вопроса.
5. Веб-служба, созданная решением "Машинное обучение", извлекает из запроса вопрос.
6. Этот вопрос направляется в модель конвейера Scikit-learn для извлечения признаков и оценки. 
7. Затем клиенту возвращаются соответствующие вопросы и оценки из списка часто задаваемых вопросов.

Ниже приведен пример приложения, использующего полученные результаты:

![Снимок экрана с примером приложения](./_images/python-faq-matches.png)

**Сценарий 2: классификация изображений.** Этот сценарий демонстрирует развертывание модели сверточной нейронной сети (CNN) в качестве веб-службы для прогнозной обработки изображений. В этом сценарии входными данными на схеме архитектуры служат файлы изображений. Сети CNN весьма эффективны для выполнения таких задач компьютерного зрения, как классификация изображений и обнаружение объектов. В этом сценарии используются платформы TensorFlow, Keras (с серверной частью TensorFlow) и PyTorch. Но также поддерживаются сценарии работы с моделью глубокого обучения для прогнозирования в реальном времени.

В этом сценарии используется модель ResNet-152, обученная с помощью набора данных ImageNet -1K (1000 классов), для прогнозирования категории изображения (см. рисунок ниже). Прогнозирование осуществляется в реальном времени с использованием конечной точки REST API.

![Пример прогнозов](./_images/python-example-predictions.png)

Модель глубокого обучения предполагает такой алгоритм работы:

1. Обученная модель глубокого обучения регистрируется в реестре моделей машинного обучения.
2. Служба машинного обучения создает образ Docker, в том числе модель и скрипт оценки.
3. Решение "Машинное обучение" развертывает образ оценки в службе контейнеров Azure (AKS) в качестве веб-службы.
4. Клиент отправляет запрос HTTP POST с закодированными данными изображения.
5. Веб-служба, созданная решением "Машинное обучение", выполняет предварительную обработку данных образа и отправляет их в модель для оценки. 
6. Затем клиенту возвращаются соответствующие категории и их оценки.

## <a name="architecture"></a>Архитектура

Архитектура состоит из следующих компонентов.

**[Служба машинного обучения Azure][aml]**  — это облачная служба, которая используется для обучения, развертывания, автоматизации моделей машинного обучения и управления ими в предоставляемом облаком широком масштабе. Она используется в этой архитектуре для развертывания моделей, а также для проверки подлинности, маршрутизации и балансировки нагрузки веб-службы.

**[Виртуальная машина][vm]**. Виртуальная машина показана в качестве примера локального или облачного устройства, способного отправлять запрос HTTP.

**[Служба Azure Kubernetes][aks]** (AKS) используется для развертывания приложения в кластере Kubernetes. AKS упрощает развертывание и использование Kubernetes. Кластер можно настроить с помощью виртуальных машин с обычным ЦП для обычных моделей Python или виртуальных машин с графическим процессором для моделей глубокого обучения.

**[Реестр контейнеров Azure][acr]** предоставляет хранилище образов для всех типов развертываний контейнеров Docker, включая DC/OS, Docker Swarm и Kubernetes. Образы оценки развертываются в виде контейнеров в службе контейнеров Azure и применяются для запуска скрипта оценки. Используемый здесь образ создается решением "Машинное обучение" на основе обученной модели и скрипта оценки, а затем помещается в реестр контейнеров Azure.

## <a name="performance-considerations"></a>Рекомендации по производительности

Пропускная способность является важным параметром для архитектур оценки в реальном времени. Принято считать, что для рабочей нагрузки обычных моделей Python достаточно обычных ЦП.

Но для рабочих нагрузок моделей глубокого обучения, когда скорость имеет решающее значение, графические процессоры обеспечивают более высокую [производительность][gpus-vs-cpus] по сравнению с обычными ЦП. Чтобы добиться производительности графического процессора, необходим кластер с большим количеством обычных ЦП.

Обычные ЦП можно использовать в любом сценарии для этой архитектуры, но для моделей глубокого обучения графические процессоры обеспечивают гораздо более высокие значения пропускной способности по сравнению с кластером с обычными ЦП в рамках одного бюджета. Для AKS реализована поддержка GPU, что является одним из преимуществ использования этой службы в описанной архитектуре. Кроме того, модели глубокого обучения обычно имеют большое количество параметров. Использование GPU устраняет конкуренцию за ресурсы между моделью и веб-службой, что является проблемой при развертывании с обычными ЦП.

## <a name="scalability-considerations"></a>Вопросы масштабируемости

Для обычных моделей Python, в которых кластер AKS содержит виртуальные машины только с обычными ЦП, особое внимание следует уделить [масштабированию количества модулей pod][manually-scale-pods]. Целью является максимальное использование возможностей кластера. Масштабирование зависит от запросов ЦП, а для модулей pod устанавливаются ограничения. При работе через Kubernetes решение "Машинное обучение" также поддерживает [автомасштабирование pod][autoscale-pods] на основе данных об использовании ЦП и (или) других метрик. [Средство автомасштабирования кластеров][autoscaler] (доступно в предварительной версии) может масштабировать узлы агентов на основе числа ожидающих модулей pod.

Ограничения на ресурсы для сценариев глубокого обучения, в которых используются виртуальные машины с графическими процессорами, предусматривают назначение каждому модулю pod одного графического процессора. В зависимости от типа используемой виртуальной машины, вам нужно выполнить [масштабирование узлов кластера][scale-cluster] в соответствии с требованиями службы. Это делается с помощью Azure CLI и kubectl.

## <a name="monitoring-and-logging-considerations"></a>Мониторинг и ведение журнала запросов

### <a name="aks-monitoring"></a>Мониторинг AKS

Чтобы отслеживать производительность AKS, используйте службу [Azure Monitor для контейнеров][monitor-containers]. Она позволяет собирать данные метрик памяти и процессора из контроллеров, узлов и контейнеров, доступных в Kubernetes, с помощью API метрик.

При развертывании приложения отслеживайте кластер AKS, чтобы убедиться в том, что он работает должным образом, все узлы исправны, а модули pod запущены. Хотя можно использовать средство командной строки [kubectl][kubectl] для получения сведений о состоянии модулей pod, доступная в Kubernetes веб-панель мониторинга позволяет выполнять базовый мониторинг состояния кластера и управлять им.

![Снимок экрана панели мониторинга Kubernetes](./_images/python-kubernetes-dashboard.png)

Чтобы проверить общее состояние кластера и узлов, перейдите в раздел **Узлы** панели мониторинга Kubernetes. Если узел неактивен или произошел сбой, можно просмотреть журналы ошибок на этой странице. В разделах **Объекты pod** и **Развертывания** содержатся сведения о количестве модулей и состоянии развертывания.

### <a name="aks-logs"></a>Журналы AKS

Все потоки stdout и stderr в AKS автоматически регистрируются в журналах модулей pod, содержащихся в кластере. Используйте kubectl, чтобы просмотреть их, а также журналы и события на уровне узла. Дополнительные сведения см. в шагах по развертыванию.

Используйте [Azure Monitor для контейнеров][monitor-containers] для сбора метрик и журналов с помощью контейнерной версии агента Log Analytics для Linux, который хранится в рабочей области Log Analytics.

## <a name="security-considerations"></a>Вопросы безопасности

Благодаря [центру безопасности Azure][security-center] можно получить полное представление о состоянии безопасности ваших ресурсов Azure. Центр безопасности отслеживает потенциальные проблемы безопасности, а также дает полное представление о работоспособности системы безопасности развертывания, хотя и не отслеживает состояние узлов агентов AKS. Центр безопасности настраивается на уровне подписки Azure. Включите сбор данных безопасности, как описано в кратком руководстве [Переход подписки Azure на ценовую категорию центра безопасности "Стандартный"][get-started]. Когда сбор данных включен, центр безопасности автоматически проверяет все виртуальные машины, созданные для этой подписки.

**Эксплуатация**. Чтобы входить в кластер AKS с помощью маркера проверки подлинности Azure Active Directory (Azure AD), настройте в AKS [проверку подлинности пользователей][aad-auth] с помощью Azure AD. Администраторы кластера также могут настроить управление доступом на основе ролей (RBAC) для Kubernetes в зависимости от членства в группе каталогов или удостоверения пользователей.

Контролируйте доступ к развертываемым ресурсам Azure с помощью [RBAC][rbac]. RBAC позволяет назначить роли авторизации участникам команды DevOps. Пользователю можно назначить несколько ролей. Можно также создать пользовательские роли, чтобы выборочно настроить [разрешения].

**HTTPS**. Из соображений безопасности следует принудительно применять в приложении протокол HTTPS, перенаправляя все HTTP-запросы. Используйте [контроллер входящего трафика][ingress-controller], чтобы развернуть обратный прокси-сервер, который завершает SSL и перенаправляет HTTP-запросы. Дополнительные сведения см. в статье [Создание контроллера входящего трафика HTTPS в Службе Azure Kubernetes (AKS)][https-ingress].

**Проверка подлинности**. Это решение не ограничивает доступ к конечным точкам. Чтобы развернуть эту архитектуру в среде предприятия, защитите конечные точки с помощью ключей API и добавьте в клиентское приложение предпочитаемую процедуру аутентификации пользователей.

**Реестр контейнеров**. Это решение использует для хранения образа Docker общедоступный реестр контейнеров Azure. Код, от которого зависит приложение, и модель содержатся в этом образе. Корпоративные приложения должны использовать частный реестр, обеспечивающий защиту от выполнения вредоносного кода и компрометации хранящейся в контейнере информации.

**Защита от атак DDoS.** Рассмотрите возможность подключения [Защиты от атак DDoS ценовой категории "Стандартный"][ddos]. Хотя платформа Azure и обеспечивает базовую защиту от атак DDoS, возможности Защиты Azure от атак DDoS ценовой категории "Стандартный" по снижению рисков атак специально оптимизированы для виртуальных сетевых ресурсов Azure.

**Ведение журналов.** Следуйте рекомендациям при сохранении данных журнала, например, выполняйте очистку пользовательских паролей и других данных, которые могут использоваться в мошеннических целях.

## <a name="deployment"></a>Развертывание

Для развертывания этой эталонной архитектуры, выполните действия, описанные в репозитории GitHub:

- [Обычные модели Python][github-python];
- [Модели машинного обучения][github-dl].

<!-- links -->

[aad-auth]: /azure/aks/aad-integration
[acr]: /azure/container-registry/
[something]: https://kubernetes.io/docs/reference/access-authn-authz/authentication/
[aks]: /azure/aks/intro-kubernetes
[autoscaler]: /azure/aks/autoscaler
[autoscale-pods]: /azure/aks/tutorial-kubernetes-scale#autoscale-pods
[azcopy]: /azure/storage/common/storage-use-azcopy-linux
[ddos]: /azure/virtual-network/ddos-protection-overview
[get-started]: /azure/security-center/security-center-get-started
[github-python]: https://github.com/Microsoft/MLAKSDeployAML
[github-dl]: https://github.com/Microsoft/AKSDeploymentTutorial_AML
[gpus-vs-cpus]: https://azure.microsoft.com/en-us/blog/gpus-vs-cpus-for-deployment-of-deep-learning-models/
[https-ingress]: /azure/aks/ingress-tls
[ingress-controller]: https://kubernetes.io/docs/concepts/services-networking/ingress/
[kubectl]: https://kubernetes.io/docs/tasks/tools/install-kubectl/
[aml]: /azure/machine-learning/service/overview-what-is-azure-ml
[manually-scale-pods]: /azure/aks/tutorial-kubernetes-scale#manually-scale-pods
[monitor-containers]: /azure/monitoring/monitoring-container-insights-overview
[разрешения]: /azure/aks/concepts-identity
[rbac]: /azure/active-directory/role-based-access-control-what-is
[scale-cluster]: /azure/aks/scale-cluster
[scikit]: https://pypi.org/project/scikit-learn/
[security-center]: /azure/security-center/security-center-intro
[vm]: /azure/virtual-machines/
