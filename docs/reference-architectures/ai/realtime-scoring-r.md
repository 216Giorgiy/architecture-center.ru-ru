---
title: Оценка в реальном времени с помощью моделей машинного обучения на языке R
description: Реализуйте службу для прогнозирования в реальном времени на языке R с помощью Machine Learning Server под управлением Службы Azure Kubernetes (AKS).
author: njray
ms.date: 12/12/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 00bea3cae0c3d2f0fea2babd7b0157382cf9890a
ms.sourcegitcommit: 1b50810208354577b00e89e5c031b774b02736e2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/23/2019
ms.locfileid: "54487174"
---
# <a name="real-time-scoring-of-r-machine-learning-models"></a>Оценка в реальном времени с помощью моделей машинного обучения на языке R

В этой эталонной архитектуре показано, как реализовать службу для (синхронного) прогнозирования в реальном времени на языке R с помощью Microsoft Machine Learning Server под управлением Службы Azure Kubernetes (AKS). Эта архитектура должна быть универсальной и подходить для любой прогнозной модели, созданной на языке R, которую вы хотите развернуть как службу в режиме реального времени. **[Разверните это решение][github]**.

## <a name="architecture"></a>Архитектура

![Оценка в реальном времени с помощью моделей машинного обучения на языке R в Azure][0]

В этой эталонной архитектуре используется подход на базе контейнеров. Образ Docker содержит код R, а также различные артефакты, необходимые для оценки новых данных. К ним относится сам объект модели и скрипт оценки. Этот образ отправляется в реестр Docker, размещенный в Azure, а затем развертывается в кластер Kubernetes, а также в Azure.

Архитектура этого рабочего процесса включает в себя следующие компоненты.

- **[Реестр контейнеров Azure][acr]** используется для хранения образов для этого рабочего процесса. Реестрами, созданными с помощью Реестра контейнеров, можно управлять с помощью стандартного [API версии 2 реестра Docker][docker] и клиента.

- **[Служба Azure Kubernetes][aks]** используется для размещения развертывания и службы. Кластерами, созданными с помощью AKS, можно управлять с помощью стандартного [API Kubernetes][k-api] и клиента (kubectl).

- **[Microsoft Machine Learning Server][mmls]** используется для определения REST API для службы и включает в себя [ввод модели в эксплуатацию][operationalization]. Этот процесс веб-сервера, ориентированный на службы, прослушивает запросы, которые затем передаются в другие фоновые процессы, выполняющие фактический код R для формирования результатов. Все эти процессы выполняются на одном узле в этой конфигурации, которая содержится внутри контейнера. Для получения подробных сведений об использовании этой службы за пределами среды разработки или тестирования обратитесь к своему представителю корпорации Майкрософт.

## <a name="performance-considerations"></a>Рекомендации по производительности

Рабочие нагрузки машинного обучения обычно интенсивно используют вычислительные ресурсы как при обучении, так и при оценке новых данных. Возьмите за правило не запускать более одного процесса оценки на ядро. Machine Learning Server позволяет определить количество процессов R, выполняемых в каждом контейнере. Значение по умолчанию составляет пять процессов. При создании относительно простой модели, такой как линейная регрессия с небольшим количеством переменных или небольшое дерево принятия решений, можно увеличить число процессов. Отслеживайте нагрузку на ЦП на узлах кластера для определения соответствующего лимита на число контейнеров.

Кластер с поддержкой GPU может ускорить некоторые типы рабочих нагрузок и модели глубокого обучения в частности. Не все рабочие нагрузки могут воспользоваться преимуществами GPU &mdash; только те, которые активно используют алгебру матриц. Например, модели на основе дерева, включая модели случайных лесов и бустинга, обычно не используют преимущества от GPU.

Некоторые типы моделей, такие как случайные леса, являются массово параллелизуемыми на ЦП. В этих случаях ускорьте оценку одного запроса, распределяя рабочую нагрузку между несколькими ядрами. Тем не менее при этом уменьшается объем емкости, доступной для обработки нескольких запросов оценки, учитывая фиксированный размер кластера.

Как правило, модели R c открытым исходным кодом хранят все свои данные в памяти, поэтому убедитесь, что узлы имеют достаточно памяти для размещения процессов, которые вы собираетесь выполнять параллельно. Если вы применяете Machine Learning Server в соответствии с моделями, используйте библиотеки, которые могут обрабатывать данные на диске, а не считывают их все в памяти. Это помогает значительно снизить требования к памяти. Независимо от того, используется ли Machine Learning Server или R с открытым исходным кодом, отслеживайте узлы, чтобы гарантировать, что процессы оценки не останутся без памяти.

## <a name="security-considerations"></a>Вопросы безопасности

### <a name="network-encryption"></a>Сетевое шифрование

В этой эталонной архитектуре включен протокол HTTPS для обмена данными с кластером и используется промежуточный сертификат от [Let's Encrypt][encrypt]. Для рабочей среды подставьте собственный сертификат от соответствующего заверителя подписи.

### <a name="authentication-and-authorization"></a>Аутентификация и авторизация

Для [ввода модели в эксплуатацию][operationalization] в среде Machine Learning Server требуется, чтобы оценка запросов прошла проверку подлинности. В этом развертывании используются имя пользователя и пароль. Для предприятия можно включить проверку подлинности с использованием [Azure Active Directory][AAD] или создать отдельный внешний интерфейс с помощью [службы управления API Azure][API].

Чтобы задание ввода модели в эксплуатацию правильно работало с Machine Learning Server на контейнерах, необходимо установить сертификат JSON Web Token (JWT). Это развертывание использует сертификат, предоставленный корпорацией Майкрософт. Для рабочей среды предоставьте собственный сертификат.

Для трафика между Реестром контейнеров и AKS рассмотрите возможность включения [управления доступом на основе ролей][rbac] (RBAC), чтобы предоставить только необходимые привилегии доступа.

### <a name="separate-storage"></a>Отдельное хранилище

Эта эталонная архитектура объединяет приложение (R) и данные (объект модели и скрипт оценки) в один образ. В некоторых случаях может быть полезно разделить их. Можно поместить модель данных и код в файловое хранилище или [хранилище][storage] BLOB-объектов Azure и извлекать их при инициализации контейнера. В этом случае убедитесь, что учетная запись хранения настроена для разрешения только доступа с проверкой подлинности и обязательного использования протокола HTTPS.

## <a name="monitoring-and-logging-considerations"></a>Мониторинг и ведение журнала запросов

С помощью [панели мониторинга Kubernetes][dashboard] можно отслеживать общее состояние кластера AKS. Дополнительные сведения приведены в колонке обзора кластера на портале Azure. В ресурсах [GitHub][github] также показано, как открыть панель мониторинга из кода R.

Несмотря на то что панель мониторинга дает представление об общем состоянии работоспособности кластера, также важно отслеживать состояние отдельных контейнеров. Чтобы сделать это, необходимо включить [службу аналитических сведений Azure Monitor][monitor] в колонке обзора кластера на портале Azure или перейти к статье об [Azure Monitor для контейнеров][monitor-containers] (в предварительной версии).

## <a name="cost-considerations"></a>Рекомендации по стоимости

Machine Learning Server лицензируется на каждое ядро, и в этом учитываются все ядра в кластере, где будет выполняться Machine Learning Server. Если вы являетесь корпоративным клиентом Machine Learning Server или Microsoft SQL Server, обратитесь к представителю корпорации Майкрософт для дополнительных сведений о ценах.

Альтернативой Machine Learning Server с открытым исходным кодом является [Plumber][plumber] — пакет R, который превращает ваш код в REST API. Plumber не такой полнофункциональный, как Machine Learning Server. Например, по умолчанию он не включает все функции, которые обеспечивают проверку подлинности запроса. Если вы используете Plumber, рекомендуется включить [службу управления API Azure][API] для обработки сведений о проверке подлинности.

Помимо лицензирования, основной источник затрат — это вычислительные ресурсы кластера Kubernetes. Кластер должен быть достаточно большим для обработки ожидаемого объема запросов в часы пик, но при этом подходе ресурсы простаивают в другое время. Чтобы ограничить влияние простаивающих ресурсов, необходимо включить [горизонтальное автомасштабирование][autoscaler] для кластера, используя средство kubectl. Можно также использовать [средство автомасштабирования кластера][cluster-autoscaler] AKS.

## <a name="deploy-the-solution"></a>Развертывание решения

Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github]. Выполните действия, описанные там, чтобы развернуть простую прогнозную модель как службу.

<!-- links -->
[AAD]: /azure/active-directory/fundamentals/active-directory-whatis
[API]: /azure/api-management/api-management-key-concepts
[ACR]: /azure/container-registry/container-registry-intro
[AKS]: /azure/aks/intro-kubernetes
[autoscaler]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
[cluster-autoscaler]: /azure/aks/autoscaler
[monitor]: /azure/monitoring/monitoring-container-insights-overview
[dashboard]: /azure/aks/kubernetes-dashboard
[docker]: https://docs.docker.com/registry/spec/api/
[encrypt]: https://letsencrypt.org/
[gitHub]: https://github.com/Azure/RealtimeRDeployment
[K-API]: https://kubernetes.io/docs/reference/
[MMLS]: /machine-learning-server/what-is-machine-learning-server
[monitor-containers]: /azure/azure-monitor/insights/container-insights-overview
[operationalization]: /machine-learning-server/what-is-operationalization
[plumber]: https://www.rplumber.io
[RBAC]: /azure/role-based-access-control/overview
[storage]: /azure/storage/common/storage-introduction
[0]: ./_images/realtime-scoring-r.png
