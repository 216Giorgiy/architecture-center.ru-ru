---
title: Распределенное обучение моделей глубокого обучения в Azure
description: В этой эталонной архитектуре демонстрируется выполнение распределенного обучения для моделей глубокого обучения в кластерах виртуальных машин с поддержкой GPU с применением Azure Batch AI.
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 800defeb851f5a31dc730038c3699e1a3d54b923
ms.sourcegitcommit: d5ea427c25f9f7799cc859b99f328739ca2d8c1c
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/15/2019
ms.locfileid: "54307805"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a><span data-ttu-id="41f17-103">Распределенное обучение моделей глубокого обучения в Azure</span><span class="sxs-lookup"><span data-stu-id="41f17-103">Distributed training of deep learning models on Azure</span></span>

<span data-ttu-id="41f17-104">В этой эталонной архитектуре демонстрируется выполнение распределенного обучения для моделей глубокого обучения в кластерах виртуальных машин с поддержкой графических процессоров (GPU).</span><span class="sxs-lookup"><span data-stu-id="41f17-104">This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span> <span data-ttu-id="41f17-105">За основу взят сценарий классификации изображений, но это решение можно адаптировать к любым сценариям глубокого обучения, таким как сегментация и обнаружение объектов.</span><span class="sxs-lookup"><span data-stu-id="41f17-105">The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</span></span>

<span data-ttu-id="41f17-106">Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="41f17-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Архитектура для распределенного глубокого обучения][0]

<span data-ttu-id="41f17-108">**Сценарий**. Классификация изображений — это широко распространенная в отрасли компьютерного зрения задача, для решения которой часто применяется обучение сверточной нейронной сети (CNN).</span><span class="sxs-lookup"><span data-stu-id="41f17-108">**Scenario**: Image classification is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN).</span></span> <span data-ttu-id="41f17-109">Для особо крупных моделей с большими наборами данных процесс такого обучения на одном GPU может занять несколько недель или даже месяцев.</span><span class="sxs-lookup"><span data-stu-id="41f17-109">For particularly large models with large datasets, the training process can take weeks or months on a single GPU.</span></span> <span data-ttu-id="41f17-110">Иногда модели бывают настолько большими, что не позволяют создать пакет приемлемого размера для выполнения на одном GPU.</span><span class="sxs-lookup"><span data-stu-id="41f17-110">In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU.</span></span> <span data-ttu-id="41f17-111">В таких ситуациях распределенное обучение позволяет сократить время обучения.</span><span class="sxs-lookup"><span data-stu-id="41f17-111">Using distributed training in these situations can shorten the training time.</span></span>

<span data-ttu-id="41f17-112">В нашем примере выполняется обучение [модели сверточной нейронной сети ResNet50][resnet] с использованием [Horovod][horovod] на основе [набора данных ImageNet][imagenet] и искусственных данных.</span><span class="sxs-lookup"><span data-stu-id="41f17-112">In this specific scenario, a [ResNet50 CNN model][resnet] is trained using [Horovod][horovod] on the [Imagenet dataset][imagenet] and on synthetic data.</span></span> <span data-ttu-id="41f17-113">Эталонная реализация демонстрирует, как выполнить эту задачу с помощью трех наиболее популярных платформ машинного обучения: TensorFlow, Keras и PyTorch.</span><span class="sxs-lookup"><span data-stu-id="41f17-113">The reference implementation shows how to accomplish this task using three of the most popular deep learning frameworks: TensorFlow, Keras, and PyTorch.</span></span>

<span data-ttu-id="41f17-114">Существует несколько способов для обучения модели глубокого обучения в распределенном режиме. В них может применяться параллельная обработка по данным или по моделям с синхронным или асинхронным обновлением.</span><span class="sxs-lookup"><span data-stu-id="41f17-114">There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates.</span></span> <span data-ttu-id="41f17-115">Сейчас самой популярной считается параллельная обработка по данным с синхронным обновлением.</span><span class="sxs-lookup"><span data-stu-id="41f17-115">Currently the most common scenario is data parallel with synchronous updates.</span></span> <span data-ttu-id="41f17-116">Это самый простой в реализации подход, и его вполне достаточно для большинства вариантов использования.</span><span class="sxs-lookup"><span data-stu-id="41f17-116">This approach is the easiest to implement and is sufficient for most use cases.</span></span>

<span data-ttu-id="41f17-117">Когда применяется распределенное обучение с параллельной обработкой по данным и синхронным обновлением, модель реплицируется на *n* аппаратных устройств.</span><span class="sxs-lookup"><span data-stu-id="41f17-117">In data-parallel distributed training with synchronous updates, the model is replicated across *n* hardware devices.</span></span> <span data-ttu-id="41f17-118">Мини-пакет образцов для обучения также разделяется на *n* микропакетов.</span><span class="sxs-lookup"><span data-stu-id="41f17-118">A mini-batch of training samples is divided into *n* micro-batches.</span></span> <span data-ttu-id="41f17-119">Затем каждое устройство выполняет прямые и обратные проходы по этим микропакетам.</span><span class="sxs-lookup"><span data-stu-id="41f17-119">Each device performs the forward and backward passes for a micro-batch.</span></span> <span data-ttu-id="41f17-120">Завершив процесс, устройство передает обновления на другие устройства.</span><span class="sxs-lookup"><span data-stu-id="41f17-120">When a device finishes the process, it shares the updates with the other devices.</span></span> <span data-ttu-id="41f17-121">Полученные значения используются для обновления весовых коэффициентов для всего мини-пакета с синхронизацией этих коэффициентов между всеми моделями.</span><span class="sxs-lookup"><span data-stu-id="41f17-121">These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models.</span></span> <span data-ttu-id="41f17-122">Этот сценарий представлен в репозитории [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="41f17-122">This scenario is covered in the [GitHub][github] repository.</span></span>

![Распределенное обучение с параллельной обработкой по данным][1]

<span data-ttu-id="41f17-124">Эту же архитектуру можно применить для параллельной обработки по моделям и асинхронных обновлений.</span><span class="sxs-lookup"><span data-stu-id="41f17-124">This architecture can also be used for model-parallel and asynchronous updates.</span></span> <span data-ttu-id="41f17-125">Если распределенное обучение выполняется с параллельной обработкой по моделям, модель разделяется между *n* аппаратными устройствами, каждому из которых достается определенная часть модели.</span><span class="sxs-lookup"><span data-stu-id="41f17-125">In model-parallel distributed training, the model is divided across *n* hardware devices, with each device holding a part of the model.</span></span> <span data-ttu-id="41f17-126">В простейшей реализации каждое устройство содержит слой сети, а данные передаются между устройствами при каждом прямом и обратном проходе.</span><span class="sxs-lookup"><span data-stu-id="41f17-126">In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass.</span></span> <span data-ttu-id="41f17-127">Так можно обучать даже большие нейронные сети, но эффективность работы при этом снижается, так как устройства постоянно ожидают друг друга на каждом прямом и обратном проходе.</span><span class="sxs-lookup"><span data-stu-id="41f17-127">Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass.</span></span> <span data-ttu-id="41f17-128">Существуют дополнительные технологии, позволяющие частично устранить эту проблему с помощью искусственных градиентов.</span><span class="sxs-lookup"><span data-stu-id="41f17-128">Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</span></span>

<span data-ttu-id="41f17-129">Ниже описана процедура обучения.</span><span class="sxs-lookup"><span data-stu-id="41f17-129">The steps for training are:</span></span>

1. <span data-ttu-id="41f17-130">Создайте скрипты, которые будут выполняться в кластере для обучения модели, и передайте их в хранилище файлов.</span><span class="sxs-lookup"><span data-stu-id="41f17-130">Create scripts that will run on the cluster and train your model, then transfer them to file storage.</span></span>

1. <span data-ttu-id="41f17-131">Сохраните данные в хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="41f17-131">Write the data to Blob Storage.</span></span>

1. <span data-ttu-id="41f17-132">Создайте файловый сервер Batch AI и скачайте на него данные из хранилища BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="41f17-132">Create a Batch AI file server and download the data from Blob Storage onto it.</span></span>

1. <span data-ttu-id="41f17-133">Создайте контейнеры Docker для каждой платформы глубокого обучения и передайте их в реестр контейнеров (Docker Hub).</span><span class="sxs-lookup"><span data-stu-id="41f17-133">Create the Docker containers for each deep learning framework and transfer them to a container registry (Docker Hub).</span></span>

1. <span data-ttu-id="41f17-134">Создайте пул Batch AI, к которому также будет подключен файловый сервер Batch AI.</span><span class="sxs-lookup"><span data-stu-id="41f17-134">Create a Batch AI pool that also mounts the Batch AI file server.</span></span>

1. <span data-ttu-id="41f17-135">отправки заданий;</span><span class="sxs-lookup"><span data-stu-id="41f17-135">Submit jobs.</span></span> <span data-ttu-id="41f17-136">Каждое задание извлекает соответствующий образ Docker и скрипты.</span><span class="sxs-lookup"><span data-stu-id="41f17-136">Each pulls in the appropriate Docker image and scripts.</span></span>

1. <span data-ttu-id="41f17-137">Результаты выполненного задания записываются в хранилище файлов.</span><span class="sxs-lookup"><span data-stu-id="41f17-137">Once the job is completed, write all the results to Files storage.</span></span>

## <a name="architecture"></a><span data-ttu-id="41f17-138">Архитектура</span><span class="sxs-lookup"><span data-stu-id="41f17-138">Architecture</span></span>

<span data-ttu-id="41f17-139">Архитектура состоит из следующих компонентов.</span><span class="sxs-lookup"><span data-stu-id="41f17-139">This architecture consists of the following components.</span></span>

<span data-ttu-id="41f17-140">**[Azure Batch AI][batch-ai]** играет центральную роль в этой архитектуре и масштабирует ресурсы в соответствии с потребностями.</span><span class="sxs-lookup"><span data-stu-id="41f17-140">**[Azure Batch AI][batch-ai]** plays the central role in this architecture by scaling resources up and down according to need.</span></span> <span data-ttu-id="41f17-141">Служба Batch AI используется для подготовки кластеров виртуальных машин и управления ими, планирования заданий, сбора результатов, масштабирования ресурсов, обработки ошибок и создания соответствующего хранилища.</span><span class="sxs-lookup"><span data-stu-id="41f17-141">Batch AI is a service that helps provision and manage clusters of VMs, schedule jobs, gather results, scale resources, handle failures, and create appropriate storage.</span></span> <span data-ttu-id="41f17-142">Она позволяет использовать виртуальные машины с поддержкой GPU для рабочих нагрузок глубокого обучения.</span><span class="sxs-lookup"><span data-stu-id="41f17-142">It supports GPU-enabled VMs for deep learning workloads.</span></span> <span data-ttu-id="41f17-143">Для работы с Batch AI предоставляются пакет SDK для Python и интерфейс командной строки (CLI).</span><span class="sxs-lookup"><span data-stu-id="41f17-143">A Python SDK and a command-line interface (CLI) are available for Batch AI.</span></span>

> [!NOTE]
> <span data-ttu-id="41f17-144">В марте 2019 г. служба Batch AI будет выведена из эксплуатации, и с этого момента все возможности масштабируемого обучения и оценки будут доступны только в [Службе машинного обучения Azure][amls].</span><span class="sxs-lookup"><span data-stu-id="41f17-144">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="41f17-145">В ближайшее время в эту эталонную архитектуру будут внесены обновления в связи с переходом на решение "Машинное обучение". Для обучения, развертывания и оценки моделей машинного обучения в нем предоставляется управляемый целевой объект вычислений, который называется [Вычислительная среда Машинного обучения Azure][aml-compute].</span><span class="sxs-lookup"><span data-stu-id="41f17-145">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

<span data-ttu-id="41f17-146">Для размещения данных используется **[хранилище BLOB-объектов][azure-blob]**.</span><span class="sxs-lookup"><span data-stu-id="41f17-146">**[Blob storage][azure-blob]** is used to stage the data.</span></span> <span data-ttu-id="41f17-147">Эти данные в процессе обучения скачиваются на файловый сервер Batch AI.</span><span class="sxs-lookup"><span data-stu-id="41f17-147">This data is downloaded to a Batch AI file server during training.</span></span>

<span data-ttu-id="41f17-148">Для хранения скриптов, журналов и окончательных результатов обучения используется служба **[Файлы Azure][files]**.</span><span class="sxs-lookup"><span data-stu-id="41f17-148">**[Azure Files][files]** is used to store the scripts, logs, and the final results from the training.</span></span> <span data-ttu-id="41f17-149">Хранилище файлов хорошо подходит для хранения журналов и скриптов, но не обеспечивает такую же производительность, как хранилище BLOB-объектов, поэтому его не стоит использовать для ресурсоемких задач.</span><span class="sxs-lookup"><span data-stu-id="41f17-149">File storage works well for storing logs and scripts, but is not as performant as Blob Storage, so it shouldn't be used for data-intensive tasks.</span></span>

<span data-ttu-id="41f17-150">В этой архитектуре для хранения учебных данных применяется **[файловый сервер Batch AI][batch-ai-files]**, который представляет собой общую папку NFS, размещенную на одном узле.</span><span class="sxs-lookup"><span data-stu-id="41f17-150">**[Batch AI file server][batch-ai-files]** is a single-node NFS share used in this architecture to store the training data.</span></span> <span data-ttu-id="41f17-151">Служба Batch AI создает общую папку NFS и подключает ее к кластеру.</span><span class="sxs-lookup"><span data-stu-id="41f17-151">Batch AI creates an NFS share and mounts it on the cluster.</span></span> <span data-ttu-id="41f17-152">Мы рекомендуем использовать файловые серверы Batch AI для предоставления данных в кластере с достаточной пропускной способностью.</span><span class="sxs-lookup"><span data-stu-id="41f17-152">Batch AI file servers are the recommended way to serve data to the cluster with the necessary throughput.</span></span>

<span data-ttu-id="41f17-153">Для хранения образа Docker, который Batch AI применяет при выполнении обучения, используется **[Docker Hub][docker]**.</span><span class="sxs-lookup"><span data-stu-id="41f17-153">**[Docker Hub][docker]** is used to store the Docker image that Batch AI uses to run the training.</span></span> <span data-ttu-id="41f17-154">Центр Docker выбран для этой архитектуры, так как он прост в использовании и является репозиторием образов по умолчанию для пользователей Docker.</span><span class="sxs-lookup"><span data-stu-id="41f17-154">Docker Hub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="41f17-155">[Реестр контейнеров Azure][acr] также можно использовать.</span><span class="sxs-lookup"><span data-stu-id="41f17-155">[Azure Container Registry][acr] can also be used.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="41f17-156">Рекомендации по производительности</span><span class="sxs-lookup"><span data-stu-id="41f17-156">Performance considerations</span></span>

<span data-ttu-id="41f17-157">Azure предоставляет четыре [типа виртуальных машин с поддержкой GPU][gpu], пригодных для обучения моделей глубокого обучения.</span><span class="sxs-lookup"><span data-stu-id="41f17-157">Azure provides four [GPU-enabled VM types][gpu] suitable for training deep learning models.</span></span> <span data-ttu-id="41f17-158">Эти варианты перечислены ниже в порядке увеличения цены и скорости работы.</span><span class="sxs-lookup"><span data-stu-id="41f17-158">They range in price and speed from low to high as follows:</span></span>

| <span data-ttu-id="41f17-159">**Серия виртуальных машин Azure**</span><span class="sxs-lookup"><span data-stu-id="41f17-159">**Azure VM series**</span></span> | <span data-ttu-id="41f17-160">**GPU NVIDIA**</span><span class="sxs-lookup"><span data-stu-id="41f17-160">**NVIDIA GPU**</span></span> |
|---------------------|----------------|
| <span data-ttu-id="41f17-161">NC</span><span class="sxs-lookup"><span data-stu-id="41f17-161">NC</span></span>                  | <span data-ttu-id="41f17-162">K80</span><span class="sxs-lookup"><span data-stu-id="41f17-162">K80</span></span>            |
| <span data-ttu-id="41f17-163">ND</span><span class="sxs-lookup"><span data-stu-id="41f17-163">ND</span></span>                  | <span data-ttu-id="41f17-164">P40</span><span class="sxs-lookup"><span data-stu-id="41f17-164">P40</span></span>            |
| <span data-ttu-id="41f17-165">NCv2</span><span class="sxs-lookup"><span data-stu-id="41f17-165">NCv2</span></span>                | <span data-ttu-id="41f17-166">P100</span><span class="sxs-lookup"><span data-stu-id="41f17-166">P100</span></span>           |
| <span data-ttu-id="41f17-167">NCv3</span><span class="sxs-lookup"><span data-stu-id="41f17-167">NCv3</span></span>                | <span data-ttu-id="41f17-168">V100</span><span class="sxs-lookup"><span data-stu-id="41f17-168">V100</span></span>           |

<span data-ttu-id="41f17-169">Для задач обучения мы рекомендуем сначала применять вертикальное масштабирование, а только после этого — горизонтальное. Например, сначала лучше использовать один процессор V100, чем кластер из нескольких процессоров K80.</span><span class="sxs-lookup"><span data-stu-id="41f17-169">We recommended scaling up your training before scaling out. For example, try a single V100 before trying a cluster of K80s.</span></span>

<span data-ttu-id="41f17-170">На приведенной ниже диаграмме показаны различия в производительности между разными типами GPU по результатам [тестов производительности][benchmark], которые выполнялись с помощью TensorFlow и Horovod в Batch AI.</span><span class="sxs-lookup"><span data-stu-id="41f17-170">The following graph shows the performance differences for different GPU types based on [benchmarking tests][benchmark] carried out using TensorFlow and Horovod on Batch AI.</span></span> <span data-ttu-id="41f17-171">На этой диаграмме представлена пропускная способность кластеров из 32 GPU для нескольких разных моделей, разных типов GPU и версий MPI.</span><span class="sxs-lookup"><span data-stu-id="41f17-171">The graph shows throughput of 32 GPU clusters across various models, on different GPU types and MPI versions.</span></span> <span data-ttu-id="41f17-172">Все модели были реализованы в TensorFlow версии 1.9.</span><span class="sxs-lookup"><span data-stu-id="41f17-172">Models were implemented in TensorFlow 1.9</span></span>

![Данные о пропускной способности для моделей TensorFlow в кластерах GPU][2]

<span data-ttu-id="41f17-174">Все серии виртуальных машин из приведенной выше таблицы включают конфигурацию с InfiniBand.</span><span class="sxs-lookup"><span data-stu-id="41f17-174">Each VM series shown in the previous table includes a configuration with InfiniBand.</span></span> <span data-ttu-id="41f17-175">При выполнении распределенного обучения эти конфигурации InfiniBand позволяют ускорить обмен данными между узлами.</span><span class="sxs-lookup"><span data-stu-id="41f17-175">Use the InfiniBand configurations when you run distributed training, for faster communication between nodes.</span></span> <span data-ttu-id="41f17-176">Также InfiniBand повышает эффективность масштабирования для обучения на тех платформах, которые поддерживают эту технологию.</span><span class="sxs-lookup"><span data-stu-id="41f17-176">InfiniBand also increases the scaling efficiency of the training for the frameworks that can take advantage of it.</span></span> <span data-ttu-id="41f17-177">Дополнительные сведения см. в [сравнительном анализе тестов][benchmark] для Infiniband.</span><span class="sxs-lookup"><span data-stu-id="41f17-177">For details, see the Infiniband [benchmark comparison][benchmark].</span></span>

<span data-ttu-id="41f17-178">Azure Batch AI умеет подключать хранилище BLOB-объектов через адаптер [blobfuse][blobfuse], но мы не рекомендуем применять хранилище BLOB-объектов при распределенном обучении таким образом, так как оно не имеет достаточной производительности для обработки требуемой пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="41f17-178">Although Batch AI can mount Blob storage using the [blobfuse][blobfuse] adapter, we don't recommend using Blob Storage this way for distributed training, because the performance isn't good enough to handle the necessary throughput.</span></span> <span data-ttu-id="41f17-179">Лучше поместите данные на файловый сервер Batch AI, как показано на схеме архитектуры.</span><span class="sxs-lookup"><span data-stu-id="41f17-179">Move the data to a Batch AI file server instead, as shown in the architecture diagram.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="41f17-180">Вопросы масштабируемости</span><span class="sxs-lookup"><span data-stu-id="41f17-180">Scalability considerations</span></span>

<span data-ttu-id="41f17-181">Эффективность масштабирования при распределенном обучении всегда далека от 100 % из-за значительных издержек на сетевое взаимодействие. Узким местом становится синхронизация всей модели между устройствами.</span><span class="sxs-lookup"><span data-stu-id="41f17-181">The scaling efficiency of distributed training is always less than 100 percent due to network overhead &mdash; syncing the entire model between devices becomes a bottleneck.</span></span> <span data-ttu-id="41f17-182">Это означает, что распределенное обучение лучше всего подходит для больших моделей, для обучения которых на одном GPU невозможно применить пакет приемлемого размера, а также для таких проблем, для решения которых недостаточно простого параллельного распределения модели.</span><span class="sxs-lookup"><span data-stu-id="41f17-182">Therefore, distributed training is most suited for large models that cannot be trained using a reasonable batch size on a single GPU, or for problems that cannot be addressed by distributing the model in a simple, parallel way.</span></span>

<span data-ttu-id="41f17-183">Мы не рекомендуем применять распределенное обучение для поиска гиперпараметров.</span><span class="sxs-lookup"><span data-stu-id="41f17-183">Distributed training is not recommended for running hyperparameter searches.</span></span> <span data-ttu-id="41f17-184">Эффективность масштабирования влияет на производительность и снижает эффективность распределенного подхода по сравнению с раздельным обучением нескольких конфигураций модели.</span><span class="sxs-lookup"><span data-stu-id="41f17-184">The scaling efficiency affects performance and makes a distributed approach less efficient than training multiple model configurations separately.</span></span>

<span data-ttu-id="41f17-185">Для повышения эффективности масштабирования можно увеличить размер пакета.</span><span class="sxs-lookup"><span data-stu-id="41f17-185">One way to increase scaling efficiency is to increase the batch size.</span></span> <span data-ttu-id="41f17-186">Но соблюдайте при этом осторожность, ведь увеличение размера пакета без корректировки других параметров может значительно снизить итоговую производительность модели.</span><span class="sxs-lookup"><span data-stu-id="41f17-186">That must be done carefully, however, because increasing the batch size without adjusting the other parameters can hurt the model's final performance.</span></span>

## <a name="storage-considerations"></a><span data-ttu-id="41f17-187">Рекомендации по работе с хранилищем</span><span class="sxs-lookup"><span data-stu-id="41f17-187">Storage considerations</span></span>

<span data-ttu-id="41f17-188">При обучении моделей глубокого обучения часто упускают из виду такой аспект, как расположение для хранения данных.</span><span class="sxs-lookup"><span data-stu-id="41f17-188">When training deep learning models, an often-overlooked aspect is where the data is stored.</span></span> <span data-ttu-id="41f17-189">Если скорость работы хранилища не соответствует требованиям GPU, эффективность обучения будет снижаться.</span><span class="sxs-lookup"><span data-stu-id="41f17-189">If the storage is too slow to keep up with the demands of the GPUs, training performance can degrade.</span></span>

<span data-ttu-id="41f17-190">Batch AI поддерживает различные решения для хранения данных.</span><span class="sxs-lookup"><span data-stu-id="41f17-190">Batch AI supports many storage solutions.</span></span> <span data-ttu-id="41f17-191">В нашей архитектуре используется файловый сервер Batch AI, который обеспечивает оптимальный баланс между простотой использования и производительностью.</span><span class="sxs-lookup"><span data-stu-id="41f17-191">This architecture uses a Batch AI file server, because it provides the best tradeoff between ease of use and performance.</span></span> <span data-ttu-id="41f17-192">Для максимальной производительности загружайте данные локально.</span><span class="sxs-lookup"><span data-stu-id="41f17-192">For best performance, load the data locally.</span></span> <span data-ttu-id="41f17-193">Но иногда это очень неудобно, так как данные из хранилища BLOB-объектов нужно скачать на все узлы, а этот процесс для набора данных ImageNet занимает несколько часов.</span><span class="sxs-lookup"><span data-stu-id="41f17-193">However, this can be cumbersome, because all the nodes must download the data from Blob Storage, and with the ImageNet dataset, this can take hours.</span></span> <span data-ttu-id="41f17-194">Еще один неплохой вариант — [хранилище BLOB-объектов Azure ценовой категории "Премиум"][blob] (ограниченная общедоступная предварительная версия).</span><span class="sxs-lookup"><span data-stu-id="41f17-194">[Azure Premium Blob Storage][blob] (limited public preview) is another good option to consider.</span></span>

<span data-ttu-id="41f17-195">Не используйте хранилище BLOB-объектов и хранилище файлов в качестве хранилища данных для распределенного обучения.</span><span class="sxs-lookup"><span data-stu-id="41f17-195">Do not mount Blob and File storage as data stores for distributed training.</span></span> <span data-ttu-id="41f17-196">Они работают слишком медленно, что снизит производительность обучения.</span><span class="sxs-lookup"><span data-stu-id="41f17-196">They are too slow and will hinder training performance.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="41f17-197">Вопросы безопасности</span><span class="sxs-lookup"><span data-stu-id="41f17-197">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="41f17-198">Ограничение доступа к хранилищу BLOB-объектов Azure</span><span class="sxs-lookup"><span data-stu-id="41f17-198">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="41f17-199">В этой архитектуре для доступа к хранилищу BLOB-объектов используются [ключи учетной записи хранения][security-guide].</span><span class="sxs-lookup"><span data-stu-id="41f17-199">This architecture uses [storage account keys][security-guide] to access the Blob storage.</span></span> <span data-ttu-id="41f17-200">Для дальнейшего управления и защиты рекомендуется использовать подписанный URL-адрес (SAS).</span><span class="sxs-lookup"><span data-stu-id="41f17-200">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="41f17-201">Таким образом можно предоставить ограниченный доступ к объектам в хранилище без необходимости жесткого кодирования ключей учетной записи или сохранения их в виде открытого текста.</span><span class="sxs-lookup"><span data-stu-id="41f17-201">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="41f17-202">Использование SAS также гарантирует, что в учетной записи хранения обеспечено надлежащее управление, а доступ предоставляется только пользователям, которым он необходим.</span><span class="sxs-lookup"><span data-stu-id="41f17-202">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="41f17-203">Для сценариев с более конфиденциальными данными убедитесь, что все ключи к хранилищу защищены, так как эти ключи предоставляют полный доступ всем входным и выходным данным из рабочей нагрузки.</span><span class="sxs-lookup"><span data-stu-id="41f17-203">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="41f17-204">Шифрование данных во время хранения и передачи</span><span class="sxs-lookup"><span data-stu-id="41f17-204">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="41f17-205">В сценариях с использованием конфиденциальных данных следует шифровать все неактивные (размещенные в хранилище) данные.</span><span class="sxs-lookup"><span data-stu-id="41f17-205">In scenarios that use sensitive data, encrypt the data at rest &mdash; that is, the data in storage.</span></span> <span data-ttu-id="41f17-206">При любых перемещениях данных из одного расположения в другое используйте SSL для безопасной передачи данных.</span><span class="sxs-lookup"><span data-stu-id="41f17-206">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="41f17-207">Дополнительные сведения см. в [руководстве по безопасности службы хранилища Azure][security-guide].</span><span class="sxs-lookup"><span data-stu-id="41f17-207">For more information, see the [Azure Storage security guide][security-guide].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="41f17-208">Защита данных в виртуальной сети</span><span class="sxs-lookup"><span data-stu-id="41f17-208">Secure data in a virtual network</span></span>

<span data-ttu-id="41f17-209">Для развертываний в рабочей среде следует развернуть кластер Batch AI в выбранной вами подсети виртуальной сети.</span><span class="sxs-lookup"><span data-stu-id="41f17-209">For production deployments, consider deploying the Batch AI cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="41f17-210">Это позволит вычислительным узлам в кластере безопасно обмениваться данными с другими виртуальными машинами или с локальной сетью.</span><span class="sxs-lookup"><span data-stu-id="41f17-210">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="41f17-211">Можно также использовать [конечные точки службы][endpoints] с хранилищем BLOB-объектов, чтобы предоставить доступ из виртуальной сети, или NFS с одним узлом внутри виртуальной сети, где размещена служба Batch AI.</span><span class="sxs-lookup"><span data-stu-id="41f17-211">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Batch AI.</span></span>

## <a name="monitoring-considerations"></a><span data-ttu-id="41f17-212">Рекомендации по мониторингу</span><span class="sxs-lookup"><span data-stu-id="41f17-212">Monitoring considerations</span></span>

<span data-ttu-id="41f17-213">Во время выполнения задания, важно отслеживать ход выполнения и убедиться, что все работает должным образом.</span><span class="sxs-lookup"><span data-stu-id="41f17-213">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="41f17-214">Тем не менее, сложно отслеживать кластер активных узлов.</span><span class="sxs-lookup"><span data-stu-id="41f17-214">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="41f17-215">Файловыми серверами Batch AI можно управлять с помощью портала Azure, [Azure CLI][cli] или пакета SDK для Python.</span><span class="sxs-lookup"><span data-stu-id="41f17-215">The Batch AI file servers can be managed through the Azure portal or though the [Azure CLI][cli] and Python SDK.</span></span> <span data-ttu-id="41f17-216">Чтобы получить представление об общем состоянии кластера, перейдите к разделу **Batch AI** на портале Azure, чтобы проверить состояние узлов в кластере.</span><span class="sxs-lookup"><span data-stu-id="41f17-216">To get a sense of the overall state of the cluster, navigate to **Batch AI** in the Azure portal to inspect the state of the cluster nodes.</span></span> <span data-ttu-id="41f17-217">Если узел неактивен или произошел сбой задания, журналы ошибок сохраняются в хранилище BLOB-объектов, а также в разделе **Задания** на портале Azure.</span><span class="sxs-lookup"><span data-stu-id="41f17-217">If a node is inactive or a job fails, the error logs are saved to blob storage, and are also accessible in the Azure Portal under **Jobs**.</span></span>

<span data-ttu-id="41f17-218">Возможности мониторинга можно расширить, подключив журналы к [Azure Application Insights][ai] или запустив отдельные процессы для сбора сведений о состоянии кластера Batch AI и его заданий.</span><span class="sxs-lookup"><span data-stu-id="41f17-218">Enrich monitoring by connecting logs to [Azure Application Insights][ai] or by running separate processes that poll for the state of the Batch AI cluster and its jobs.</span></span>

<span data-ttu-id="41f17-219">Batch AI автоматически сохраняет все выходные данные stdout и stderr в связанной учетной записи хранения больших двоичных объектов.</span><span class="sxs-lookup"><span data-stu-id="41f17-219">Batch AI automatically logs all stdout/stderr to the associate Blob storage account.</span></span> <span data-ttu-id="41f17-220">Средства навигации в хранилище, например [Обозреватель службы хранилища Azure][storage-explorer], упрощают навигацию по файлам журналов.</span><span class="sxs-lookup"><span data-stu-id="41f17-220">Use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] for an easier experience when navigating log files.</span></span>

<span data-ttu-id="41f17-221">Также вы можете настроить потоковую передачу журналов для каждого задания.</span><span class="sxs-lookup"><span data-stu-id="41f17-221">It is also possible to stream the logs for each job.</span></span> <span data-ttu-id="41f17-222">Дополнительные сведения об этом варианте вы найдете в описании этапов разработки на сайте [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="41f17-222">For details about this option, see the development steps on [GitHub][github].</span></span>

## <a name="deployment"></a><span data-ttu-id="41f17-223">Развертывание</span><span class="sxs-lookup"><span data-stu-id="41f17-223">Deployment</span></span>

<span data-ttu-id="41f17-224">Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="41f17-224">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="41f17-225">Описанные здесь шаги позволяют выполнить распределенное обучение моделей глубокого обучения в кластерах виртуальных машин с поддержкой GPU.</span><span class="sxs-lookup"><span data-stu-id="41f17-225">Follow the steps described there to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="41f17-226">Дополнительная информация</span><span class="sxs-lookup"><span data-stu-id="41f17-226">Next steps</span></span>

<span data-ttu-id="41f17-227">Результатом применения этой архитектуры станет обученная модель, сохраненная в хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="41f17-227">The output from this architecture is a trained model that is saved to blob storage.</span></span> <span data-ttu-id="41f17-228">Вы можете ввести эту модель в эксплуатацию, чтобы выполнять оценку в реальном времени или в пакетном режиме.</span><span class="sxs-lookup"><span data-stu-id="41f17-228">You can operationalize this model for either real-time scoring or batch scoring.</span></span> <span data-ttu-id="41f17-229">Дополнительные сведения см. в следующих описаниях эталонных архитектур:</span><span class="sxs-lookup"><span data-stu-id="41f17-229">For more information, see the following reference architectures:</span></span>

- <span data-ttu-id="41f17-230">[Оценка в реальном времени моделей Python scikit-learn и глубокого обучения в Azure][real-time-scoring].</span><span class="sxs-lookup"><span data-stu-id="41f17-230">[Real-time scoring of Python Scikit-Learn and deep learning models on Azure][real-time-scoring]</span></span>
- <span data-ttu-id="41f17-231">[Пакетная оценка для моделей глубокого обучения в Azure][batch-scoring].</span><span class="sxs-lookup"><span data-stu-id="41f17-231">[Batch scoring on Azure for deep learning models][batch-scoring]</span></span>

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning