---
title: Распределенное обучение моделей глубокого обучения в Azure
description: В этой эталонной архитектуре демонстрируется выполнение распределенного обучения для моделей глубокого обучения в кластерах виртуальных машин с поддержкой GPU с применением Azure Batch AI.
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 800defeb851f5a31dc730038c3699e1a3d54b923
ms.sourcegitcommit: d5ea427c25f9f7799cc859b99f328739ca2d8c1c
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/15/2019
ms.locfileid: "54307805"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a>Распределенное обучение моделей глубокого обучения в Azure

В этой эталонной архитектуре демонстрируется выполнение распределенного обучения для моделей глубокого обучения в кластерах виртуальных машин с поддержкой графических процессоров (GPU). За основу взят сценарий классификации изображений, но это решение можно адаптировать к любым сценариям глубокого обучения, таким как сегментация и обнаружение объектов.

Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github].

![Архитектура для распределенного глубокого обучения][0]

**Сценарий**. Классификация изображений — это широко распространенная в отрасли компьютерного зрения задача, для решения которой часто применяется обучение сверточной нейронной сети (CNN). Для особо крупных моделей с большими наборами данных процесс такого обучения на одном GPU может занять несколько недель или даже месяцев. Иногда модели бывают настолько большими, что не позволяют создать пакет приемлемого размера для выполнения на одном GPU. В таких ситуациях распределенное обучение позволяет сократить время обучения.

В нашем примере выполняется обучение [модели сверточной нейронной сети ResNet50][resnet] с использованием [Horovod][horovod] на основе [набора данных ImageNet][imagenet] и искусственных данных. Эталонная реализация демонстрирует, как выполнить эту задачу с помощью трех наиболее популярных платформ машинного обучения: TensorFlow, Keras и PyTorch.

Существует несколько способов для обучения модели глубокого обучения в распределенном режиме. В них может применяться параллельная обработка по данным или по моделям с синхронным или асинхронным обновлением. Сейчас самой популярной считается параллельная обработка по данным с синхронным обновлением. Это самый простой в реализации подход, и его вполне достаточно для большинства вариантов использования.

Когда применяется распределенное обучение с параллельной обработкой по данным и синхронным обновлением, модель реплицируется на *n* аппаратных устройств. Мини-пакет образцов для обучения также разделяется на *n* микропакетов. Затем каждое устройство выполняет прямые и обратные проходы по этим микропакетам. Завершив процесс, устройство передает обновления на другие устройства. Полученные значения используются для обновления весовых коэффициентов для всего мини-пакета с синхронизацией этих коэффициентов между всеми моделями. Этот сценарий представлен в репозитории [GitHub][github].

![Распределенное обучение с параллельной обработкой по данным][1]

Эту же архитектуру можно применить для параллельной обработки по моделям и асинхронных обновлений. Если распределенное обучение выполняется с параллельной обработкой по моделям, модель разделяется между *n* аппаратными устройствами, каждому из которых достается определенная часть модели. В простейшей реализации каждое устройство содержит слой сети, а данные передаются между устройствами при каждом прямом и обратном проходе. Так можно обучать даже большие нейронные сети, но эффективность работы при этом снижается, так как устройства постоянно ожидают друг друга на каждом прямом и обратном проходе. Существуют дополнительные технологии, позволяющие частично устранить эту проблему с помощью искусственных градиентов.

Ниже описана процедура обучения.

1. Создайте скрипты, которые будут выполняться в кластере для обучения модели, и передайте их в хранилище файлов.

1. Сохраните данные в хранилище BLOB-объектов.

1. Создайте файловый сервер Batch AI и скачайте на него данные из хранилища BLOB-объектов.

1. Создайте контейнеры Docker для каждой платформы глубокого обучения и передайте их в реестр контейнеров (Docker Hub).

1. Создайте пул Batch AI, к которому также будет подключен файловый сервер Batch AI.

1. отправки заданий; Каждое задание извлекает соответствующий образ Docker и скрипты.

1. Результаты выполненного задания записываются в хранилище файлов.

## <a name="architecture"></a>Архитектура

Архитектура состоит из следующих компонентов.

**[Azure Batch AI][batch-ai]** играет центральную роль в этой архитектуре и масштабирует ресурсы в соответствии с потребностями. Служба Batch AI используется для подготовки кластеров виртуальных машин и управления ими, планирования заданий, сбора результатов, масштабирования ресурсов, обработки ошибок и создания соответствующего хранилища. Она позволяет использовать виртуальные машины с поддержкой GPU для рабочих нагрузок глубокого обучения. Для работы с Batch AI предоставляются пакет SDK для Python и интерфейс командной строки (CLI).

> [!NOTE]
> В марте 2019 г. служба Batch AI будет выведена из эксплуатации, и с этого момента все возможности масштабируемого обучения и оценки будут доступны только в [Службе машинного обучения Azure][amls]. В ближайшее время в эту эталонную архитектуру будут внесены обновления в связи с переходом на решение "Машинное обучение". Для обучения, развертывания и оценки моделей машинного обучения в нем предоставляется управляемый целевой объект вычислений, который называется [Вычислительная среда Машинного обучения Azure][aml-compute].

Для размещения данных используется **[хранилище BLOB-объектов][azure-blob]**. Эти данные в процессе обучения скачиваются на файловый сервер Batch AI.

Для хранения скриптов, журналов и окончательных результатов обучения используется служба **[Файлы Azure][files]**. Хранилище файлов хорошо подходит для хранения журналов и скриптов, но не обеспечивает такую же производительность, как хранилище BLOB-объектов, поэтому его не стоит использовать для ресурсоемких задач.

В этой архитектуре для хранения учебных данных применяется **[файловый сервер Batch AI][batch-ai-files]**, который представляет собой общую папку NFS, размещенную на одном узле. Служба Batch AI создает общую папку NFS и подключает ее к кластеру. Мы рекомендуем использовать файловые серверы Batch AI для предоставления данных в кластере с достаточной пропускной способностью.

Для хранения образа Docker, который Batch AI применяет при выполнении обучения, используется **[Docker Hub][docker]**. Центр Docker выбран для этой архитектуры, так как он прост в использовании и является репозиторием образов по умолчанию для пользователей Docker. [Реестр контейнеров Azure][acr] также можно использовать.

## <a name="performance-considerations"></a>Рекомендации по производительности

Azure предоставляет четыре [типа виртуальных машин с поддержкой GPU][gpu], пригодных для обучения моделей глубокого обучения. Эти варианты перечислены ниже в порядке увеличения цены и скорости работы.

| **Серия виртуальных машин Azure** | **GPU NVIDIA** |
|---------------------|----------------|
| NC                  | K80            |
| ND                  | P40            |
| NCv2                | P100           |
| NCv3                | V100           |

Для задач обучения мы рекомендуем сначала применять вертикальное масштабирование, а только после этого — горизонтальное. Например, сначала лучше использовать один процессор V100, чем кластер из нескольких процессоров K80.

На приведенной ниже диаграмме показаны различия в производительности между разными типами GPU по результатам [тестов производительности][benchmark], которые выполнялись с помощью TensorFlow и Horovod в Batch AI. На этой диаграмме представлена пропускная способность кластеров из 32 GPU для нескольких разных моделей, разных типов GPU и версий MPI. Все модели были реализованы в TensorFlow версии 1.9.

![Данные о пропускной способности для моделей TensorFlow в кластерах GPU][2]

Все серии виртуальных машин из приведенной выше таблицы включают конфигурацию с InfiniBand. При выполнении распределенного обучения эти конфигурации InfiniBand позволяют ускорить обмен данными между узлами. Также InfiniBand повышает эффективность масштабирования для обучения на тех платформах, которые поддерживают эту технологию. Дополнительные сведения см. в [сравнительном анализе тестов][benchmark] для Infiniband.

Azure Batch AI умеет подключать хранилище BLOB-объектов через адаптер [blobfuse][blobfuse], но мы не рекомендуем применять хранилище BLOB-объектов при распределенном обучении таким образом, так как оно не имеет достаточной производительности для обработки требуемой пропускной способности. Лучше поместите данные на файловый сервер Batch AI, как показано на схеме архитектуры.

## <a name="scalability-considerations"></a>Вопросы масштабируемости

Эффективность масштабирования при распределенном обучении всегда далека от 100 % из-за значительных издержек на сетевое взаимодействие. Узким местом становится синхронизация всей модели между устройствами. Это означает, что распределенное обучение лучше всего подходит для больших моделей, для обучения которых на одном GPU невозможно применить пакет приемлемого размера, а также для таких проблем, для решения которых недостаточно простого параллельного распределения модели.

Мы не рекомендуем применять распределенное обучение для поиска гиперпараметров. Эффективность масштабирования влияет на производительность и снижает эффективность распределенного подхода по сравнению с раздельным обучением нескольких конфигураций модели.

Для повышения эффективности масштабирования можно увеличить размер пакета. Но соблюдайте при этом осторожность, ведь увеличение размера пакета без корректировки других параметров может значительно снизить итоговую производительность модели.

## <a name="storage-considerations"></a>Рекомендации по работе с хранилищем

При обучении моделей глубокого обучения часто упускают из виду такой аспект, как расположение для хранения данных. Если скорость работы хранилища не соответствует требованиям GPU, эффективность обучения будет снижаться.

Batch AI поддерживает различные решения для хранения данных. В нашей архитектуре используется файловый сервер Batch AI, который обеспечивает оптимальный баланс между простотой использования и производительностью. Для максимальной производительности загружайте данные локально. Но иногда это очень неудобно, так как данные из хранилища BLOB-объектов нужно скачать на все узлы, а этот процесс для набора данных ImageNet занимает несколько часов. Еще один неплохой вариант — [хранилище BLOB-объектов Azure ценовой категории "Премиум"][blob] (ограниченная общедоступная предварительная версия).

Не используйте хранилище BLOB-объектов и хранилище файлов в качестве хранилища данных для распределенного обучения. Они работают слишком медленно, что снизит производительность обучения.

## <a name="security-considerations"></a>Вопросы безопасности

### <a name="restrict-access-to-azure-blob-storage"></a>Ограничение доступа к хранилищу BLOB-объектов Azure

В этой архитектуре для доступа к хранилищу BLOB-объектов используются [ключи учетной записи хранения][security-guide]. Для дальнейшего управления и защиты рекомендуется использовать подписанный URL-адрес (SAS). Таким образом можно предоставить ограниченный доступ к объектам в хранилище без необходимости жесткого кодирования ключей учетной записи или сохранения их в виде открытого текста. Использование SAS также гарантирует, что в учетной записи хранения обеспечено надлежащее управление, а доступ предоставляется только пользователям, которым он необходим.

Для сценариев с более конфиденциальными данными убедитесь, что все ключи к хранилищу защищены, так как эти ключи предоставляют полный доступ всем входным и выходным данным из рабочей нагрузки.

### <a name="encrypt-data-at-rest-and-in-motion"></a>Шифрование данных во время хранения и передачи

В сценариях с использованием конфиденциальных данных следует шифровать все неактивные (размещенные в хранилище) данные. При любых перемещениях данных из одного расположения в другое используйте SSL для безопасной передачи данных. Дополнительные сведения см. в [руководстве по безопасности службы хранилища Azure][security-guide].

### <a name="secure-data-in-a-virtual-network"></a>Защита данных в виртуальной сети

Для развертываний в рабочей среде следует развернуть кластер Batch AI в выбранной вами подсети виртуальной сети. Это позволит вычислительным узлам в кластере безопасно обмениваться данными с другими виртуальными машинами или с локальной сетью. Можно также использовать [конечные точки службы][endpoints] с хранилищем BLOB-объектов, чтобы предоставить доступ из виртуальной сети, или NFS с одним узлом внутри виртуальной сети, где размещена служба Batch AI.

## <a name="monitoring-considerations"></a>Рекомендации по мониторингу

Во время выполнения задания, важно отслеживать ход выполнения и убедиться, что все работает должным образом. Тем не менее, сложно отслеживать кластер активных узлов.

Файловыми серверами Batch AI можно управлять с помощью портала Azure, [Azure CLI][cli] или пакета SDK для Python. Чтобы получить представление об общем состоянии кластера, перейдите к разделу **Batch AI** на портале Azure, чтобы проверить состояние узлов в кластере. Если узел неактивен или произошел сбой задания, журналы ошибок сохраняются в хранилище BLOB-объектов, а также в разделе **Задания** на портале Azure.

Возможности мониторинга можно расширить, подключив журналы к [Azure Application Insights][ai] или запустив отдельные процессы для сбора сведений о состоянии кластера Batch AI и его заданий.

Batch AI автоматически сохраняет все выходные данные stdout и stderr в связанной учетной записи хранения больших двоичных объектов. Средства навигации в хранилище, например [Обозреватель службы хранилища Azure][storage-explorer], упрощают навигацию по файлам журналов.

Также вы можете настроить потоковую передачу журналов для каждого задания. Дополнительные сведения об этом варианте вы найдете в описании этапов разработки на сайте [GitHub][github].

## <a name="deployment"></a>Развертывание

Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github]. Описанные здесь шаги позволяют выполнить распределенное обучение моделей глубокого обучения в кластерах виртуальных машин с поддержкой GPU.

## <a name="next-steps"></a>Дополнительная информация

Результатом применения этой архитектуры станет обученная модель, сохраненная в хранилище BLOB-объектов. Вы можете ввести эту модель в эксплуатацию, чтобы выполнять оценку в реальном времени или в пакетном режиме. Дополнительные сведения см. в следующих описаниях эталонных архитектур:

- [Оценка в реальном времени моделей Python scikit-learn и глубокого обучения в Azure][real-time-scoring].
- [Пакетная оценка для моделей глубокого обучения в Azure][batch-scoring].

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning