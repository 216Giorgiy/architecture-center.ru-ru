---
title: Пакетная оценка моделей Spark в Azure Databricks
description: Создайте масштабируемое решение для пакетной оценки моделей классификации Apache Spark по расписанию с использованием Azure Databricks.
author: njray
ms.date: 02/07/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: cba8d272ddbdbf2c2da94f68b288e9fb79be7de2
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887817"
---
# <a name="batch-scoring-of-spark-machine-learning-models-on-azure-databricks"></a>Пакетная оценка моделей машинного обучения Spark в Azure Databricks

Эта эталонная архитектура позволяет создать масштабируемое решение для пакетной оценки модели классификации Apache Spark по расписанию с помощью Azure Databricks, оптимизированной для Azure аналитической платформы на основе Apache Spark. Вы можете использовать это решение в качестве шаблона, применимого и к другим сценариям.

Ссылку на реализацию этой архитектуры можно найти на сайте  [GitHub][github].

![Пакетная оценка моделей Spark в Azure Databricks](./_images/batch-scoring-spark.png)

**Сценарий**. Предприятие из отрасли, требующей интенсивного использования ресурсов, намерено сократить расходы и время простоя в связи с непредвиденными физическими сбоями. Используя данные Интернета, полученные со своих компьютеров, они могут создавать модели прогнозного обслуживания. Эта модель позволит организации обслуживать и ремонтировать компоненты до того, как они выйдут из строя. Повысив эффективность использования физических компонентов, они смогут снизить расходы и сократить время простоя.

Модель прогнозного обслуживания собирает данные с компьютеров и сохраняет зарегистрированные данные о сбоях компонентов. Эту модель затем можно применить для отслеживания текущего состояния компонентов и прогнозировать на ее основе вероятность сбоя компонентов в ближайшем будущем. Распространенные варианты использования и подходы к моделированию см. в [руководстве по использованию Azure ИИ для создания решений прогнозного обслуживания][ai-guide].

Эта эталонная архитектура предназначена для рабочих нагрузок, которые активируются при получении новых данных от физических компонентов. Обработка предусматривает указанные ниже действия.

1. Прием данных из внешнего хранилища данных в хранилище данных Azure Databricks.

2. Обучение модели машинного обучения путем преобразования данных в обучающий набор данных с последующим созданием модели Spark MLlib. MLlib содержит распространенные алгоритмы машинного обучения и служебные программы, оптимизированные для использования поддерживаемых в Spark возможностей масштабируемости данных.

3. Применение обученной модели для прогнозирования (классификация) сбоев компонентов путем преобразования данных в оценочный набор данных. Оценка данных с помощью модели Spark MLLib.

4. Сохранение результатов в хранилище данных Databricks для использования после обработки.

Для каждой из этих задач на  [GitHub][github] доступны готовые записные книжки.

## <a name="architecture"></a>Архитектура

Архитектура определяет поток данных, который полностью содержится в [Azure Databricks][databricks] на основе набора последовательно выполняемых [записных книжек][notebooks]. Она содержит следующие компоненты.

**[Файлы данных][github]**. Эталонная реализация использует имитированный набор данных, содержащийся в пяти файлах статических данных.

**[Прием][notebooks]**. Записная книжка для приема данных скачивает входные файлы данных в коллекцию наборов данных Databricks. В реальном сценарии поток данных с устройств Интернета вещей будет поступать в хранилище, доступное для Databricks, например экземпляр Azure SQL Server или хранилище BLOB-объектов Azure. Databricks поддерживает несколько [источников данных][data-sources].

**Конвейер обучения**. Эта записная книжка выполняет записную книжку проектирования признаков, чтобы на основе полученных данных создать набор аналитических данных. Затем выполняется записная книжка создания модели, которая обучает модель машинного обучения с помощью масштабируемой библиотеки машинного обучения [Apache Spark MLlib][mllib].

**Конвейер оценки**. Эта записная книжка выполняет записную книжку проектирования признаков, чтобы на основе полученных данных создать набор оценочных данных, и записную книжку оценки. Записная книжка оценки использует обученную модель [Spark MLlib][mllib-spark] для создания прогнозов для наблюдений в оценочном наборе данных. Эти прогнозы сохраняются в хранилище результатов, для которого создается новый набор данных в хранилище данных Databricks.

**Планировщик**. Запланированное [задание][job] Databricks выполняет оценку с использованием модели Spark в пакетном режиме. Это задание выполняет записную книжку конвейера оценки, передавая переменные аргументы через параметры записной книжки, а также предоставляя сведения для создания оценочного набора данных и определения расположения для хранения результирующего набора данных.

Этот сценарий реализован в виде последовательности конвейера. Каждая записная книжка оптимизирована для выполнения в пакетном режиме любой из операций: прием, проектирование признаков, создание модели и оценка модели. Для этой цели записная книжка проектирования признаков создает большой набор данных, который используется в любой из операций: обучение, калибровка, тестирование и оценка. В нашем примере для этих операций используется стратегия темпорального разбиения, то есть параметры записной книжки применяются для фильтрации по заданному диапазону дат.

Так как этот сценарий создает конвейер пакетного выполнения, мы предоставляем набор дополнительных записных книжек для просмотра выходных данных, возвращаемых записными книжками конвейера. Их можно найти в репозитории GitHub:

- `1a_raw-data_exploring`
- `2a_feature_exploration`
- `2b_model_testing`
- `3b_model_scoring_evaluation`

## <a name="recommendations"></a>Рекомендации

Платформа Databricks настроена так, чтобы можно было загружать и развертывать обученные модели для создания прогнозов с использованием новых данных. Мы использовали для этого примера Databricks из-за следующих дополнительных преимуществ:

- поддержка единого входа с использованием учетных данных Azure Active Directory;
- планировщик заданий для выполнения заданий рабочих конвейеров;
- полностью интерактивная записная книжка с поддержкой совместной работы, панелей мониторинга и интерфейсов REST API;
- неограниченное количество кластеров с возможностью масштабирования до любого размера;
- широкий набор средств безопасности, управление доступом на основе ролей и журналы аудита.

Для взаимодействия с платформой Azure Databricks откройте интерфейс [рабочей области][workspace] Databricks в браузере или [интерфейсе командной строки][cli] (CLI). Доступ к Databricks с помощью CLI возможен с любой платформы, которая поддерживает Python версий 2.7.9–3.6.

Эталонная реализация использует [записные книжки][notebooks] для последовательного выполнения задач. Каждая записная книжка сохраняет промежуточные артефакты данных (наборы данных для обучения, тестирования, оценки и итоговые результаты) в то же хранилище данных, где расположены входные данные. Это сделано для того, чтобы вам было проще применить эти данные для вашего варианта использования. На практике вы будете подключать источник данных к экземпляру Azure Databricks, чтобы записные книжки считывали данные непосредственно из хранилища и записывали в него результаты.

При желании вы можете отслеживать выполнение заданий с помощью пользовательского интерфейса Databricks, хранилища данных или Databricks [CLI][cli]. Для мониторинга кластера доступны [журнал событий][log] и другие [метрики][metrics], предлагаемые Databricks.

## <a name="performance-considerations"></a>Рекомендации по производительности

Кластер Azure Databricks по умолчанию применяет автоматическое масштабирование, то есть во время выполнения Databricks динамически перераспределяет рабочие роли с учетом характеристик конкретного задания. Возможно, некоторым частям конвейера потребуется больше вычислительных ресурсов, чем другим. Databricks добавляет во время этих этапов задания дополнительные рабочие роли, а затем удаляет их по мере необходимости. Автоматическое масштабирование позволяет максимизировать [использование кластера][cluster], ведь вам не придется подготавливать кластер в соответствии с рабочей нагрузкой.

Кроме того, [Фабрика данных Azure][adf] с Azure Databricks позволяет разрабатывать более сложные конвейеры с выполнением по расписанию.

## <a name="storage-considerations"></a>Рекомендации по работе с хранилищем

В этой эталонной реализации данные хранятся непосредственно в хранилище Databricks, чтобы упростить систему. Для реальной работы данные можно хранить в облачном хранилище данных, например [хранилище BLOB-объектов Azure][blob]. Также [Databricks][databricks-connect] поддерживает Azure Data Lake Store, Хранилище данных SQL Azure, Azure Cosmos DB, Apache Kafka и Hadoop.

## <a name="cost-considerations"></a>Рекомендации по стоимости

Azure Databricks — это предложение Spark ценовой категории "Премиум" с соответствующими ценами. Кроме того, существуют [ценовые категории][pricing] Databricks "Стандартный" и "Премиум".

Для нашего примера вполне достаточно ценовой категории "Стандартный". Но если для вашего приложения требуются автоматическое масштабирование кластеров для обработки больших рабочих нагрузок или интерактивные панели мониторинга Databricks, вам потребуется уровень "Премиум" с соответствующими ценами.

Записные книжки этого решения можно запустить на любой платформе на базе Spark с минимальными изменениями — нужно лишь удалить специализированные пакеты для Databricks. Вы можете изучить аналогичные решения для других платформ Azure.

- [Записная книжка Python для Студии машинного обучения Azure][python-aml]
- [Службы R в SQL Server][sql-r]
- [PySpark для Виртуальной машины для обработки и анализа данных в Azure][py-dvsm]

## <a name="deploy-the-solution"></a>Развертывание решения

Для развертывания этой эталонной архитектуры выполните действия, описанные в репозитории  [GitHub][github], чтобы создать масштабируемое решение для оценки моделей Spark в Azure Databricks в пакетном режиме.

## <a name="related-architectures"></a>Связанные архитектуры

Мы разработали эталонную архитектуру, которая использует Spark для создания [систем рекомендаций в режиме реального времени][recommendation] с автономными предварительно вычисленными оценками. Такие системы рекомендации — распространенный пример применения пакетной обработки для оценок.

[adf]: https://azure.microsoft.com/blog/operationalize-azure-databricks-notebooks-using-data-factory/
[ai-guide]: /azure/machine-learning/team-data-science-process/cortana-analytics-playbook-predictive-maintenance
[blob]: https://docs.databricks.com/spark/latest/data-sources/azure/azure-storage.html
[cli]: https://docs.databricks.com/user-guide/dev-tools/databricks-cli.html
[cluster]: https://docs.azuredatabricks.net/user-guide/clusters/sizing.html
[databricks]: /azure/azure-databricks/
[databricks-connect]: /azure/azure-databricks/databricks-connect-to-data-sources
[data-sources]: https://docs.databricks.com/spark/latest/data-sources/index.html
[github]: https://github.com/Azure/BatchSparkScoringPredictiveMaintenance
[job]: https://docs.databricks.com/user-guide/jobs.html
[log]: https://docs.databricks.com/user-guide/clusters/event-log.html
[metrics]: https://docs.databricks.com/user-guide/clusters/metrics.html
[mllib]: https://docs.databricks.com/spark/latest/mllib/index.html
[mllib-spark]: https://docs.databricks.com/spark/latest/mllib/index.html#apache-spark-mllib
[notebooks]: https://docs.databricks.com/user-guide/notebooks/index.html
[pricing]: https://azure.microsoft.com/en-us/pricing/details/databricks/
[python-aml]: https://gallery.azure.ai/Notebook/Predictive-Maintenance-Modelling-Guide-Python-Notebook-1
[py-dvsm]: https://gallery.azure.ai/Tutorial/Predictive-Maintenance-using-PySpark
[recommendation]: /azure/architecture/reference-architectures/ai/real-time-recommendation
[sql-r]: https://gallery.azure.ai/Tutorial/Predictive-Maintenance-Modeling-Guide-using-SQL-R-Services-1
[workspace]: https://docs.databricks.com/user-guide/workspace.html
