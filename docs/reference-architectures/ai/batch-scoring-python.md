---
title: Пакетная оценка моделей Python в Azure
description: Создайте масштабируемое решение для параллельной пакетной оценки моделей по расписанию, используя службу Машинного обучения Azure.
author: njray
ms.date: 01/30/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: b7607984bcf2c4bd046421aeb6e9d52dd8e7c18e
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887749"
---
# <a name="batch-scoring-of-python-machine-learning-models-on-azure"></a><span data-ttu-id="2c510-103">Пакетная оценка моделей машинного обучения Python в Azure</span><span class="sxs-lookup"><span data-stu-id="2c510-103">Batch scoring of Python machine learning models on Azure</span></span>

<span data-ttu-id="2c510-104">В этой эталонной архитектуре показано, как создать масштабируемое решение для параллельной пакетной оценки нескольких моделей по расписанию, используя службу Машинного обучения Azure.</span><span class="sxs-lookup"><span data-stu-id="2c510-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Machine Learning Service.</span></span> <span data-ttu-id="2c510-105">Это решение можно использовать как шаблон и подготовить к использованию для различных проблем.</span><span class="sxs-lookup"><span data-stu-id="2c510-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="2c510-106">Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="2c510-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Пакетная оценка моделей Python в Azure](./_images/batch-scoring-python.png)

<span data-ttu-id="2c510-108">**Сценарий**. Это решение отслеживает работу большого количества устройств в параметре Центра Интернета вещей, куда каждое устройство непрерывно отправляет показания датчиков.</span><span class="sxs-lookup"><span data-stu-id="2c510-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="2c510-109">Предполагается, что каждое устройство связано с предварительно обученными моделями обнаружения аномалий. Они необходимы для прогнозирования того, свидетельствует ли об аномалии серия измерений, агрегированных за предварительно заданный интервал времени.</span><span class="sxs-lookup"><span data-stu-id="2c510-109">Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="2c510-110">В реальных сценариях это может быть поток показаний датчика, который необходимо отфильтровать и агрегировать перед использованием в обучении или оценке в реальном времени.</span><span class="sxs-lookup"><span data-stu-id="2c510-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="2c510-111">Для простоты это решение использует тот же файл данных при выполнении заданий оценки.</span><span class="sxs-lookup"><span data-stu-id="2c510-111">For simplicity, this solution uses the same data file when executing scoring jobs.</span></span>

<span data-ttu-id="2c510-112">Эта эталонная архитектура предназначена для рабочих нагрузок, которые активируются по расписанию.</span><span class="sxs-lookup"><span data-stu-id="2c510-112">This reference architecture is designed for workloads that are triggered on a schedule.</span></span> <span data-ttu-id="2c510-113">Обработка предусматривает указанные ниже действия.</span><span class="sxs-lookup"><span data-stu-id="2c510-113">Processing involves the following steps:</span></span>
1.  <span data-ttu-id="2c510-114">Отправка показаний датчиков для приема в Центры событий Azure.</span><span class="sxs-lookup"><span data-stu-id="2c510-114">Send sensor readings for ingestion to Azure Event Hubs.</span></span>
2.  <span data-ttu-id="2c510-115">Потоковая обработка и сохранение необработанных данных.</span><span class="sxs-lookup"><span data-stu-id="2c510-115">Perform stream processing and store the raw data.</span></span>
3.  <span data-ttu-id="2c510-116">Отправка данных в кластер Машинного обучения, который подготовлен для работы.</span><span class="sxs-lookup"><span data-stu-id="2c510-116">Send the data to a Machine Learning cluster that is ready to start taking work.</span></span> <span data-ttu-id="2c510-117">Каждый узел в кластере выполняет задание оценки для определенного датчика.</span><span class="sxs-lookup"><span data-stu-id="2c510-117">Each node in the cluster runs a scoring job for a specific sensor.</span></span> 
4.  <span data-ttu-id="2c510-118">Выполнение конвейера оценки, выполняющего задания оценки в параллельном режиме, с помощью скриптов Python для Машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="2c510-118">Execute the scoring pipeline, which runs the scoring jobs in parallel using Machine Learning Python scripts.</span></span> <span data-ttu-id="2c510-119">Конвейер создается, публикуется и планируется к выполнению в течение определенного интервала времени.</span><span class="sxs-lookup"><span data-stu-id="2c510-119">The pipeline is created, published, and scheduled to run on a predefined interval of time.</span></span>
5.  <span data-ttu-id="2c510-120">Создание прогнозов и их сохранение в хранилище BLOB-объектов для последующего использования.</span><span class="sxs-lookup"><span data-stu-id="2c510-120">Generate predictions and store them in Blob storage for later consumption.</span></span>

## <a name="architecture"></a><span data-ttu-id="2c510-121">Архитектура</span><span class="sxs-lookup"><span data-stu-id="2c510-121">Architecture</span></span>

<span data-ttu-id="2c510-122">Эта архитектура состоит из следующих компонентов.</span><span class="sxs-lookup"><span data-stu-id="2c510-122">This architecture consists of the following components:</span></span>

<span data-ttu-id="2c510-123">[Центры событий Azure][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="2c510-123">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="2c510-124">Эта служба приема сообщений может принимать миллионы сообщений о событиях в секунду.</span><span class="sxs-lookup"><span data-stu-id="2c510-124">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="2c510-125">В этой архитектуре датчики передают поток данных в концентратор событий.</span><span class="sxs-lookup"><span data-stu-id="2c510-125">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="2c510-126">[Azure Stream Analytics][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="2c510-126">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="2c510-127">Подсистема обработки событий.</span><span class="sxs-lookup"><span data-stu-id="2c510-127">An event-processing engine.</span></span> <span data-ttu-id="2c510-128">Задание Stream Analytics считывает потоки данных из концентратора событий и обрабатывает их.</span><span class="sxs-lookup"><span data-stu-id="2c510-128">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="2c510-129">[База данных SQL Azure][sql-database].</span><span class="sxs-lookup"><span data-stu-id="2c510-129">[Azure SQL Database][sql-database].</span></span> <span data-ttu-id="2c510-130">Данные показаний датчиков загружаются в Базу данных SQL.</span><span class="sxs-lookup"><span data-stu-id="2c510-130">Data from the sensor readings is loaded into SQL Database.</span></span> <span data-ttu-id="2c510-131">SQL — это привычный способ хранения обработанных потоковых данных (в табличном и структурированном виде), который также позволяет использовать другие хранилища данных.</span><span class="sxs-lookup"><span data-stu-id="2c510-131">SQL is a familiar way to store the processed, streamed data (which is tabular and structured), but other data stores can be used.</span></span>

<span data-ttu-id="2c510-132">[Служба машинного обучения Azure][amls].</span><span class="sxs-lookup"><span data-stu-id="2c510-132">[Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="2c510-133">Машинное обучение — это облачная служба для обучения, оценки, развертывания и администрирования моделей машинного обучения в нужном масштабе.</span><span class="sxs-lookup"><span data-stu-id="2c510-133">Machine Learning is a cloud service for training, scoring, deploying, and managing machine learning models at scale.</span></span> <span data-ttu-id="2c510-134">Для пакетной оценки служба Машинного обучения Azure создает кластер виртуальных машин с возможностью автоматического масштабирования, в котором каждый узел выполняет задание оценки для определенного датчика.</span><span class="sxs-lookup"><span data-stu-id="2c510-134">In the context of batch scoring, Machine Learning creates a cluster of virtual machines on demand with an automatic scaling option, where each node in the cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="2c510-135">Задания оценки выполняются в параллельном режиме в виде действий скрипта Python, которые включаются в очередь и управляются службой Машинного обучения Azure.</span><span class="sxs-lookup"><span data-stu-id="2c510-135">The scoring jobs are executed in parallel as Python-script steps that are queued and managed by Machine Learning.</span></span> <span data-ttu-id="2c510-136">Эти действия являются частью конвейера Машинного обучения, который создается, публикуется и планируется к выполнению в течение определенного интервала времени.</span><span class="sxs-lookup"><span data-stu-id="2c510-136">These steps are part of a Machine Learning pipeline that is created, published, and scheduled to run on a predefined interval of time.</span></span>

<span data-ttu-id="2c510-137">[Хранилище BLOB-объектов Azure][storage].</span><span class="sxs-lookup"><span data-stu-id="2c510-137">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="2c510-138">Контейнеры BLOB-объектов используются для хранения предварительно обученных моделей, данных и результатов прогнозирования.</span><span class="sxs-lookup"><span data-stu-id="2c510-138">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="2c510-139">Модели загружаются в хранилище BLOB-объектов в записную книжку [01_create_resources.ipynb][create-resources].</span><span class="sxs-lookup"><span data-stu-id="2c510-139">The models are uploaded to Blob storage in the [01_create_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="2c510-140">Эти модели [одноклассового SVM][one-class-svm] обучаются на данных, которые представляют собой значения различных датчиков для различных устройств.</span><span class="sxs-lookup"><span data-stu-id="2c510-140">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="2c510-141">Это решение предполагает, что значения данных агрегируются за фиксированный интервал времени.</span><span class="sxs-lookup"><span data-stu-id="2c510-141">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="2c510-142">[Реестр контейнеров Azure][acr].</span><span class="sxs-lookup"><span data-stu-id="2c510-142">[Azure Container Registry][acr].</span></span> <span data-ttu-id="2c510-143">[Скрипт][pyscript] оценки Python выполняется в контейнерах Docker, создаваемых на каждом узле кластера, в котором он считывает данные соответствующих датчиков, создает прогнозы и сохраняет их в хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="2c510-143">The scoring Python [script][pyscript] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="2c510-144">Рекомендации по производительности</span><span class="sxs-lookup"><span data-stu-id="2c510-144">Performance considerations</span></span>

<span data-ttu-id="2c510-145">Принято считать, что для обработки рабочей нагрузки стандартных моделей Python достаточно обычных ЦП.</span><span class="sxs-lookup"><span data-stu-id="2c510-145">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="2c510-146">Эта архитектура использует ЦП.</span><span class="sxs-lookup"><span data-stu-id="2c510-146">This architecture uses CPUs.</span></span> <span data-ttu-id="2c510-147">Однако для [рабочие нагрузки глубокого обучения][deep], GPU обычно более эффективны, чем ЦП, значительное &mdash; изменяемого размера кластера ЦП обычно требуется, чтобы получить сравнимую производительность.</span><span class="sxs-lookup"><span data-stu-id="2c510-147">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount &mdash; a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-versus-cores"></a><span data-ttu-id="2c510-148">Параллелизации между виртуальными машинами и ядер</span><span class="sxs-lookup"><span data-stu-id="2c510-148">Parallelizing across VMs versus cores</span></span>

<span data-ttu-id="2c510-149">При выполнении процессов оценки многих моделей в пакетном режиме задания должны быть распараллелены между виртуальными машинами.</span><span class="sxs-lookup"><span data-stu-id="2c510-149">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="2c510-150">Возможны два подхода:</span><span class="sxs-lookup"><span data-stu-id="2c510-150">Two approaches are possible:</span></span>

* <span data-ttu-id="2c510-151">Создайте большой кластер, используя недорогие виртуальные машины.</span><span class="sxs-lookup"><span data-stu-id="2c510-151">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="2c510-152">Создайте маленький кластер, используя высокопроизводительные виртуальные машины с дополнительным количеством ядер, доступных в каждой.</span><span class="sxs-lookup"><span data-stu-id="2c510-152">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="2c510-153">В целом оценка стандартных моделей Python не так сложна, как оценка моделей глубокого обучения, и небольшой кластер должен быть способен эффективно обрабатывать большое количество моделей в очереди.</span><span class="sxs-lookup"><span data-stu-id="2c510-153">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="2c510-154">Вы можете увеличить количество узлов кластера по мере увеличения размеров набора данных.</span><span class="sxs-lookup"><span data-stu-id="2c510-154">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="2c510-155">Для удобства в этом сценарии отправляется одно задние оценки в рамках выполнения одного этапа конвейера Машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="2c510-155">For convenience in this scenario, one scoring task is submitted within a single Machine Learning pipeline step.</span></span> <span data-ttu-id="2c510-156">Но более целесообразной была бы оценка нескольких блоков данных в ходе одного этапа конвейера.</span><span class="sxs-lookup"><span data-stu-id="2c510-156">However, it can be more efficient to score multiple data chunks within the same pipeline step.</span></span> <span data-ttu-id="2c510-157">Для таких случаев необходимо написать пользовательский код для чтения нескольких наборов данных и выполнения для них скрипта оценки в ходе выполнения одного этапа конвейера.</span><span class="sxs-lookup"><span data-stu-id="2c510-157">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single-step execution.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="2c510-158">Рекомендации по управлению</span><span class="sxs-lookup"><span data-stu-id="2c510-158">Management considerations</span></span>

- <span data-ttu-id="2c510-159">**Мониторинг заданий**.</span><span class="sxs-lookup"><span data-stu-id="2c510-159">**Monitor jobs**.</span></span> <span data-ttu-id="2c510-160">Важно следить за ходом выполнения заданий, но это может быть проблемой для мониторинга в кластере активных узлов.</span><span class="sxs-lookup"><span data-stu-id="2c510-160">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="2c510-161">Чтобы проверить состояние узлов в кластере, используйте [портал Azure][portal] для управления [рабочей областью машинного обучения][ml-workspace].</span><span class="sxs-lookup"><span data-stu-id="2c510-161">To inspect the state of the nodes in the cluster, use the [Azure Portal][portal] to manage the [machine learning workspace][ml-workspace].</span></span> <span data-ttu-id="2c510-162">Если узел неактивен или произошел сбой задания, журналы ошибок будут сохранены в хранилище BLOB-объектов и также будут доступными в разделе конвейеров.</span><span class="sxs-lookup"><span data-stu-id="2c510-162">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Pipelines section.</span></span> <span data-ttu-id="2c510-163">Для оптимизации мониторинга подключите журналы к [Application Insights][app-insights] или запустите отдельные процессы для опроса состояния кластера и его заданий.</span><span class="sxs-lookup"><span data-stu-id="2c510-163">For richer monitoring, connect logs to [Application Insights][app-insights], or run separate processes to poll for the state of the cluster and its jobs.</span></span>
-   <span data-ttu-id="2c510-164">**Ведение журналов.**</span><span class="sxs-lookup"><span data-stu-id="2c510-164">**Logging**.</span></span> <span data-ttu-id="2c510-165">Служба Машинного обучения автоматически регистрирует в журнале все потоки stdout и stderr в соответствующей учетной записи службы хранилища Azure.</span><span class="sxs-lookup"><span data-stu-id="2c510-165">Machine Learning Service logs all stdout/stderr to the associated Azure Storage account.</span></span> <span data-ttu-id="2c510-166">С помощью средств навигации, например [Обозревателя службы хранилища Azure][explorer], можно удобно просматривать файлы журнала.</span><span class="sxs-lookup"><span data-stu-id="2c510-166">To easily view the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="2c510-167">Рекомендации по стоимости</span><span class="sxs-lookup"><span data-stu-id="2c510-167">Cost considerations</span></span>

<span data-ttu-id="2c510-168">Самые дорогие компоненты, используемые в этой эталонной архитектуре, – вычислительные ресурсы.</span><span class="sxs-lookup"><span data-stu-id="2c510-168">The most expensive components used in this reference architecture are the compute resources.</span></span> <span data-ttu-id="2c510-169">Вычислительный кластер можно масштабировать в зависимости от заданий в очереди.</span><span class="sxs-lookup"><span data-stu-id="2c510-169">The compute cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="2c510-170">Включите автоматическое масштабирование программным способом с помощью пакета SDK для Python, изменив конфигурацию подготовки вычислений.</span><span class="sxs-lookup"><span data-stu-id="2c510-170">Enable automatic scaling programmatically through the Python SDK by modifying the compute’s provisioning configuration.</span></span> <span data-ttu-id="2c510-171">Или используйте [Azure CLI][cli] для установки параметров автоматического масштабирования кластера.</span><span class="sxs-lookup"><span data-stu-id="2c510-171">Or use the [Azure CLI][cli] to set the automatic scaling parameters of the cluster.</span></span>

<span data-ttu-id="2c510-172">Для работы, которая не требует немедленной обработки, настройте формулу автоматического масштабирования, чтобы состояние по умолчанию (минимальное) было кластером нулевых узлов.</span><span class="sxs-lookup"><span data-stu-id="2c510-172">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="2c510-173">При использовании этой конфигурации кластер запускается с нулевых узлов и масштабируется только при обнаружении заданий в очереди.</span><span class="sxs-lookup"><span data-stu-id="2c510-173">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="2c510-174">Если процесс пакетной оценки происходит несколько раз в день или реже, этот параметр позволяет значительно сократить затраты.</span><span class="sxs-lookup"><span data-stu-id="2c510-174">If the batch scoring process happens only a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="2c510-175">Автоматическое масштабирование может не подойти для пакетных заданий, которые происходят слишком близко друг к другу.</span><span class="sxs-lookup"><span data-stu-id="2c510-175">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="2c510-176">За время, необходимое на развертывание кластера и его отключение, также начисляется плата. Поэтому, если пакетная рабочая нагрузка запускается через несколько минут после окончания предыдущего задания, было бы экономически целесообразно не отключать кластер между заданиями.</span><span class="sxs-lookup"><span data-stu-id="2c510-176">The time that it takes for a cluster to spin up and spin down also incurs a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="2c510-177">Это зависит от того, запланированы ли процессы оценки с высокой частотой (например, каждый час) или реже (например, раз в месяц).</span><span class="sxs-lookup"><span data-stu-id="2c510-177">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>


## <a name="deployment"></a><span data-ttu-id="2c510-178">Развертывание</span><span class="sxs-lookup"><span data-stu-id="2c510-178">Deployment</span></span>

<span data-ttu-id="2c510-179">Для развертывания этой эталонной архитектуры, выполните действия, описанные в [репозитории GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="2c510-179">To deploy this reference architecture, follow the steps described in the [GitHub repo][github].</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[cli]: /cli/azure
[create-resources]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Microsoft/AMLBatchScoringPipeline
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[ml-workspace]: /azure/machine-learning/studio/create-workspace
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[pyscript]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/scripts/predict.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
[sql-database]: /azure/sql-database/
[app-insights]: /azure/application-insights/app-insights-overview
