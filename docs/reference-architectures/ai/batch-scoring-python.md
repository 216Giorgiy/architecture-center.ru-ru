---
title: Пакетная оценка моделей Python в Azure
description: Создайте масштабируемое решение для параллельной пакетной оценки моделей по расписанию, используя Azure Batch AI.
author: njray
ms.date: 12/13/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: a291821860a8e503ba4c6173ac6d8fd449d6ebf3
ms.sourcegitcommit: 1b50810208354577b00e89e5c031b774b02736e2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/23/2019
ms.locfileid: "54485372"
---
# <a name="batch-scoring-of-python-models-on-azure"></a><span data-ttu-id="d1de2-103">Пакетная оценка моделей Python в Azure</span><span class="sxs-lookup"><span data-stu-id="d1de2-103">Batch scoring of Python models on Azure</span></span>

<span data-ttu-id="d1de2-104">В этой эталонной архитектуре показано, как создать масштабируемое решение для параллельной пакетной оценки многих моделей по расписанию, используя Azure Batch AI.</span><span class="sxs-lookup"><span data-stu-id="d1de2-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Batch AI.</span></span> <span data-ttu-id="d1de2-105">Это решение можно использовать как шаблон и подготовить к использованию для различных проблем.</span><span class="sxs-lookup"><span data-stu-id="d1de2-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="d1de2-106">Ссылку на реализацию этой архитектуры можно найти на сайте  [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="d1de2-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Пакетная оценка моделей Python в Azure](./_images/batch-scoring-python.png)

<span data-ttu-id="d1de2-108">**Сценарий**. Это решение отслеживает работу большого количества устройств в параметре Центра Интернета вещей, куда каждое устройство непрерывно отправляет показания датчиков.</span><span class="sxs-lookup"><span data-stu-id="d1de2-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="d1de2-109">Предполагается, что каждое устройство имеет предварительно обученные модели обнаружения аномалий, которые необходимо использовать, чтобы спрогнозировать, соответствует ли серия измерений, которые агрегированы за предварительно определенный интервал времени, аномалии или нет.</span><span class="sxs-lookup"><span data-stu-id="d1de2-109">Each device is assumed to have pre-trained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="d1de2-110">В реальных сценариях это может быть поток показаний датчика, который необходимо отфильтровать и агрегировать перед использованием в обучении или оценке в реальном времени.</span><span class="sxs-lookup"><span data-stu-id="d1de2-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="d1de2-111">Для упрощения решение использует тот же файл данных при выполнении оценки заданий.</span><span class="sxs-lookup"><span data-stu-id="d1de2-111">For simplicity, the solution uses the same data file when executing scoring jobs.</span></span>

## <a name="architecture"></a><span data-ttu-id="d1de2-112">Архитектура</span><span class="sxs-lookup"><span data-stu-id="d1de2-112">Architecture</span></span>

<span data-ttu-id="d1de2-113">Эта архитектура состоит из следующих компонентов.</span><span class="sxs-lookup"><span data-stu-id="d1de2-113">This architecture consists of the following components:</span></span>

<span data-ttu-id="d1de2-114">[Центры событий Azure][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="d1de2-114">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="d1de2-115">Эта служба приема сообщений может принимать миллионы сообщений о событиях в секунду.</span><span class="sxs-lookup"><span data-stu-id="d1de2-115">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="d1de2-116">В этой архитектуре датчики передают поток данных в концентратор событий.</span><span class="sxs-lookup"><span data-stu-id="d1de2-116">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="d1de2-117">[Azure Stream Analytics][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="d1de2-117">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="d1de2-118">Подсистема обработки событий.</span><span class="sxs-lookup"><span data-stu-id="d1de2-118">An event-processing engine.</span></span> <span data-ttu-id="d1de2-119">Задание Stream Analytics считывает потоки данных из концентратора событий и обрабатывает их.</span><span class="sxs-lookup"><span data-stu-id="d1de2-119">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="d1de2-120">[Azure Batch AI][batch-ai].</span><span class="sxs-lookup"><span data-stu-id="d1de2-120">[Azure Batch AI][batch-ai].</span></span> <span data-ttu-id="d1de2-121">Эта подсистема распределенных вычислений используется для обучения и тестирования машинного обучения и моделей ИИ, свернутых в Azure.</span><span class="sxs-lookup"><span data-stu-id="d1de2-121">This distributed computing engine is used to train and test machine learning and AI models at scale in Azure.</span></span> <span data-ttu-id="d1de2-122">Azure Batch AI по запросу создает виртуальные машины с возможностью автоматического масштабирования, где каждый узел в кластере Batch AI выполняет оценку задания для определенного датчика.</span><span class="sxs-lookup"><span data-stu-id="d1de2-122">Batch AI creates virtual machines on demand with an automatic scaling option, where each node in the Batch AI cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="d1de2-123">Оценка  [скрипта][python-script] Python выполняется в контейнерах Docker, созданных на каждом узле кластера, в котором считываются данные соответствующих датчиков, создаются прогнозирования, а их результаты сохраняются в хранилище BLOB-объектов.</span><span class="sxs-lookup"><span data-stu-id="d1de2-123">The scoring Python [script][python-script] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

<span data-ttu-id="d1de2-124">[Хранилище BLOB-объектов Azure][storage].</span><span class="sxs-lookup"><span data-stu-id="d1de2-124">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="d1de2-125">Контейнеры BLOB-объектов используются для хранения предварительно обученных моделей, данных и результатов прогнозирования.</span><span class="sxs-lookup"><span data-stu-id="d1de2-125">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="d1de2-126">Модели загружаются в хранилище BLOB-объектов в записную книжку [создать\_ресурсы.ipynb][create-resources].</span><span class="sxs-lookup"><span data-stu-id="d1de2-126">The models are uploaded to Blob storage in the [create\_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="d1de2-127">Эти модели [одноклассового SVM][one-class-svm] обучаются на данных, которые представляют собой значения различных датчиков для различных устройств.</span><span class="sxs-lookup"><span data-stu-id="d1de2-127">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="d1de2-128">Это решение предполагает, что значения данных агрегируются за фиксированный интервал времени.</span><span class="sxs-lookup"><span data-stu-id="d1de2-128">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="d1de2-129">[Azure Logic Apps][logic-apps].</span><span class="sxs-lookup"><span data-stu-id="d1de2-129">[Azure Logic Apps][logic-apps].</span></span> <span data-ttu-id="d1de2-130">Это решение создает приложение логики, которое выполняет почасовые задания Batch AI.</span><span class="sxs-lookup"><span data-stu-id="d1de2-130">This solution creates a Logic App that runs hourly Batch AI jobs.</span></span> <span data-ttu-id="d1de2-131">Logic Apps предоставляет простой способ создания среды выполнения рабочего процесса и планирования решения.</span><span class="sxs-lookup"><span data-stu-id="d1de2-131">Logic Apps provides an easy way to create the runtime workflow and scheduling for the solution.</span></span> <span data-ttu-id="d1de2-132">Задания Batch AI отправляются с использованием [скрипта][script] Python, который также выполняется в контейнере Docker.</span><span class="sxs-lookup"><span data-stu-id="d1de2-132">The Batch AI jobs are submitted using a Python [script][script] that also runs in a Docker container.</span></span>

<span data-ttu-id="d1de2-133">[Реестр контейнеров Azure][acr].</span><span class="sxs-lookup"><span data-stu-id="d1de2-133">[Azure Container Registry][acr].</span></span> <span data-ttu-id="d1de2-134">Образы Docker, которые используются как в Batch AI, так и в Logic Apps, создаются в записной книжке [создать\_резурсы.ipynb][create-resources], а затем помещаются в реестр контейнеров Azure.</span><span class="sxs-lookup"><span data-stu-id="d1de2-134">Docker images are used in both Batch AI and Logic Apps and are created in the [create\_resources.ipynb][create-resources] notebook, then pushed to Container Registry.</span></span> <span data-ttu-id="d1de2-135">Это удобный способ размещения образов и создания экземпляров контейнеров через другие службы Azure – в этом решении Logic Apps и Batch AI.</span><span class="sxs-lookup"><span data-stu-id="d1de2-135">This provides a convenient way to host images and instantiate containers through other Azure services—Logic Apps and Batch AI in this solution.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="d1de2-136">Рекомендации по производительности</span><span class="sxs-lookup"><span data-stu-id="d1de2-136">Performance considerations</span></span>

<span data-ttu-id="d1de2-137">Принято считать, что для обработки рабочей нагрузки стандартных моделей Python достаточно обычных ЦП.</span><span class="sxs-lookup"><span data-stu-id="d1de2-137">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="d1de2-138">Эта архитектура использует ЦП.</span><span class="sxs-lookup"><span data-stu-id="d1de2-138">This architecture uses CPUs.</span></span> <span data-ttu-id="d1de2-139">Однако для [нагрузок с глубоким обучением][deep] GPU выполняют работу намного лучше чем ЦП – для достижения сопоставимой производительности обычно требуется кластер ЦП изменяемого размера.</span><span class="sxs-lookup"><span data-stu-id="d1de2-139">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount—a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-vs-cores"></a><span data-ttu-id="d1de2-140">Распараллеливание между виртуальными машинами и ядрами</span><span class="sxs-lookup"><span data-stu-id="d1de2-140">Parallelizing across VMs vs cores</span></span>

<span data-ttu-id="d1de2-141">При выполнении процессов оценки многих моделей в пакетном режиме задания должны быть распараллелены между виртуальными машинами.</span><span class="sxs-lookup"><span data-stu-id="d1de2-141">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="d1de2-142">Возможны два подхода:</span><span class="sxs-lookup"><span data-stu-id="d1de2-142">Two approaches are possible:</span></span>

* <span data-ttu-id="d1de2-143">Создайте большой кластер, используя недорогие виртуальные машины.</span><span class="sxs-lookup"><span data-stu-id="d1de2-143">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="d1de2-144">Создайте маленький кластер, используя высокопроизводительные виртуальные машины с дополнительным количеством ядер, доступных в каждой.</span><span class="sxs-lookup"><span data-stu-id="d1de2-144">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="d1de2-145">В целом оценка стандартных моделей Python не так сложна, как оценка моделей глубокого обучения, и небольшой кластер должен быть способен эффективно обрабатывать большое количество моделей в очереди.</span><span class="sxs-lookup"><span data-stu-id="d1de2-145">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="d1de2-146">Вы можете увеличить количество узлов кластера по мере увеличения размеров набора данных.</span><span class="sxs-lookup"><span data-stu-id="d1de2-146">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="d1de2-147">Для удобства в этом сценарии в рамках одного задания Batch AI отправляется одна оценка задачи.</span><span class="sxs-lookup"><span data-stu-id="d1de2-147">For convenience in this scenario, one scoring task is submitted within a single Batch AI job.</span></span> <span data-ttu-id="d1de2-148">Однако оценка нескольких блоков данных в одном Batch AI может быть более эффективной.</span><span class="sxs-lookup"><span data-stu-id="d1de2-148">However, it can be more efficient to score multiple data chunks within the same Batch AI job.</span></span> <span data-ttu-id="d1de2-149">В этих случаях напишите пользовательский код для чтения в нескольких наборах данных и выполните для них скрипт оценки во время выполнения одного задания Batch AI.</span><span class="sxs-lookup"><span data-stu-id="d1de2-149">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single Batch AI job execution.</span></span>

### <a name="file-servers"></a><span data-ttu-id="d1de2-150">Файловые серверы</span><span class="sxs-lookup"><span data-stu-id="d1de2-150">File servers</span></span>

<span data-ttu-id="d1de2-151">При использовании Batch AI, можно выбрать несколько вариантов хранения, в зависимости от пропускной способности, необходимой для вашего сценария.</span><span class="sxs-lookup"><span data-stu-id="d1de2-151">When using Batch AI, you can choose multiple storage options depending on the throughput needed for your scenario.</span></span> <span data-ttu-id="d1de2-152">Для рабочих нагрузок с низкой пропускной способностью использование хранилища BLOB-объектов должно быть достаточно.</span><span class="sxs-lookup"><span data-stu-id="d1de2-152">For workloads with low throughput requirements, using blob storage should be enough.</span></span> <span data-ttu-id="d1de2-153">В качестве альтернативы Batch AI также поддерживает [Файловый сервер Batch AI][bai-file-server], управляемый одноузловой NFS, который может автоматически монтироваться на узлах кластера, чтобы обеспечить заданиям централизованный доступ к хранилищу.</span><span class="sxs-lookup"><span data-stu-id="d1de2-153">Alternatively, Batch AI also supports a [Batch AI File Server][bai-file-server], a managed, single-node NFS, which can be automatically mounted on cluster nodes to provide a centrally accessible storage location for jobs.</span></span> <span data-ttu-id="d1de2-154">В большинстве случаев требуется только один файловый сервер в рабочей области, и можно поместить данные для заданий обучения в разные каталоги.</span><span class="sxs-lookup"><span data-stu-id="d1de2-154">For most cases, only one file server is needed in a workspace, and you can separate data for your training jobs into different directories.</span></span>

<span data-ttu-id="d1de2-155">Если одноузловая NFS не подходит для рабочих нагрузок, Batch AI поддерживает другие варианты хранения, включая [файлы Azure][azure-files] и пользовательские решения, например, файловые системы Gluster или Lustre.</span><span class="sxs-lookup"><span data-stu-id="d1de2-155">If a single-node NFS isn't appropriate for your workloads, Batch AI supports other storage options, including [Azure Files][azure-files] and custom solutions such as a Gluster or Lustre file system.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="d1de2-156">Рекомендации по управлению</span><span class="sxs-lookup"><span data-stu-id="d1de2-156">Management considerations</span></span>

### <a name="monitoring-batch-ai-jobs"></a><span data-ttu-id="d1de2-157">Отслеживание заданий Batch AI</span><span class="sxs-lookup"><span data-stu-id="d1de2-157">Monitoring Batch AI jobs</span></span>

<span data-ttu-id="d1de2-158">Важно следить за ходом выполнения заданий, но это может быть проблемой для мониторинга в кластере активных узлов.</span><span class="sxs-lookup"><span data-stu-id="d1de2-158">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="d1de2-159">Чтобы получить представление об общем состояние кластера, перейдите к колонке **Batch AI** на [портале Azure][portal], чтобы проанализировать состояние узлов в кластере.</span><span class="sxs-lookup"><span data-stu-id="d1de2-159">To get a sense of the overall state of the cluster, go to the **Batch AI** blade of the [Azure Portal][portal] to inspect the state of the nodes in the cluster.</span></span> <span data-ttu-id="d1de2-160">Если узел неактивен или произошел сбой задания, журналы ошибок сохраняются в хранилище BLOB-объектов и также доступны в колонке **Задания** на портале.</span><span class="sxs-lookup"><span data-stu-id="d1de2-160">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the **Jobs** blade of the portal.</span></span>

<span data-ttu-id="d1de2-161">Для улучшения мониторинга подключите журналы к [Application Insights][ai] или запустите отдельные процессы для опроса о состоянии кластера и заданий Batch AI.</span><span class="sxs-lookup"><span data-stu-id="d1de2-161">For richer monitoring, connect logs to [Application Insights][ai], or run separate processes to poll for the state of the Batch AI cluster and its jobs.</span></span>

### <a name="logging-in-batch-ai"></a><span data-ttu-id="d1de2-162">Ведение журнала в Batch AI</span><span class="sxs-lookup"><span data-stu-id="d1de2-162">Logging in Batch AI</span></span>

<span data-ttu-id="d1de2-163">Batch AI регистрирует все StdOut или Stderr в учетную запись службы хранилища Azure.</span><span class="sxs-lookup"><span data-stu-id="d1de2-163">Batch AI logs all stdout/stderr to the associated Azure storage account.</span></span> <span data-ttu-id="d1de2-164">Для упрощения навигации по файлам журналов используйте инструмент навигации хранилища, например [Обозреватель службы хранилища Azure][explorer].</span><span class="sxs-lookup"><span data-stu-id="d1de2-164">For easy navigation of the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

<span data-ttu-id="d1de2-165">При развертывании этой эталонной архитектуры у вас есть возможность настроить упрощенную систему ведения журнала.</span><span class="sxs-lookup"><span data-stu-id="d1de2-165">When you deploy this reference architecture, you have the option to set up a simpler logging system.</span></span> <span data-ttu-id="d1de2-166">С помощью этого параметра все журналы в разных заданиях сохраняются в одном каталоге контейнера BLOB-объектов, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="d1de2-166">With this option, all the logs across the different jobs are saved to the same directory in your blob container as shown below.</span></span> <span data-ttu-id="d1de2-167">Используйте эти журналы, чтобы отслеживать, сколько времени занимает обработка каждого задания и каждого образа, чтобы вы лучше понимали, как оптимизировать процесс.</span><span class="sxs-lookup"><span data-stu-id="d1de2-167">Use these logs to monitor how long it takes for each job and each image to process, so you have a better sense of how to optimize the process.</span></span>

![обозреватель хранилищ Azure](./_images/batch-scoring-python-monitor.png)

## <a name="cost-considerations"></a><span data-ttu-id="d1de2-169">Рекомендации по стоимости</span><span class="sxs-lookup"><span data-stu-id="d1de2-169">Cost considerations</span></span>

<span data-ttu-id="d1de2-170">Самые дорогие компоненты, используемые в этой эталонной архитектуре, – вычислительные ресурсы.</span><span class="sxs-lookup"><span data-stu-id="d1de2-170">The most expensive components used in this reference architecture are the compute resources.</span></span>

<span data-ttu-id="d1de2-171">Размер кластера Batch AI можно масштабировать в зависимости от заданий в очереди.</span><span class="sxs-lookup"><span data-stu-id="d1de2-171">The Batch AI cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="d1de2-172">Вы можете включить [автоматическое масштабирование][automatic-scaling] с помощью Batch AI одним из двух способов.</span><span class="sxs-lookup"><span data-stu-id="d1de2-172">You can enable [automatic scaling][automatic-scaling] with Batch AI in one of two ways.</span></span> <span data-ttu-id="d1de2-173">Так можно сделать путем программирования, который можно настроить в файле ENV, который является частью [шагов развертывания][github], или можно изменить формулу масштабирования на портале после создания кластера.</span><span class="sxs-lookup"><span data-stu-id="d1de2-173">You can do so programmatically, which can be configured in the .env file that is part of the [deployment steps][github], or you can change the scale formula directly in the portal after the cluster is created.</span></span>

<span data-ttu-id="d1de2-174">Для работы, которая не требует немедленной обработки, настройте формулу автоматического масштабирования, чтобы состояние по умолчанию (минимальное) было кластером нулевых узлов.</span><span class="sxs-lookup"><span data-stu-id="d1de2-174">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="d1de2-175">При использовании этой конфигурации кластер запускается с нулевых узлов и масштабируется только при обнаружении заданий в очереди.</span><span class="sxs-lookup"><span data-stu-id="d1de2-175">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="d1de2-176">Если процесс пакетной оценки происходит несколько раз в день или меньше, этот параметр позволяет значительно сократить затраты.</span><span class="sxs-lookup"><span data-stu-id="d1de2-176">If the batch scoring process only happens a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="d1de2-177">Автоматическое масштабирование может не подойти для пакетных заданий, которые происходят слишком близко друг к другу.</span><span class="sxs-lookup"><span data-stu-id="d1de2-177">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="d1de2-178">Время, затрачиваемое на развертывание кластера и его отключение, также несет расходы. Поэтому, если пакет рабочей нагрузки запускается всего через несколько минут после окончания предыдущего задания, более экономично запускать кластер между заданиями.</span><span class="sxs-lookup"><span data-stu-id="d1de2-178">The time that it takes for a cluster to spin up and spin down also incur a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="d1de2-179">Это зависит от того, запланированы ли процессы оценки с высокой частотой (например, каждый час) или реже (например, раз в месяц).</span><span class="sxs-lookup"><span data-stu-id="d1de2-179">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="d1de2-180">Развертывание решения</span><span class="sxs-lookup"><span data-stu-id="d1de2-180">Deploy the solution</span></span>

<span data-ttu-id="d1de2-181">Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="d1de2-181">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="d1de2-182">Следуйте инструкциям по установке, чтобы создать масштабируемое решение для параллельной оценки множества моделей с использованием Batch AI.</span><span class="sxs-lookup"><span data-stu-id="d1de2-182">Follow the setup steps there to build a scalable solution for scoring many models in parallel using Batch AI.</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[batch-ai]: /azure/batch-ai/
[bai-file-server]: /azure/batch-ai/resource-concepts#file-server
[create-resources]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Azure/BatchAIAnomalyDetection
[logic-apps]: /azure/logic-apps/logic-apps-overview
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/sched/submit_jobs.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
