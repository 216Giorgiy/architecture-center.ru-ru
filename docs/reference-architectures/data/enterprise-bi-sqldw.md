---
title: Корпоративная бизнес-аналитика с использованием хранилища данных SQL
description: Используйте Azure для получения информации о бизнесе из реляционных данных, хранящихся локально
author: MikeWasson
ms.date: 07/01/2018
ms.openlocfilehash: e3542e40b4b6d1f604f93bb21528f34ba7f22fc6
ms.sourcegitcommit: 58d93e7ac9a6d44d5668a187a6827d7cd4f5a34d
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/02/2018
ms.locfileid: "37142341"
---
# <a name="enterprise-bi-with-sql-data-warehouse"></a><span data-ttu-id="59f08-103">Корпоративная бизнес-аналитика с использованием хранилища данных SQL</span><span class="sxs-lookup"><span data-stu-id="59f08-103">Enterprise BI with SQL Data Warehouse</span></span>

<span data-ttu-id="59f08-104">Эта эталонная архитектура реализует конвейер [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (извлечение-загрузка-преобразование), который перемещает данные из локальной базы данных SQL Server в хранилище данных SQL и преобразует данные для анализа.</span><span class="sxs-lookup"><span data-stu-id="59f08-104">This reference architecture implements an [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (extract-load-transform) pipeline that moves data from an on-premises SQL Server database into SQL Data Warehouse and transforms the data for analysis.</span></span> [<span data-ttu-id="59f08-105">**Разверните это решение**.</span><span class="sxs-lookup"><span data-stu-id="59f08-105">**Deploy this solution**.</span></span>](#deploy-the-solution)

![](./images/enterprise-bi-sqldw.png)

<span data-ttu-id="59f08-106">**Сценарий**. Организация имеет большой набор данных OLTP, хранящийся локально в базе данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="59f08-106">**Scenario**: An organization has a large OLTP data set stored in a SQL Server database on premises.</span></span> <span data-ttu-id="59f08-107">Организация хочет использовать хранилище данных SQL для проведения анализа с использованием Power BI.</span><span class="sxs-lookup"><span data-stu-id="59f08-107">The organization wants to use SQL Data Warehouse to perform analysis using Power BI.</span></span> 

<span data-ttu-id="59f08-108">Эта эталонная архитектура предназначена для однократных заданий или заданий по требованию.</span><span class="sxs-lookup"><span data-stu-id="59f08-108">This reference architecture is designed for one-time or on-demand jobs.</span></span> <span data-ttu-id="59f08-109">Если необходимо регулярно перемещать данные (ежечасно или ежедневно), рекомендуется использовать фабрику данных Azure для автоматизации рабочего процесса.</span><span class="sxs-lookup"><span data-stu-id="59f08-109">If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow.</span></span> <span data-ttu-id="59f08-110">Описание эталонной архитектуры, в которой используется Фабрика данных, см. в статье [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory](./enterprise-bi-adf.md) (Автоматизированная корпоративная бизнес-аналитика с использованием Хранилища данных SQL и Фабрики данных).</span><span class="sxs-lookup"><span data-stu-id="59f08-110">For a reference architecture that uses Data Factory, see [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory](./enterprise-bi-adf.md).</span></span>

## <a name="architecture"></a><span data-ttu-id="59f08-111">Архитектура</span><span class="sxs-lookup"><span data-stu-id="59f08-111">Architecture</span></span>

<span data-ttu-id="59f08-112">Архитектура состоит из следующих компонентов:</span><span class="sxs-lookup"><span data-stu-id="59f08-112">The architecture consists of the following components.</span></span>

### <a name="data-source"></a><span data-ttu-id="59f08-113">Источник данных</span><span class="sxs-lookup"><span data-stu-id="59f08-113">Data source</span></span>

<span data-ttu-id="59f08-114">**SQL Server.**</span><span class="sxs-lookup"><span data-stu-id="59f08-114">**SQL Server**.</span></span> <span data-ttu-id="59f08-115">Исходные данные размещаются локально в базе данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="59f08-115">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="59f08-116">Чтобы имитировать локальную среду, скрипты развертывания для этой архитектуры предоставляют виртуальную машину в Azure с установленной платформой SQL Server.</span><span class="sxs-lookup"><span data-stu-id="59f08-116">To simulate the on-premises environment, the deployment scripts for this architecture provision a VM in Azure with SQL Server installed.</span></span> <span data-ttu-id="59f08-117">В качестве исходных данных используется [пример базы данных OLTP Wide World Importers][wwi].</span><span class="sxs-lookup"><span data-stu-id="59f08-117">The [Wide World Importers OLTP sample database][wwi] is used as the source data.</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="59f08-118">Прием и хранение данных</span><span class="sxs-lookup"><span data-stu-id="59f08-118">Ingestion and data storage</span></span>

<span data-ttu-id="59f08-119">**Хранилище больших двоичных объектов**.</span><span class="sxs-lookup"><span data-stu-id="59f08-119">**Blob Storage**.</span></span> <span data-ttu-id="59f08-120">Хранилище больших двоичных объектов используется в качестве промежуточной области для копирования данных перед загрузкой в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-120">Blob storage is used as a staging area to copy the data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="59f08-121">**Хранилище данных Azure SQL.**</span><span class="sxs-lookup"><span data-stu-id="59f08-121">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="59f08-122">[Хранилище данных SQL](/azure/sql-data-warehouse/) — распределенная система, предназначенная для анализа больших объемов данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-122">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="59f08-123">Она поддерживает массовую параллельную обработку (MPP), что делает ее пригодной для запуска высокопроизводительной аналитики.</span><span class="sxs-lookup"><span data-stu-id="59f08-123">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span> 

### <a name="analysis-and-reporting"></a><span data-ttu-id="59f08-124">Анализ и создание отчетов</span><span class="sxs-lookup"><span data-stu-id="59f08-124">Analysis and reporting</span></span>

<span data-ttu-id="59f08-125">**Службы Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="59f08-125">**Azure Analysis Services**.</span></span> <span data-ttu-id="59f08-126">[Analysis Services](/azure/analysis-services/) — полностью управляемая служба, которая предоставляет возможности моделирования данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-126">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="59f08-127">Используйте службу Analysis Services для создания семантической модели, которую могут запрашивать пользователи.</span><span class="sxs-lookup"><span data-stu-id="59f08-127">Use Analysis Services to create a semantic model that users can query.</span></span> <span data-ttu-id="59f08-128">Служба Analysis Services особенно полезна в сценарии информационной панели бизнес-аналитики.</span><span class="sxs-lookup"><span data-stu-id="59f08-128">Analysis Services is especially useful in a BI dashboard scenario.</span></span> <span data-ttu-id="59f08-129">В этой архитектуре служба Analysis Services считывает данные из хранилища данных для обработки семантической модели и эффективно обслуживает запросы информационной панели.</span><span class="sxs-lookup"><span data-stu-id="59f08-129">In this architecture, Analysis Services reads data from the data warehouse to process the semantic model, and efficiently serves dashboard queries.</span></span> <span data-ttu-id="59f08-130">Она также поддерживает гибкий параллелизм путем масштабирования реплик, чтобы быстрее обрабатывать запросы.</span><span class="sxs-lookup"><span data-stu-id="59f08-130">It also supports elastic concurrency, by scaling out replicas for faster query processing.</span></span>

<span data-ttu-id="59f08-131">В настоящее время Azure Analysis Services поддерживает табличные модели, но не поддерживает многомерные.</span><span class="sxs-lookup"><span data-stu-id="59f08-131">Currently, Azure Analysis Services supports tabular models but not multidimensional models.</span></span> <span data-ttu-id="59f08-132">В табличных моделях используются конструкции реляционного моделирования (таблицы и столбцы), тогда как в многомерных моделях используются моделирующие конструкции OLAP (кубы, размеры и меры).</span><span class="sxs-lookup"><span data-stu-id="59f08-132">Tabular models use relational modeling constructs (tables and columns), whereas multidimensional models use OLAP modeling constructs (cubes, dimensions, and measures).</span></span> <span data-ttu-id="59f08-133">Если требуются многомерные модели, используйте SQL Server Analysis Services (SSAS).</span><span class="sxs-lookup"><span data-stu-id="59f08-133">If you require multidimensional models, use SQL Server Analysis Services (SSAS).</span></span> <span data-ttu-id="59f08-134">Дополнительные сведения см. в разделе [Сравнение табличных и многомерных решений](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span><span class="sxs-lookup"><span data-stu-id="59f08-134">For more information, see [Comparing tabular and multidimensional solutions](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span></span>

<span data-ttu-id="59f08-135">**Power BI**.</span><span class="sxs-lookup"><span data-stu-id="59f08-135">**Power BI**.</span></span> <span data-ttu-id="59f08-136">Power BI — набор средств бизнес-аналитики для анализа информации о бизнесе.</span><span class="sxs-lookup"><span data-stu-id="59f08-136">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="59f08-137">В этой архитектуре он запрашивает семантическую модель, хранящуюся в службе Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-137">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="59f08-138">Authentication</span><span class="sxs-lookup"><span data-stu-id="59f08-138">Authentication</span></span>

<span data-ttu-id="59f08-139">**Azure Active Directory** (Azure AD) аутентифицирует пользователей, которые подключаются к серверу Analysis Services через Power BI.</span><span class="sxs-lookup"><span data-stu-id="59f08-139">**Azure Active Directory** (Azure AD) authenticates users who connect to the Analysis Services server through Power BI.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="59f08-140">Конвейер данных</span><span class="sxs-lookup"><span data-stu-id="59f08-140">Data pipeline</span></span>
 
<span data-ttu-id="59f08-141">В этой эталонной архитектуре в качестве источника данных используется база данных [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database).</span><span class="sxs-lookup"><span data-stu-id="59f08-141">This reference architecture uses the [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) sample database as a data source.</span></span> <span data-ttu-id="59f08-142">Конвейер данных состоит из перечисленных ниже этапов.</span><span class="sxs-lookup"><span data-stu-id="59f08-142">The data pipeline has the following stages:</span></span>

1. <span data-ttu-id="59f08-143">Экспортирование данных из SQL Server в неструктурированные файлы (утилита bcp).</span><span class="sxs-lookup"><span data-stu-id="59f08-143">Export the data from SQL Server to flat files (bcp utility).</span></span>
2. <span data-ttu-id="59f08-144">Копирование неструктурированных файлов в хранилище больших двоичных объектов Azure (AzCopy)</span><span class="sxs-lookup"><span data-stu-id="59f08-144">Copy the flat files to Azure Blob Storage (AzCopy).</span></span>
3. <span data-ttu-id="59f08-145">Загрузка данных в хранилище данных SQL (PolyBase).</span><span class="sxs-lookup"><span data-stu-id="59f08-145">Load the data into SQL Data Warehouse (PolyBase).</span></span>
4. <span data-ttu-id="59f08-146">Преобразование данных в схему типа "звезда" (T-SQL).</span><span class="sxs-lookup"><span data-stu-id="59f08-146">Transform the data into a star schema (T-SQL).</span></span>
5. <span data-ttu-id="59f08-147">Загрузка семантической модели в службу Analysis Services (средства SQL Server Data Tools).</span><span class="sxs-lookup"><span data-stu-id="59f08-147">Load a semantic model into Analysis Services (SQL Server Data Tools).</span></span>

![](./images/enterprise-bi-sqldw-pipeline.png)
 
> [!NOTE]
> <span data-ttu-id="59f08-148">Для шагов 1 &ndash; 3 рассмотрите использование Redgate Data Platform Studio.</span><span class="sxs-lookup"><span data-stu-id="59f08-148">For steps 1 &ndash; 3, consider using Redgate Data Platform Studio.</span></span> <span data-ttu-id="59f08-149">Так как к Data Platform Studio применены наиболее подходящие оптимизации и исправления совместимости, это самый быстрый способ начать работу с хранилищем данных SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-149">Data Platform Studio applies the most appropriate compatibility fixes and optimizations, so it's the quickest way to get started with SQL Data Warehouse.</span></span> <span data-ttu-id="59f08-150">Дополнительную информацию см. в разделе [Загрузка данных с помощью Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span><span class="sxs-lookup"><span data-stu-id="59f08-150">For more information, see [Load data with Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span></span> 

<span data-ttu-id="59f08-151">Следующие разделы описывают эти этапы более подробно.</span><span class="sxs-lookup"><span data-stu-id="59f08-151">The next sections describe these stages in more detail.</span></span>

### <a name="export-data-from-sql-server"></a><span data-ttu-id="59f08-152">Экспорт данных из SQL Server</span><span class="sxs-lookup"><span data-stu-id="59f08-152">Export data from SQL Server</span></span>

<span data-ttu-id="59f08-153">Программа массового копирования [bcp](/sql/tools/bcp-utility) — это быстрый способ создания неструктурированных текстовых файлов из таблиц SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-153">The [bcp](/sql/tools/bcp-utility) (bulk copy program) utility is a fast way to create flat text files from SQL tables.</span></span> <span data-ttu-id="59f08-154">На этом шаге выбираются столбцы, которые нужно экспортировать, но данные не надо преобразовывать.</span><span class="sxs-lookup"><span data-stu-id="59f08-154">In this step, you select the columns that you want to export, but don't transform the data.</span></span> <span data-ttu-id="59f08-155">Любые преобразования данных должны происходить в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-155">Any data transformations should happen in SQL Data Warehouse.</span></span>

<span data-ttu-id="59f08-156">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="59f08-156">**Recommendations**</span></span>

<span data-ttu-id="59f08-157">Если возможно, планируйте извлечение данных в часы с наименьшей загрузкой, чтобы свести к минимуму конфликт ресурсов в рабочей среде.</span><span class="sxs-lookup"><span data-stu-id="59f08-157">If possible, schedule data extraction during off-peak hours, to minimize resource contention in the production environment.</span></span> 

<span data-ttu-id="59f08-158">Избегайте запуска bcp на сервере базы данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-158">Avoid running bcp on the database server.</span></span> <span data-ttu-id="59f08-159">Вместо этого запустите его с другого компьютера.</span><span class="sxs-lookup"><span data-stu-id="59f08-159">Instead, run it from another machine.</span></span> <span data-ttu-id="59f08-160">Записывайте файлы на локальный диск.</span><span class="sxs-lookup"><span data-stu-id="59f08-160">Write the files to a local drive.</span></span> <span data-ttu-id="59f08-161">Убедитесь, что имеется достаточно ресурсов ввода-вывода для обработки параллельных операций записи.</span><span class="sxs-lookup"><span data-stu-id="59f08-161">Ensure that you have sufficient I/O resources to handle the concurrent writes.</span></span> <span data-ttu-id="59f08-162">Для обеспечения максимальной производительности экспортируйте файлы в специализированные высокоскоростные хранилища.</span><span class="sxs-lookup"><span data-stu-id="59f08-162">For best performance, export the files to dedicated fast storage drives.</span></span>

<span data-ttu-id="59f08-163">Вы можете ускорить сетевой перенос, сохранив экспортированные данные в сжатом формате Gzip.</span><span class="sxs-lookup"><span data-stu-id="59f08-163">You can speed up the network transfer by saving the exported data in Gzip compressed format.</span></span> <span data-ttu-id="59f08-164">Однако загрузка сжатых файлов в хранилище происходит медленнее, чем загрузка несжатых файлов, поэтому существует компромисс между более быстрой передачей сети и более быстрой загрузкой.</span><span class="sxs-lookup"><span data-stu-id="59f08-164">However, loading compressed files into the warehouse is slower than loading uncompressed files, so there is a tradeoff between faster network transfer versus faster loading.</span></span> <span data-ttu-id="59f08-165">Если решено использовать сжатие Gzip, не создавайте отдельные файлы Gzip.</span><span class="sxs-lookup"><span data-stu-id="59f08-165">If you decide to use Gzip compression, don't create a single Gzip file.</span></span> <span data-ttu-id="59f08-166">Вместо этого разделите данные на несколько сжатых файлов.</span><span class="sxs-lookup"><span data-stu-id="59f08-166">Instead, split the data into multiple compressed files.</span></span>

### <a name="copy-flat-files-into-blob-storage"></a><span data-ttu-id="59f08-167">Копирование неструктурированных файлов в хранилище больших двоичных объектов</span><span class="sxs-lookup"><span data-stu-id="59f08-167">Copy flat files into blob storage</span></span>

<span data-ttu-id="59f08-168">Утилита [AzCopy](/azure/storage/common/storage-use-azcopy) предназначена для высокопроизводительного копирования данных в хранилище больших двоичных объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-168">The [AzCopy](/azure/storage/common/storage-use-azcopy) utility is designed for high-performance copying of data into Azure blob storage.</span></span>

<span data-ttu-id="59f08-169">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="59f08-169">**Recommendations**</span></span>

<span data-ttu-id="59f08-170">Создайте учетную запись хранения в регионе, расположенном рядом с исходными данными.</span><span class="sxs-lookup"><span data-stu-id="59f08-170">Create the storage account in a region near the location of the source data.</span></span> <span data-ttu-id="59f08-171">Разверните учетную запись хранения и экземпляр хранилища данных SQL в том же регионе.</span><span class="sxs-lookup"><span data-stu-id="59f08-171">Deploy the storage account and the SQL Data Warehouse instance in the same region.</span></span> 

<span data-ttu-id="59f08-172">Не запускайте AzCopy на том же компьютере, на котором выполняются производственные рабочие нагрузки, поскольку потребление процессора и ввода-вывода может влиять на рабочую нагрузку.</span><span class="sxs-lookup"><span data-stu-id="59f08-172">Don't run AzCopy on the same machine that runs your production workloads, because the CPU and I/O consumption can interfere with the production workload.</span></span> 

<span data-ttu-id="59f08-173">Сначала проверьте загрузку, чтобы изучить скорость загрузки.</span><span class="sxs-lookup"><span data-stu-id="59f08-173">Test the upload first to see what the upload speed is like.</span></span> <span data-ttu-id="59f08-174">Чтобы указать количество параллельных операций копирования, в AzCopy можно использовать параметр /NC.</span><span class="sxs-lookup"><span data-stu-id="59f08-174">You can use the /NC option in AzCopy to specify the number of concurrent copy operations.</span></span> <span data-ttu-id="59f08-175">Чтобы настроить производительность, начните со значения по умолчанию и затем поэкспериментируйте с этим параметром.</span><span class="sxs-lookup"><span data-stu-id="59f08-175">Start with the default value, then experiment with this setting to tune the performance.</span></span> <span data-ttu-id="59f08-176">В среде с низкой пропускной способностью слишком много параллельных операций могут привести к сбою сетевого соединения и не допустить успешного завершения операций.</span><span class="sxs-lookup"><span data-stu-id="59f08-176">In a low-bandwidth environment, too many concurrent operations can overwhelm the network connection and prevent the operations from completing successfully.</span></span>  

<span data-ttu-id="59f08-177">AzCopy перемещает данные в хранилище через общий доступ в Интернет.</span><span class="sxs-lookup"><span data-stu-id="59f08-177">AzCopy moves data to storage over the public internet.</span></span> <span data-ttu-id="59f08-178">Если это недостаточно быстро, рассмотрите создание схемы [ExpressRoute](/azure/expressroute/).</span><span class="sxs-lookup"><span data-stu-id="59f08-178">If this isn't fast enough, consider setting up an [ExpressRoute](/azure/expressroute/) circuit.</span></span> <span data-ttu-id="59f08-179">ExpressRoute — это служба, которая направляет данные с помощью выделенного частного подключения в Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-179">ExpressRoute is a service that routes your data through a dedicated private connection to Azure.</span></span> <span data-ttu-id="59f08-180">Если ваше сетевое соединение слишком медленное, то другой вариант заключается в физической отправке данных на диск в центр данных Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-180">Another option, if your network connection is too slow, is to physically ship the data on disk to an Azure datacenter.</span></span> <span data-ttu-id="59f08-181">Дополнительные сведения см. в разделе [Передача данных в Azure и обратно](/azure/architecture/data-guide/scenarios/data-transfer).</span><span class="sxs-lookup"><span data-stu-id="59f08-181">For more information, see [Transferring data to and from Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span></span>

<span data-ttu-id="59f08-182">Во время операции копирования AzCopy создает временный файл журнала, который позволяет AzCopy перезапустить операцию, если она прервется (например, из-за сетевой ошибки).</span><span class="sxs-lookup"><span data-stu-id="59f08-182">During a copy operation, AzCopy creates a temporary journal file, which enables AzCopy to restart the operation if it gets interrupted (for example, due to a network error).</span></span> <span data-ttu-id="59f08-183">Убедитесь, что для хранения файлов журнала на диске достаточно свободного места.</span><span class="sxs-lookup"><span data-stu-id="59f08-183">Make sure there is enough disk space to store the journal files.</span></span> <span data-ttu-id="59f08-184">Чтобы указать, где записываются файлы журнала, можно использовать параметр /Z.</span><span class="sxs-lookup"><span data-stu-id="59f08-184">You can use the /Z option to specify where the journal files are written.</span></span>

### <a name="load-data-into-sql-data-warehouse"></a><span data-ttu-id="59f08-185">Загрузка данных в хранилище данных SQL</span><span class="sxs-lookup"><span data-stu-id="59f08-185">Load data into SQL Data Warehouse</span></span>

<span data-ttu-id="59f08-186">Используйте [PolyBase](/sql/relational-databases/polybase/polybase-guide), чтобы загрузить файлы из хранилища больших двоичных объектов в хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-186">Use [PolyBase](/sql/relational-databases/polybase/polybase-guide) to load the files from blob storage into the data warehouse.</span></span> <span data-ttu-id="59f08-187">PolyBase предназначен для использования архитектуры MPP (массовой параллельной обработки) хранилища данных SQL, которая делает ее самым быстрым способом загрузки данных в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-187">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse, which makes it the fastest way to load data into SQL Data Warehouse.</span></span> 

<span data-ttu-id="59f08-188">Загрузка данных — это двухэтапный процесс:</span><span class="sxs-lookup"><span data-stu-id="59f08-188">Loading the data is a two-step process:</span></span>

1. <span data-ttu-id="59f08-189">Создание набора внешних таблиц для данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-189">Create a set of external tables for the data.</span></span> <span data-ttu-id="59f08-190">Внешняя таблица — это определение таблицы, которое указывает на данные, хранящиеся вне хранилища &mdash; в этом случае, неструктурированные файлы в хранилище памяти.</span><span class="sxs-lookup"><span data-stu-id="59f08-190">An external table is a table definition that points to data stored outside of the warehouse &mdash; in this case, the flat files in blob storage.</span></span> <span data-ttu-id="59f08-191">Этот этап не перемещает никаких данных в хранилище.</span><span class="sxs-lookup"><span data-stu-id="59f08-191">This step does not move any data into the warehouse.</span></span>
2. <span data-ttu-id="59f08-192">Создание промежуточных таблиц и загрузка данных в промежуточные таблицы.</span><span class="sxs-lookup"><span data-stu-id="59f08-192">Create staging tables, and load the data into the staging tables.</span></span> <span data-ttu-id="59f08-193">Этот этап копирует данные в хранилище.</span><span class="sxs-lookup"><span data-stu-id="59f08-193">This step copies the data into the warehouse.</span></span>

<span data-ttu-id="59f08-194">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="59f08-194">**Recommendations**</span></span>

<span data-ttu-id="59f08-195">Если имеется большой объем данных (более 1 ТБ) и используется рабочая нагрузка аналитики, которая выиграет от параллелизма, то рассмотрите возможности хранилища данных SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-195">Consider SQL Data Warehouse when you have large amounts of data (more than 1 TB) and are running an analytics workload that will benefit from parallelism.</span></span> <span data-ttu-id="59f08-196">Хранилище данных SQL не подходит для рабочих нагрузок OLTP или малых наборов данных (<250 ГБ).</span><span class="sxs-lookup"><span data-stu-id="59f08-196">SQL Data Warehouse is not a good fit for OLTP workloads or smaller data sets (< 250GB).</span></span> <span data-ttu-id="59f08-197">Для наборов данных менее 250 ГБ рассмотрите базу данных Azure SQL или SQL Server.</span><span class="sxs-lookup"><span data-stu-id="59f08-197">For data sets less than 250GB, consider Azure SQL Database or SQL Server.</span></span> <span data-ttu-id="59f08-198">Дополнительные сведения см. в разделе [Хранение данных](../../data-guide/relational-data/data-warehousing.md).</span><span class="sxs-lookup"><span data-stu-id="59f08-198">For more information, see [Data warehousing](../../data-guide/relational-data/data-warehousing.md).</span></span>

<span data-ttu-id="59f08-199">Создайте промежуточные таблицы в виде таблиц без кластеризованных индексов, которые не индексируются.</span><span class="sxs-lookup"><span data-stu-id="59f08-199">Create the staging tables as heap tables, which are not indexed.</span></span> <span data-ttu-id="59f08-200">Запросы, которые создают производственные таблицы, приведут к полному сканированию таблицы, поэтому нет причин индексировать промежуточные таблицы.</span><span class="sxs-lookup"><span data-stu-id="59f08-200">The queries that create the production tables will result in a full table scan, so there is no reason to index the staging tables.</span></span>

<span data-ttu-id="59f08-201">PolyBase автоматически использует преимущества параллелизма в хранилище.</span><span class="sxs-lookup"><span data-stu-id="59f08-201">PolyBase automatically takes advantage of parallelism in the warehouse.</span></span> <span data-ttu-id="59f08-202">Производительность нагрузки масштабируется при увеличении DWU.</span><span class="sxs-lookup"><span data-stu-id="59f08-202">The load performance scales as you increase DWUs.</span></span> <span data-ttu-id="59f08-203">Для достижения оптимальной производительности используйте операции одинарной загрузки.</span><span class="sxs-lookup"><span data-stu-id="59f08-203">For best performance, use a single load operation.</span></span> <span data-ttu-id="59f08-204">Разбивка входных данных на фрагменты и выполнение нескольких одновременных нагрузок не повышает производительность.</span><span class="sxs-lookup"><span data-stu-id="59f08-204">There is no performance benefit to breaking the input data into chunks and running multiple concurrent loads.</span></span>

<span data-ttu-id="59f08-205">PolyBase может читать данные, сжатые с помощью GZip.</span><span class="sxs-lookup"><span data-stu-id="59f08-205">PolyBase can read Gzip compressed files.</span></span> <span data-ttu-id="59f08-206">Тем не менее для сжатого файла используется только один модуль чтения, потому что распаковка файла является однопоточной операцией.</span><span class="sxs-lookup"><span data-stu-id="59f08-206">However, only a single reader is used per compressed file, because uncompressing the file is a single-threaded operation.</span></span> <span data-ttu-id="59f08-207">Поэтому следует избегать загрузки одного большого сжатого файла.</span><span class="sxs-lookup"><span data-stu-id="59f08-207">Therefore, avoid loading a single large compressed file.</span></span> <span data-ttu-id="59f08-208">Вместо этого разбейте данные на несколько сжатых файлов, чтобы воспользоваться преимуществами параллелизма.</span><span class="sxs-lookup"><span data-stu-id="59f08-208">Instead, split the data into multiple compressed files, in order to take advantage of parallelism.</span></span> 

<span data-ttu-id="59f08-209">Следует учитывать следующие ограничения.</span><span class="sxs-lookup"><span data-stu-id="59f08-209">Be aware of the following limitations:</span></span>

- <span data-ttu-id="59f08-210">PolyBase поддерживает максимальный размер столбца из `varchar(8000)`, `nvarchar(4000)` или `varbinary(8000)`.</span><span class="sxs-lookup"><span data-stu-id="59f08-210">PolyBase supports a maximum column size of `varchar(8000)`, `nvarchar(4000)`, or `varbinary(8000)`.</span></span> <span data-ttu-id="59f08-211">Если имеются данные, превышающие эти лимиты, то при экспорте следует разбить данные на блоки, а затем собрать эти блоки после импорта.</span><span class="sxs-lookup"><span data-stu-id="59f08-211">If you have data that exceeds these limits, one option is to break the data up into chunks when you export it, and then reassemble the chunks after import.</span></span> 

- <span data-ttu-id="59f08-212">PolyBase использует фиксированный признак конца строки \n или новой строки.</span><span class="sxs-lookup"><span data-stu-id="59f08-212">PolyBase uses a fixed row terminator of \n or newline.</span></span> <span data-ttu-id="59f08-213">Если в исходных данных появляются символы новой строки, это может вызвать проблемы.</span><span class="sxs-lookup"><span data-stu-id="59f08-213">This can cause problems if newline characters appear in the source data.</span></span>

- <span data-ttu-id="59f08-214">Схема исходных данных может содержать типы данных, которые не поддерживаются в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-214">Your source data schema might contain data types that are not supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="59f08-215">Чтобы обойти эти ограничения, можно создать хранимую процедуру, которая выполнит необходимые преобразования.</span><span class="sxs-lookup"><span data-stu-id="59f08-215">To work around these limitations, you can create a stored procedure that performs the necessary conversions.</span></span> <span data-ttu-id="59f08-216">При запуске bcp найдите по ссылке эту хранимую процедуру.</span><span class="sxs-lookup"><span data-stu-id="59f08-216">Reference this stored procedure when you run bcp.</span></span> <span data-ttu-id="59f08-217">Как альтернатива [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) автоматически преобразует типы данных, которые не поддерживаются в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="59f08-217">Alternatively, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatically converts data types that aren’t supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="59f08-218">Дополнительные сведения см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="59f08-218">For more information, see the following articles:</span></span>

- <span data-ttu-id="59f08-219">[Рекомендации по загрузке данных в хранилище данных SQL Azure](/azure/sql-data-warehouse/guidance-for-loading-data).</span><span class="sxs-lookup"><span data-stu-id="59f08-219">[Best practices for loading data into Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span></span>
- <span data-ttu-id="59f08-220">[Перенос схем в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema).</span><span class="sxs-lookup"><span data-stu-id="59f08-220">[Migrate your schemas to SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema)</span></span>
- <span data-ttu-id="59f08-221">[Руководство по определению типов данных для таблиц в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types).</span><span class="sxs-lookup"><span data-stu-id="59f08-221">[Guidance for defining data types for tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types)</span></span>

### <a name="transform-the-data"></a><span data-ttu-id="59f08-222">Преобразование данных</span><span class="sxs-lookup"><span data-stu-id="59f08-222">Transform the data</span></span>

<span data-ttu-id="59f08-223">Преобразование данных и перемещение их в производственные таблицы.</span><span class="sxs-lookup"><span data-stu-id="59f08-223">Transform the data and move it into production tables.</span></span> <span data-ttu-id="59f08-224">На этом этапе данные преобразуются в схему типа "звезда" с таблицами измерений и таблицами фактов, подходящими для семантического моделирования.</span><span class="sxs-lookup"><span data-stu-id="59f08-224">In this step, the data is transformed into a star schema with dimension tables and fact tables, suitable for semantic modeling.</span></span>

<span data-ttu-id="59f08-225">Создайте рабочие таблицы с кластерными индексами columnstore, которые обеспечивают наилучшую общую производительность запросов.</span><span class="sxs-lookup"><span data-stu-id="59f08-225">Create the production tables with clustered columnstore indexes, which offer the best overall query performance.</span></span> <span data-ttu-id="59f08-226">Индексы columnstore оптимизированы для запросов, которые сканируют большое количество записей.</span><span class="sxs-lookup"><span data-stu-id="59f08-226">Columnstore indexes are optimized for queries that scan many records.</span></span> <span data-ttu-id="59f08-227">Индексы columnstore также не работают для отдельных поисковых запросов (которые просматривают одну строку).</span><span class="sxs-lookup"><span data-stu-id="59f08-227">Columnstore indexes don't perform as well for singleton lookups (that is, looking up a single row).</span></span> <span data-ttu-id="59f08-228">Если необходимо выполнять частые отдельные запросы, можно добавить некластеризованный индекс в таблицу.</span><span class="sxs-lookup"><span data-stu-id="59f08-228">If you need to perform frequent singleton lookups, you can add a non-clustered index to a table.</span></span> <span data-ttu-id="59f08-229">Выполнение отдельных запросов происходит значительно быстрее с помощью некластеризованного индекса.</span><span class="sxs-lookup"><span data-stu-id="59f08-229">Singleton lookups can run significantly faster using a non-clustered index.</span></span> <span data-ttu-id="59f08-230">Однако отдельный поиск обычно менее распространен в сценариях хранилища данных, чем рабочие нагрузки OLTP.</span><span class="sxs-lookup"><span data-stu-id="59f08-230">However, singleton lookups are typically less common in data warehouse scenarios than OLTP workloads.</span></span> <span data-ttu-id="59f08-231">Дополнительные сведения см. в разделе [Индексирование таблиц в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span><span class="sxs-lookup"><span data-stu-id="59f08-231">For more information, see [Indexing tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span></span>

> [!NOTE]
> <span data-ttu-id="59f08-232">Кластерные таблицы columnstore не поддерживают типы данных `varchar(max)`, `nvarchar(max)` или `varbinary(max)`.</span><span class="sxs-lookup"><span data-stu-id="59f08-232">Clustered columnstore tables do not support `varchar(max)`, `nvarchar(max)`, or `varbinary(max)` data types.</span></span> <span data-ttu-id="59f08-233">В этом случае рассмотрим кучу или кластеризованный индекс.</span><span class="sxs-lookup"><span data-stu-id="59f08-233">In that case, consider a heap or clustered index.</span></span> <span data-ttu-id="59f08-234">Эти столбцы можно поместить в отдельную таблицу.</span><span class="sxs-lookup"><span data-stu-id="59f08-234">You might put those columns into a separate table.</span></span>

<span data-ttu-id="59f08-235">Поскольку база данных примеров не очень велика, были созданы реплицированные таблицы без разделов.</span><span class="sxs-lookup"><span data-stu-id="59f08-235">Because the sample database is not very large, we created replicated tables with no partitions.</span></span> <span data-ttu-id="59f08-236">Для производственных нагрузок использование распределенных таблиц, вероятно, улучшит производительность запросов.</span><span class="sxs-lookup"><span data-stu-id="59f08-236">For production workloads, using distributed tables is likely to improve query performance.</span></span> <span data-ttu-id="59f08-237">См. [Руководство по проектированию распределенных таблиц в хранилище данных SQL Azure](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span><span class="sxs-lookup"><span data-stu-id="59f08-237">See [Guidance for designing distributed tables in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span></span> <span data-ttu-id="59f08-238">В примерах скрипты запускают запросы, используя статический [класс ресурсов](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span><span class="sxs-lookup"><span data-stu-id="59f08-238">Our example scripts run the queries using a static [resource class](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span></span>

### <a name="load-the-semantic-model"></a><span data-ttu-id="59f08-239">Загрузка семантической модели</span><span class="sxs-lookup"><span data-stu-id="59f08-239">Load the semantic model</span></span>

<span data-ttu-id="59f08-240">Загрузка данных в табличную модель в Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-240">Load the data into a tabular model in Azure Analysis Services.</span></span> <span data-ttu-id="59f08-241">На этом этапе создается семантическая модель данных с помощью средства SQL Server Data Tools (SSDT).</span><span class="sxs-lookup"><span data-stu-id="59f08-241">In this step, you create a semantic data model by using SQL Server Data Tools (SSDT).</span></span> <span data-ttu-id="59f08-242">Можно также создать модель путем импорта из файла Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="59f08-242">You can also create a model by importing it from a Power BI Desktop file.</span></span> <span data-ttu-id="59f08-243">Поскольку хранилище данных SQL не поддерживает внешние ключи, необходимо добавить связи для семантической модели, чтобы можно было присоединиться к таблицам.</span><span class="sxs-lookup"><span data-stu-id="59f08-243">Because SQL Data Warehouse does not support foreign keys, you must add the relationships to the semantic model, so that you can join across tables.</span></span>

### <a name="use-power-bi-to-visualize-the-data"></a><span data-ttu-id="59f08-244">Использование Power BI для визуализации данных</span><span class="sxs-lookup"><span data-stu-id="59f08-244">Use Power BI to visualize the data</span></span>

<span data-ttu-id="59f08-245">Существует два варианта подключения Power BI к Azure Analysis Services:</span><span class="sxs-lookup"><span data-stu-id="59f08-245">Power BI supports two options for connecting to Azure Analysis Services:</span></span>

- <span data-ttu-id="59f08-246">Импорт.</span><span class="sxs-lookup"><span data-stu-id="59f08-246">Import.</span></span> <span data-ttu-id="59f08-247">Данные импортируются в модель Power BI.</span><span class="sxs-lookup"><span data-stu-id="59f08-247">The data is imported into the Power BI model.</span></span>
- <span data-ttu-id="59f08-248">Активное подключение.</span><span class="sxs-lookup"><span data-stu-id="59f08-248">Live Connection.</span></span> <span data-ttu-id="59f08-249">Данные извлекаются непосредственно из Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-249">Data is pulled directly from Analysis Services.</span></span>

<span data-ttu-id="59f08-250">Корпорация Майкрософт рекомендует активное подключение, так как оно не требует копирования данных в модели Power BI.</span><span class="sxs-lookup"><span data-stu-id="59f08-250">We recommend Live Connection because it doesn't require copying data into the Power BI model.</span></span> <span data-ttu-id="59f08-251">Кроме того, использование DirectQuery гарантирует, что результаты всегда соответствуют последним исходным данным.</span><span class="sxs-lookup"><span data-stu-id="59f08-251">Also, using DirectQuery ensures that results are always consistent with the latest source data.</span></span> <span data-ttu-id="59f08-252">Дополнительные сведения см. в разделе [Подключение с помощью Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span><span class="sxs-lookup"><span data-stu-id="59f08-252">For more information, see [Connect with Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span></span>

<span data-ttu-id="59f08-253">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="59f08-253">**Recommendations**</span></span>

<span data-ttu-id="59f08-254">Избегайте запуска запросов панели управления бизнес-аналитики непосредственно к хранилищу данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-254">Avoid running BI dashboard queries directly against the data warehouse.</span></span> <span data-ttu-id="59f08-255">Информационные панели бизнес-аналитики требуют очень малого времени отклика, которого может не хватить на прямые запросы к хранилищу.</span><span class="sxs-lookup"><span data-stu-id="59f08-255">BI dashboards require very low response times, which direct queries against the warehouse may be unable to satisfy.</span></span> <span data-ttu-id="59f08-256">Кроме того, при обновлении информационной панели будет учитываться количество одновременных запросов, что может повлиять на производительность.</span><span class="sxs-lookup"><span data-stu-id="59f08-256">Also, refreshing the dashboard will count against the number of concurrent queries, which could impact performance.</span></span> 

<span data-ttu-id="59f08-257">Azure Analysis Services предназначена для обработки требований к запросу информационной панели бизнес-аналитики, поэтому рекомендуемая практика заключается в том, чтобы запрашивать Analysis Services из Power BI.</span><span class="sxs-lookup"><span data-stu-id="59f08-257">Azure Analysis Services is designed to handle the query requirements of a BI dashboard, so the recommended practice is to query Analysis Services from Power BI.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="59f08-258">Вопросы масштабируемости</span><span class="sxs-lookup"><span data-stu-id="59f08-258">Scalability considerations</span></span>

### <a name="sql-data-warehouse"></a><span data-ttu-id="59f08-259">Хранилище данных SQL</span><span class="sxs-lookup"><span data-stu-id="59f08-259">SQL Data Warehouse</span></span>

<span data-ttu-id="59f08-260">С хранилищем данных SQL можно по требованию масштабировать вычислительные ресурсы.</span><span class="sxs-lookup"><span data-stu-id="59f08-260">With SQL Data Warehouse, you can scale out your compute resources on demand.</span></span> <span data-ttu-id="59f08-261">Механизм запросов оптимизирует запросы для параллельной обработки на основе количества вычислительных узлов и перемещает данные между узлами по мере необходимости.</span><span class="sxs-lookup"><span data-stu-id="59f08-261">The query engine optimizes queries for parallel processing based on the number of compute nodes, and moves data between nodes as necessary.</span></span> <span data-ttu-id="59f08-262">Дополнительные сведения см. в разделе [Управление вычислительными ресурсами в хранилище данных SQL Azure](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span><span class="sxs-lookup"><span data-stu-id="59f08-262">For more information, see [Manage compute in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span></span>

### <a name="analysis-services"></a><span data-ttu-id="59f08-263">Analysis Services</span><span class="sxs-lookup"><span data-stu-id="59f08-263">Analysis Services</span></span>

<span data-ttu-id="59f08-264">Для рабочих нагрузок рекомендуется уровень "Стандартный" для служб Azure Analysis Services, так как он поддерживает секционирование и DirectQuery.</span><span class="sxs-lookup"><span data-stu-id="59f08-264">For production workloads, we recommend the Standard Tier for Azure Analysis Services, because it supports partitioning and DirectQuery.</span></span> <span data-ttu-id="59f08-265">В пределах уровня размер экземпляра определяет память и мощность обработки.</span><span class="sxs-lookup"><span data-stu-id="59f08-265">Within a tier, the instance size determines the memory and processing power.</span></span> <span data-ttu-id="59f08-266">Вычислительная мощность измеряется в единицах обработки запроса (QPUs).</span><span class="sxs-lookup"><span data-stu-id="59f08-266">Processing power is measured in Query Processing Units (QPUs).</span></span> <span data-ttu-id="59f08-267">Контролируйте использование QPU, чтобы выбрать необходимый размер.</span><span class="sxs-lookup"><span data-stu-id="59f08-267">Monitor your QPU usage to select the appropriate size.</span></span> <span data-ttu-id="59f08-268">Дополнительные сведения см. в разделе [Мониторинг производительности сервера](/azure/analysis-services/analysis-services-monitor).</span><span class="sxs-lookup"><span data-stu-id="59f08-268">For more information, see [Monitor server metrics](/azure/analysis-services/analysis-services-monitor).</span></span>

<span data-ttu-id="59f08-269">При высокой нагрузке производительность запросов может ухудшиться из-за параллелизма запросов.</span><span class="sxs-lookup"><span data-stu-id="59f08-269">Under high load, query performance can become degraded due to query concurrency.</span></span> <span data-ttu-id="59f08-270">Чтобы одновременно выполнять больше запросов, можно масштабировать службы Analysis Services, создавая пул реплик для обработки запросов.</span><span class="sxs-lookup"><span data-stu-id="59f08-270">You can scale out Analysis Services by creating a pool of replicas to process queries, so that more queries can be performed concurrently.</span></span> <span data-ttu-id="59f08-271">Работа по обработке модели данных всегда происходит на основном сервере.</span><span class="sxs-lookup"><span data-stu-id="59f08-271">The work of processing the data model always happens on the primary server.</span></span> <span data-ttu-id="59f08-272">Основной сервер по умолчанию также обрабатывает запросы.</span><span class="sxs-lookup"><span data-stu-id="59f08-272">By default, the primary server also handles queries.</span></span> <span data-ttu-id="59f08-273">При необходимости можно назначить сервер-источник исключительно для обработки, чтобы пул запросов обрабатывал все запросы.</span><span class="sxs-lookup"><span data-stu-id="59f08-273">Optionally, you can designate the primary server to run processing exclusively, so that the query pool handles all queries.</span></span> <span data-ttu-id="59f08-274">В случае высоких требований к обработке нужно отделить обработку от пула запросов.</span><span class="sxs-lookup"><span data-stu-id="59f08-274">If you have high processing requirements, you should separate the processing from the query pool.</span></span> <span data-ttu-id="59f08-275">В случае высокой нагрузки запросов и относительно несложной обработки можно включить сервер-источник в пул запросов.</span><span class="sxs-lookup"><span data-stu-id="59f08-275">If you have high query loads, and relatively light processing, you can include the primary server in the query pool.</span></span> <span data-ttu-id="59f08-276">Дополнительные сведения см. в разделе [Горизонтальное масштабирование служб Azure Analysis Services](/azure/analysis-services/analysis-services-scale-out).</span><span class="sxs-lookup"><span data-stu-id="59f08-276">For more information, see [Azure Analysis Services scale-out](/azure/analysis-services/analysis-services-scale-out).</span></span> 

<span data-ttu-id="59f08-277">Чтобы уменьшить объем ненужной обработки, рассмотрите возможность использования секций для разделения табличной модели на логические части.</span><span class="sxs-lookup"><span data-stu-id="59f08-277">To reduce the amount of unnecessary processing, consider using partitions to divide the tabular model into logical parts.</span></span> <span data-ttu-id="59f08-278">Каждая секция может обрабатываться отдельно.</span><span class="sxs-lookup"><span data-stu-id="59f08-278">Each partition can be processed separately.</span></span> <span data-ttu-id="59f08-279">Дополнительные сведения см. в разделе [Секция](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span><span class="sxs-lookup"><span data-stu-id="59f08-279">For more information, see [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span></span>

## <a name="security-considerations"></a><span data-ttu-id="59f08-280">Вопросы безопасности</span><span class="sxs-lookup"><span data-stu-id="59f08-280">Security considerations</span></span>

### <a name="ip-whitelisting-of-analysis-services-clients"></a><span data-ttu-id="59f08-281">Список разрешенных IP-адресов клиентов службы Analysis Services</span><span class="sxs-lookup"><span data-stu-id="59f08-281">IP whitelisting of Analysis Services clients</span></span>

<span data-ttu-id="59f08-282">Рассмотрите возможность использования функции брандмауэра службы Analysis Services белого списка клиентских IP-адресов.</span><span class="sxs-lookup"><span data-stu-id="59f08-282">Consider using the Analysis Services firewall feature to whitelist client IP addresses.</span></span> <span data-ttu-id="59f08-283">Если параметр включен, брандмауэр блокирует все клиентские соединения, которые отличаются от указанных в правилах брандмауэра.</span><span class="sxs-lookup"><span data-stu-id="59f08-283">If enabled, the firewall blocks all client connections other than those specified in the firewall rules.</span></span> <span data-ttu-id="59f08-284">Стандартные правила присваивают белый список службе Power BI, но при необходимости можно отключить это правило.</span><span class="sxs-lookup"><span data-stu-id="59f08-284">The default rules whitelist the Power BI service, but you can disable this rule if desired.</span></span> <span data-ttu-id="59f08-285">Дополнительные сведения см. в разделе [Усиление защиты Azure Analysis Services благодаря новым возможностям брандмауэра](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span><span class="sxs-lookup"><span data-stu-id="59f08-285">For more information, see [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span></span>

### <a name="authorization"></a><span data-ttu-id="59f08-286">Авторизация</span><span class="sxs-lookup"><span data-stu-id="59f08-286">Authorization</span></span>

<span data-ttu-id="59f08-287">Azure Analysis Services использует Azure Active Directory (Azure AD) для аутентификации пользователей, подключающихся к серверу служб Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-287">Azure Analysis Services uses Azure Active Directory (Azure AD) to authenticate users who connect to an Analysis Services server.</span></span> <span data-ttu-id="59f08-288">Создавая роли и затем назначая их пользователям или группам Azure AD, можно ограничить данные, которые может просматривать конкретный пользователь.</span><span class="sxs-lookup"><span data-stu-id="59f08-288">You can restrict what data a particular user is able to view, by creating roles and then assigning Azure AD users or groups to those roles.</span></span> <span data-ttu-id="59f08-289">Для каждой роли можно сделать следующее.</span><span class="sxs-lookup"><span data-stu-id="59f08-289">For each role, you can:</span></span> 

- <span data-ttu-id="59f08-290">Защитить таблицы или отдельные столбцы.</span><span class="sxs-lookup"><span data-stu-id="59f08-290">Protect tables or individual columns.</span></span> 
- <span data-ttu-id="59f08-291">Защитить отдельные строки на основе выражения фильтра.</span><span class="sxs-lookup"><span data-stu-id="59f08-291">Protect individual rows based on filter expressions.</span></span> 

<span data-ttu-id="59f08-292">Дополнительные сведения см. в разделе [Управление ролями и пользователями базы данных](/azure/analysis-services/analysis-services-database-users).</span><span class="sxs-lookup"><span data-stu-id="59f08-292">For more information, see [Manage database roles and users](/azure/analysis-services/analysis-services-database-users).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="59f08-293">Развертывание решения</span><span class="sxs-lookup"><span data-stu-id="59f08-293">Deploy the solution</span></span>

<span data-ttu-id="59f08-294">Пример развертывания для этой архитектуры можно найти на портале [GitHub][ref-arch-repo-folder].</span><span class="sxs-lookup"><span data-stu-id="59f08-294">A deployment for this reference architecture is available on [GitHub][ref-arch-repo-folder].</span></span> <span data-ttu-id="59f08-295">Он позволяет развернуть следующее:</span><span class="sxs-lookup"><span data-stu-id="59f08-295">It deploys the following:</span></span>

  * <span data-ttu-id="59f08-296">Виртуальную машину Windows для имитации локального сервера базы данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-296">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="59f08-297">Она включает SQL Server 2017 и связанные с ним инструменты, а также Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="59f08-297">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
  * <span data-ttu-id="59f08-298">Учетная запись хранения Azure, которая обеспечивает хранилище больших двоичных объектов для хранения данных, экспортированных из базы данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="59f08-298">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
  * <span data-ttu-id="59f08-299">Экземпляр хранилища данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-299">An Azure SQL Data Warehouse instance.</span></span>
  * <span data-ttu-id="59f08-300">Экземпляр службы Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-300">An Azure Analysis Services instance.</span></span>

### <a name="prerequisites"></a><span data-ttu-id="59f08-301">предварительным требованиям</span><span class="sxs-lookup"><span data-stu-id="59f08-301">Prerequisites</span></span>

[!INCLUDE [ref-arch-prerequisites.md](../../../includes/ref-arch-prerequisites.md)]

### <a name="deploy-the-simulated-on-premises-server"></a><span data-ttu-id="59f08-302">Развертывание имитации локального сервера</span><span class="sxs-lookup"><span data-stu-id="59f08-302">Deploy the simulated on-premises server</span></span>

<span data-ttu-id="59f08-303">Сначала надо развернуть виртуальную машину в качестве имитируемого локального сервера, который включает SQL Server 2017 и связанные с ним инструменты.</span><span class="sxs-lookup"><span data-stu-id="59f08-303">First you'll deploy a VM as a simulated on-premises server, which includes SQL Server 2017 and related tools.</span></span> <span data-ttu-id="59f08-304">На этом этапе в SQL Server также загружается [база данных OLTP Wide World Importers][wwi].</span><span class="sxs-lookup"><span data-stu-id="59f08-304">This step also loads the [Wide World Importers OLTP database][wwi] into SQL Server.</span></span>

1. <span data-ttu-id="59f08-305">Перейдите в папку `data\enterprise_bi_sqldw\onprem\templates` в репозитории.</span><span class="sxs-lookup"><span data-stu-id="59f08-305">Navigate to the `data\enterprise_bi_sqldw\onprem\templates` folder of the repository.</span></span>

2. <span data-ttu-id="59f08-306">В файле `onprem.parameters.json` замените значения для `adminUsername` и `adminPassword`.</span><span class="sxs-lookup"><span data-stu-id="59f08-306">In the `onprem.parameters.json` file, replace the values for `adminUsername` and `adminPassword`.</span></span> <span data-ttu-id="59f08-307">Измените также значения в разделе `SqlUserCredentials` в соответствии с именем пользователя и паролем.</span><span class="sxs-lookup"><span data-stu-id="59f08-307">Also change the values in the `SqlUserCredentials` section to match the user name and password.</span></span> <span data-ttu-id="59f08-308">Обратите внимание на префикс `.\\` в свойстве userName.</span><span class="sxs-lookup"><span data-stu-id="59f08-308">Note the `.\\` prefix in the userName property.</span></span>
    
    ```bash
    "SqlUserCredentials": {
      "userName": ".\\username",
      "password": "password"
    }
    ```

3. <span data-ttu-id="59f08-309">Для развертывания локального сервера выполните `azbb`, как показано ниже.</span><span class="sxs-lookup"><span data-stu-id="59f08-309">Run `azbb` as shown below to deploy the on-premises server.</span></span>

    ```bash
    azbb -s <subscription_id> -g <resource_group_name> -l <region> -p onprem.parameters.json --deploy
    ```

    <span data-ttu-id="59f08-310">Укажите регион, в котором поддерживается Хранилище данных SQL Azure и Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-310">Specify a region that supports SQL Data Warehouse and Azure Analysis Services.</span></span> <span data-ttu-id="59f08-311">Ознакомьтесь со статьей [Доступность продуктов по регионам](https://azure.microsoft.com/global-infrastructure/services/).</span><span class="sxs-lookup"><span data-stu-id="59f08-311">See [Azure Products by Region](https://azure.microsoft.com/global-infrastructure/services/)</span></span>

4. <span data-ttu-id="59f08-312">Для завершения развертывания потребуется от 20 до 30 минут, включая запуск сценария [DSC](/powershell/dsc/overview) для установки инструментов и восстановления базы данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-312">The deployment may take 20 to 30 minutes to complete, which includes running the [DSC](/powershell/dsc/overview) script to install the tools and restore the database.</span></span> <span data-ttu-id="59f08-313">Проверьте развертывание на портале Azure, просмотрев ресурсы в группе ресурсов.</span><span class="sxs-lookup"><span data-stu-id="59f08-313">Verify the deployment in the Azure portal by reviewing the resources in the resource group.</span></span> <span data-ttu-id="59f08-314">Вы должны увидеть виртуальную машину `sql-vm1` и связанные с ней ресурсы.</span><span class="sxs-lookup"><span data-stu-id="59f08-314">You should see the `sql-vm1` virtual machine and its associated resources.</span></span>

### <a name="deploy-the-azure-resources"></a><span data-ttu-id="59f08-315">Развертывание ресурсов Azure</span><span class="sxs-lookup"><span data-stu-id="59f08-315">Deploy the Azure resources</span></span>

<span data-ttu-id="59f08-316">На этом шаге подготавливается Хранилище данных SQL и службы Azure Analysis Services вместе с учетной записью хранения.</span><span class="sxs-lookup"><span data-stu-id="59f08-316">This step provisions SQL Data Warehouse and Azure Analysis Services, along with a Storage account.</span></span> <span data-ttu-id="59f08-317">Если требуется, можно выполнить этот шаг параллельно с предыдущим шагом.</span><span class="sxs-lookup"><span data-stu-id="59f08-317">If you want, you can run this step in parallel with the previous step.</span></span>

1. <span data-ttu-id="59f08-318">Перейдите в папку `data\enterprise_bi_sqldw\azure\templates` в репозитории.</span><span class="sxs-lookup"><span data-stu-id="59f08-318">Navigate to the `data\enterprise_bi_sqldw\azure\templates` folder of the repository.</span></span>

2. <span data-ttu-id="59f08-319">Выполните следующую команду в Azure CLI, чтобы создать группу ресурсов.</span><span class="sxs-lookup"><span data-stu-id="59f08-319">Run the following Azure CLI command to create a resource group.</span></span> <span data-ttu-id="59f08-320">Вы можете выполнить развертывание в группу ресурсов, отличную от указанной на предыдущем шаге, но необходимо выбрать тот же регион.</span><span class="sxs-lookup"><span data-stu-id="59f08-320">You can deploy to a different resource group than the previous step, but choose the same region.</span></span> 

    ```bash
    az group create --name <resource_group_name> --location <region>  
    ```

3. <span data-ttu-id="59f08-321">Выполните следующую команду в Azure CLI, чтобы развернуть ресурсы Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-321">Run the following Azure CLI command to deploy the Azure resources.</span></span> <span data-ttu-id="59f08-322">Замените значения параметров, отображаемые в угловых скобках.</span><span class="sxs-lookup"><span data-stu-id="59f08-322">Replace the parameter values shown in angle brackets.</span></span> 

    ```bash
    az group deployment create --resource-group <resource_group_name> \
     --template-file azure-resources-deploy.json \
     --parameters "dwServerName"="<server_name>" \
     "dwAdminLogin"="<admin_username>" "dwAdminPassword"="<password>" \ 
     "storageAccountName"="<storage_account_name>" \
     "analysisServerName"="<analysis_server_name>" \
     "analysisServerAdmin"="user@contoso.com"
    ```

    - <span data-ttu-id="59f08-323">Параметр `storageAccountName` должен следовать [правилам именования](../../best-practices/naming-conventions.md#naming-rules-and-restrictions) для учетных записей хранения.</span><span class="sxs-lookup"><span data-stu-id="59f08-323">The `storageAccountName` parameter must follow the [naming rules](../../best-practices/naming-conventions.md#naming-rules-and-restrictions) for Storage accounts.</span></span>
    - <span data-ttu-id="59f08-324">Для параметра `analysisServerAdmin` используйте имя участника-пользователя Azure Active Directory (UPN).</span><span class="sxs-lookup"><span data-stu-id="59f08-324">For the `analysisServerAdmin` parameter, use your Azure Active Directory user principal name (UPN).</span></span>

4. <span data-ttu-id="59f08-325">Проверьте развертывание на портале Azure, просмотрев ресурсы в группе ресурсов.</span><span class="sxs-lookup"><span data-stu-id="59f08-325">Verify the deployment in the Azure portal by reviewing the resources in the resource group.</span></span> <span data-ttu-id="59f08-326">Вы должны увидеть учетную запись хранения, экземпляр хранилища данных Azure SQL и экземпляр службы Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-326">You should see a storage account, Azure SQL Data Warehouse instance, and Analysis Services instance.</span></span>

5. <span data-ttu-id="59f08-327">Используйте портал Azure, чтобы получить ключ доступа для учетной записи хранения.</span><span class="sxs-lookup"><span data-stu-id="59f08-327">Use the Azure portal to get the access key for the storage account.</span></span> <span data-ttu-id="59f08-328">Выберите учетную запись хранения, чтобы открыть ее.</span><span class="sxs-lookup"><span data-stu-id="59f08-328">Select the storage account to open it.</span></span> <span data-ttu-id="59f08-329">В разделе **Параметры** выберите **Ключи доступа**.</span><span class="sxs-lookup"><span data-stu-id="59f08-329">Under **Settings**, select **Access keys**.</span></span> <span data-ttu-id="59f08-330">Скопируйте значение первичного ключа.</span><span class="sxs-lookup"><span data-stu-id="59f08-330">Copy the primary key value.</span></span> <span data-ttu-id="59f08-331">Он понадобится на следующем шаге.</span><span class="sxs-lookup"><span data-stu-id="59f08-331">You will use it in the next step.</span></span>

### <a name="export-the-source-data-to-azure-blob-storage"></a><span data-ttu-id="59f08-332">Экспорт исходных данных в хранилище больших двоичных объектов Azure</span><span class="sxs-lookup"><span data-stu-id="59f08-332">Export the source data to Azure Blob storage</span></span> 

<span data-ttu-id="59f08-333">На этом этапе вы запустите сценарий PowerShell, который использует bcp для экспорта базы данных SQL в неструктурированные файлы на виртуальной машине, а затем использует AzCopy для копирования этих файлов в хранилище больших двоичных объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-333">In this step, you will run a PowerShell script that uses bcp to export the SQL database to flat files on the VM, and then uses AzCopy to copy those files into Azure Blob Storage.</span></span>

1. <span data-ttu-id="59f08-334">Используйте удаленный рабочий стол для подключения к моделируемой виртуальной машине.</span><span class="sxs-lookup"><span data-stu-id="59f08-334">Use Remote Desktop to connect to the simulated on-premises VM.</span></span>

2. <span data-ttu-id="59f08-335">При входе в виртуальную машину запустите следующие команды из окна PowerShell.</span><span class="sxs-lookup"><span data-stu-id="59f08-335">While logged into the VM, run the following commands from a PowerShell window.</span></span>  

    ```powershell
    cd 'C:\SampleDataFiles\reference-architectures\data\enterprise_bi_sqldw\onprem'

    .\Load_SourceData_To_Blob.ps1 -File .\sql_scripts\db_objects.txt -Destination 'https://<storage_account_name>.blob.core.windows.net/wwi' -StorageAccountKey '<storage_account_key>'
    ```

    <span data-ttu-id="59f08-336">Для параметра `Destination` замените `<storage_account_name>` на имя созданной ранее учетной записи хранения.</span><span class="sxs-lookup"><span data-stu-id="59f08-336">For the `Destination` parameter, replace `<storage_account_name>` with the name the Storage account that you created previously.</span></span> <span data-ttu-id="59f08-337">Для параметра `StorageAccountKey` используйте ключ доступа для этой учетной записи хранения.</span><span class="sxs-lookup"><span data-stu-id="59f08-337">For the `StorageAccountKey` parameter, use the access key for that Storage account.</span></span>

3. <span data-ttu-id="59f08-338">Перейдя к учетной записи хранения, выбрав службу BLOB-объектов и открыв контейнер `wwi` на портале Azure, убедитесь, что исходные данные были скопированы в хранилище больших двоичных объектов.</span><span class="sxs-lookup"><span data-stu-id="59f08-338">In the Azure portal, verify that the source data was copied to Blob storage by navigating to the storage account, selecting the Blob service, and opening the `wwi` container.</span></span> <span data-ttu-id="59f08-339">Вы должны увидеть список таблиц, которые начинаются с `WorldWideImporters_Application_*`.</span><span class="sxs-lookup"><span data-stu-id="59f08-339">You should see a list of tables prefaced with `WorldWideImporters_Application_*`.</span></span>

### <a name="run-the-data-warehouse-scripts"></a><span data-ttu-id="59f08-340">Выполнение скриптов хранилища данных</span><span class="sxs-lookup"><span data-stu-id="59f08-340">Run the data warehouse scripts</span></span>

1. <span data-ttu-id="59f08-341">Во время сеанса удаленного рабочего стола запустите SQL Server Management Studio (SSMS).</span><span class="sxs-lookup"><span data-stu-id="59f08-341">From your Remote Desktop session, launch SQL Server Management Studio (SSMS).</span></span> 

2. <span data-ttu-id="59f08-342">Подключение к хранилищу данных SQL</span><span class="sxs-lookup"><span data-stu-id="59f08-342">Connect to SQL Data Warehouse</span></span>

    - <span data-ttu-id="59f08-343">Тип сервера: ядро СУБД</span><span class="sxs-lookup"><span data-stu-id="59f08-343">Server type: Database Engine</span></span>
    
    - <span data-ttu-id="59f08-344">Имя сервера: `<dwServerName>.database.windows.net`, где `<dwServerName>` — имя, указанное при развертывании ресурсов Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-344">Server name: `<dwServerName>.database.windows.net`, where `<dwServerName>` is the name that you specified when you deployed the Azure resources.</span></span> <span data-ttu-id="59f08-345">Его можно получить на портале Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-345">You can get this name from the Azure portal.</span></span>
    
    - <span data-ttu-id="59f08-346">Аутентификация: проверка подлинности SQL Server.</span><span class="sxs-lookup"><span data-stu-id="59f08-346">Authentication: SQL Server Authentication.</span></span> <span data-ttu-id="59f08-347">Используйте учетные данные, указанные при развертывании ресурсов Azure, в параметрах `dwAdminLogin` и `dwAdminPassword`.</span><span class="sxs-lookup"><span data-stu-id="59f08-347">Use the credentials that you specified when you deployed the Azure resources, in the `dwAdminLogin` and `dwAdminPassword` parameters.</span></span>

2. <span data-ttu-id="59f08-348">Перейдите к папке `C:\SampleDataFiles\reference-architectures\data\enterprise_bi_sqldw\azure\sqldw_scripts` на виртуальной машине.</span><span class="sxs-lookup"><span data-stu-id="59f08-348">Navigate to the `C:\SampleDataFiles\reference-architectures\data\enterprise_bi_sqldw\azure\sqldw_scripts` folder on the VM.</span></span> <span data-ttu-id="59f08-349">Вы будете исполнять скрипты в этой папке в порядке от `STEP_1` до `STEP_7`.</span><span class="sxs-lookup"><span data-stu-id="59f08-349">You will execute the scripts in this folder in numerical order, `STEP_1` through `STEP_7`.</span></span>

3. <span data-ttu-id="59f08-350">Выберите в SSMS базу данных `master` и откройте скрипт `STEP_1`.</span><span class="sxs-lookup"><span data-stu-id="59f08-350">Select the `master` database in SSMS and open the `STEP_1` script.</span></span> <span data-ttu-id="59f08-351">Измените значение пароля в следующей строке, а затем выполните сценарий.</span><span class="sxs-lookup"><span data-stu-id="59f08-351">Change the value of the password in the following line, then execute the script.</span></span>

    ```sql
    CREATE LOGIN LoaderRC20 WITH PASSWORD = '<change this value>';
    ```

4. <span data-ttu-id="59f08-352">Выберите в SSMS базу данных `wwi`.</span><span class="sxs-lookup"><span data-stu-id="59f08-352">Select the `wwi` database in SSMS.</span></span> <span data-ttu-id="59f08-353">Откройте сценарий `STEP_2` и выполните его.</span><span class="sxs-lookup"><span data-stu-id="59f08-353">Open the `STEP_2` script and execute the script.</span></span> <span data-ttu-id="59f08-354">Если возникает сообщение об ошибке, убедитесь, что выполняется сценарий базы данных `wwi`, а не `master`.</span><span class="sxs-lookup"><span data-stu-id="59f08-354">If you get an error, make sure you are running the script against the `wwi` database and not `master`.</span></span>

5. <span data-ttu-id="59f08-355">Откройте новое соединение с хранилищем данных SQL, используя пользователя `LoaderRC20` и пароль, указанный в сценарии `STEP_1`.</span><span class="sxs-lookup"><span data-stu-id="59f08-355">Open a new connection to SQL Data Warehouse, using the `LoaderRC20` user and the password indicated in the `STEP_1` script.</span></span>

6. <span data-ttu-id="59f08-356">С помощью этого подключения откройте сценарий `STEP_3`.</span><span class="sxs-lookup"><span data-stu-id="59f08-356">Using this connection, open the `STEP_3` script.</span></span> <span data-ttu-id="59f08-357">Установите в сценарии следующие значения:</span><span class="sxs-lookup"><span data-stu-id="59f08-357">Set the following values in the script:</span></span>

    - <span data-ttu-id="59f08-358">SECRET: введите ключ доступа к учетной записи хранения.</span><span class="sxs-lookup"><span data-stu-id="59f08-358">SECRET: Use the access key for your storage account.</span></span>
    - <span data-ttu-id="59f08-359">LOCATION: используйте имя учетной записи хранения следующим образом: `wasbs://wwi@<storage_account_name>.blob.core.windows.net`.</span><span class="sxs-lookup"><span data-stu-id="59f08-359">LOCATION: Use the name of the storage account as follows: `wasbs://wwi@<storage_account_name>.blob.core.windows.net`.</span></span>

7. <span data-ttu-id="59f08-360">Используя это же подключение, последовательно выполняйте сценарии от `STEP_4` до `STEP_7`.</span><span class="sxs-lookup"><span data-stu-id="59f08-360">Using the same connection, execute scripts `STEP_4` through `STEP_7` sequentially.</span></span> <span data-ttu-id="59f08-361">Перед запуском следующего сценария убедитесь, что каждый сценарий выполняется успешно.</span><span class="sxs-lookup"><span data-stu-id="59f08-361">Verify that each script completes successfully before running the next.</span></span>

<span data-ttu-id="59f08-362">В SMSS вы должны увидеть набор таблиц `prd.*` в базе данных `wwi`.</span><span class="sxs-lookup"><span data-stu-id="59f08-362">In SMSS, you should see a set of `prd.*` tables in the `wwi` database.</span></span> <span data-ttu-id="59f08-363">Чтобы убедиться, что данные были созданы, выполните следующий запрос:</span><span class="sxs-lookup"><span data-stu-id="59f08-363">To verify that the data was generated, run the following query:</span></span> 

```sql
SELECT TOP 10 * FROM prd.CityDimensions
```

## <a name="build-the-analysis-services-model"></a><span data-ttu-id="59f08-364">Создание модели Analysis Services</span><span class="sxs-lookup"><span data-stu-id="59f08-364">Build the Analysis Services model</span></span>

<span data-ttu-id="59f08-365">На этом этапе вы создадите табличную модель, которая импортирует данные из хранилища данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-365">In this step, you will create a tabular model that imports data from the data warehouse.</span></span> <span data-ttu-id="59f08-366">Затем вы развернете модель в Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-366">Then you will deploy the model to Azure Analysis Services.</span></span>

1. <span data-ttu-id="59f08-367">Во время сеанса удаленного рабочего стола запустите средства SQL Server Data Tools 2015.</span><span class="sxs-lookup"><span data-stu-id="59f08-367">From your Remote Desktop session, launch SQL Server Data Tools 2015.</span></span>

2. <span data-ttu-id="59f08-368">Выберите **Файл** > **Создать** > **Проект**.</span><span class="sxs-lookup"><span data-stu-id="59f08-368">Select **File** > **New** > **Project**.</span></span>

3. <span data-ttu-id="59f08-369">В диалоговом окне **Создать проект** в разделе **Шаблоны** выберите **Бизнес-аналитика** > **Analysis Services** > **Табличный проект служб Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="59f08-369">In the **New Project** dialog, under **Templates**, select  **Business Intelligence** > **Analysis Services** > **Analysis Services Tabular Project**.</span></span> 

4. <span data-ttu-id="59f08-370">Назовите проект и нажмите кнопку **ОК**.</span><span class="sxs-lookup"><span data-stu-id="59f08-370">Name the project and click **OK**.</span></span>

5. <span data-ttu-id="59f08-371">В диалоговом окне **Конструктор табличных моделей** выберите **Интегрированная рабочая область** и установите **Уровень совместимости** на `SQL Server 2017 / Azure Analysis Services (1400)`.</span><span class="sxs-lookup"><span data-stu-id="59f08-371">In the **Tabular model designer** dialog, select **Integrated workspace**  and set **Compatibility level** to `SQL Server 2017 / Azure Analysis Services (1400)`.</span></span> <span data-ttu-id="59f08-372">Последовательно выберите **ОК**.</span><span class="sxs-lookup"><span data-stu-id="59f08-372">Click **OK**.</span></span>

6. <span data-ttu-id="59f08-373">В окне **Обозреватель табличных моделей** щелкните правой кнопкой мыши проект и выберите **Импорт из источника данных**.</span><span class="sxs-lookup"><span data-stu-id="59f08-373">In the **Tabular Model Explorer** window, right-click the project and select **Import from Data Source**.</span></span>

7. <span data-ttu-id="59f08-374">Выберите **Хранилище данных SQL Azure** и нажмите **Подключить**.</span><span class="sxs-lookup"><span data-stu-id="59f08-374">Select **Azure SQL Data Warehouse** and click **Connect**.</span></span>

8. <span data-ttu-id="59f08-375">Для **Server** введите полное имя сервера хранилища данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-375">For **Server**, enter the fully qualified name of your Azure SQL Data Warehouse server.</span></span> <span data-ttu-id="59f08-376">Для **Database** введите `wwi`.</span><span class="sxs-lookup"><span data-stu-id="59f08-376">For **Database**, enter `wwi`.</span></span> <span data-ttu-id="59f08-377">Последовательно выберите **ОК**.</span><span class="sxs-lookup"><span data-stu-id="59f08-377">Click **OK**.</span></span>

9. <span data-ttu-id="59f08-378">В следующем диалоговом окне выберите аутентификацию **базы данных**, введите имя пользователя и пароль хранилища данных SQL Azure и нажмите **ОК**.</span><span class="sxs-lookup"><span data-stu-id="59f08-378">In the next dialog, choose **Database** authentication and enter your Azure SQL Data Warehouse user name and password, and click **OK**.</span></span>

10. <span data-ttu-id="59f08-379">В диалоговом окне **Навигатор** установите флажки для **prd.CityDimensions**, **prd.DateDimensions** и **prd.SalesFact**.</span><span class="sxs-lookup"><span data-stu-id="59f08-379">In the **Navigator** dialog, select the checkboxes for **prd.CityDimensions**, **prd.DateDimensions**, and **prd.SalesFact**.</span></span> 

    ![](./images/analysis-services-import.png)

11. <span data-ttu-id="59f08-380">Нажмите кнопку **Загрузить**.</span><span class="sxs-lookup"><span data-stu-id="59f08-380">Click **Load**.</span></span> <span data-ttu-id="59f08-381">После завершения обработки нажмите кнопку **Закрыть**.</span><span class="sxs-lookup"><span data-stu-id="59f08-381">When processing is complete, click **Close**.</span></span> <span data-ttu-id="59f08-382">Теперь вы должны увидеть табличное представление данных.</span><span class="sxs-lookup"><span data-stu-id="59f08-382">You should now see a tabular view of the data.</span></span>

12. <span data-ttu-id="59f08-383">В окне **Обозреватель табличных моделей** нажмите правой кнопкой мыши проект и выберите **Представление модели** > **Представление диаграммы**.</span><span class="sxs-lookup"><span data-stu-id="59f08-383">In the **Tabular Model Explorer** window, right-click the project and select **Model View** > **Diagram View**.</span></span>

13. <span data-ttu-id="59f08-384">Чтобы создать связь, перетащите поле **[prd.SalesFact].[WWI City ID]** в поле **[prd.CityDimensions].[WWI City ID]**.</span><span class="sxs-lookup"><span data-stu-id="59f08-384">Drag the **[prd.SalesFact].[WWI City ID]** field to the **[prd.CityDimensions].[WWI City ID]** field to create a relationship.</span></span>  

14. <span data-ttu-id="59f08-385">Перетащите поле **[prd.SalesFact].[Invoice Date Key]** в поле **[prd.DateDimensions].[Date]**.</span><span class="sxs-lookup"><span data-stu-id="59f08-385">Drag the **[prd.SalesFact].[Invoice Date Key]** field to the **[prd.DateDimensions].[Date]** field.</span></span>  
    ![](./images/analysis-services-relations.png)

15. <span data-ttu-id="59f08-386">В меню **Файл** выберите **Сохранить все**.</span><span class="sxs-lookup"><span data-stu-id="59f08-386">From the **File** menu, choose **Save All**.</span></span>  

16. <span data-ttu-id="59f08-387">В **обозревателе решений** щелкните правой кнопкой мыши проект и выберите **Свойства**.</span><span class="sxs-lookup"><span data-stu-id="59f08-387">In **Solution Explorer**, right-click the project and select **Properties**.</span></span> 

17. <span data-ttu-id="59f08-388">В разделе **Сервер** введите URL-адрес своего экземпляра службы Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-388">Under **Server**, enter the URL of your Azure Analysis Services instance.</span></span> <span data-ttu-id="59f08-389">Его можно получить на портале Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-389">You can get this value from the Azure Portal.</span></span> <span data-ttu-id="59f08-390">На портале выберите ресурс службы Analysis Services, нажмите панель "Обзор" и найдите свойство **Server Name**.</span><span class="sxs-lookup"><span data-stu-id="59f08-390">In the portal, select the Analysis Services resource, click the Overview pane, and look for the **Server Name** property.</span></span> <span data-ttu-id="59f08-391">Он будет выглядеть аналогично `asazure://westus.asazure.windows.net/contoso`.</span><span class="sxs-lookup"><span data-stu-id="59f08-391">It will be similar to `asazure://westus.asazure.windows.net/contoso`.</span></span> <span data-ttu-id="59f08-392">Последовательно выберите **ОК**.</span><span class="sxs-lookup"><span data-stu-id="59f08-392">Click **OK**.</span></span>

    ![](./images/analysis-services-properties.png)

18. <span data-ttu-id="59f08-393">В **обозревателе решений** щелкните правой кнопкой мыши проект и выберите пункт **Развернуть**.</span><span class="sxs-lookup"><span data-stu-id="59f08-393">In **Solution Explorer**, right-click the project and select **Deploy**.</span></span> <span data-ttu-id="59f08-394">При появлении запроса войдите в Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-394">Sign into Azure if prompted.</span></span> <span data-ttu-id="59f08-395">После завершения обработки нажмите кнопку **Закрыть**.</span><span class="sxs-lookup"><span data-stu-id="59f08-395">When processing is complete, click **Close**.</span></span>

19. <span data-ttu-id="59f08-396">На портале Azure просмотрите сведения о вашем экземпляре Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-396">In the Azure portal, view the details for your Azure Analysis Services instance.</span></span> <span data-ttu-id="59f08-397">Убедитесь, что ваша модель отображается в списке моделей.</span><span class="sxs-lookup"><span data-stu-id="59f08-397">Verify that your model appears in the list of models.</span></span>

    ![](./images/analysis-services-models.png)

## <a name="analyze-the-data-in-power-bi-desktop"></a><span data-ttu-id="59f08-398">Анализ данных в Power BI Desktop</span><span class="sxs-lookup"><span data-stu-id="59f08-398">Analyze the data in Power BI Desktop</span></span>

<span data-ttu-id="59f08-399">На этом этапе вы будете использовать Power BI для создания отчета из данных в Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="59f08-399">In this step, you will use Power BI to create a report from the data in Analysis Services.</span></span>

1. <span data-ttu-id="59f08-400">Во время сеанса удаленного рабочего стола запустите Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="59f08-400">From your Remote Desktop session, launch Power BI Desktop.</span></span>

2. <span data-ttu-id="59f08-401">На экране приветствия нажмите **Получение данных**.</span><span class="sxs-lookup"><span data-stu-id="59f08-401">In the Welcome Scren, click **Get Data**.</span></span>

3. <span data-ttu-id="59f08-402">Выберите **Azure** > **База данных Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="59f08-402">Select **Azure** > **Azure Analysis Services database**.</span></span> <span data-ttu-id="59f08-403">Добавьте новый отчет, щелкнув **Подключить**</span><span class="sxs-lookup"><span data-stu-id="59f08-403">Click **Connect**</span></span>

    ![](./images/power-bi-get-data.png)

4. <span data-ttu-id="59f08-404">Введите URL-адрес экземпляра службы Analysis Services, а затем нажмите кнопку **ОК**.</span><span class="sxs-lookup"><span data-stu-id="59f08-404">Enter the URL of your Analysis Services instance, then click **OK**.</span></span> <span data-ttu-id="59f08-405">При появлении запроса войдите в Azure.</span><span class="sxs-lookup"><span data-stu-id="59f08-405">Sign into Azure if prompted.</span></span>

5. <span data-ttu-id="59f08-406">В диалоговом окне **Навигатор** разверните проект таблицы, который вы развертывали, выберите созданную модель и нажмите кнопку **ОК**.</span><span class="sxs-lookup"><span data-stu-id="59f08-406">In the **Navigator** dialog, expand the tabular project that you deployed, select the model that you created, and click **OK**.</span></span>

2. <span data-ttu-id="59f08-407">На панели **визуализации** выберите значок **Линейчатая диаграмма с накоплением**.</span><span class="sxs-lookup"><span data-stu-id="59f08-407">In the **Visualizations** pane, select the **Stacked Bar Chart** icon.</span></span> <span data-ttu-id="59f08-408">В представлении "Отчет" измените размер визуализации, чтобы ее увеличить.</span><span class="sxs-lookup"><span data-stu-id="59f08-408">In the Report view, resize the visualization to make it larger.</span></span>

6. <span data-ttu-id="59f08-409">В области **Поля** разверните **prd.CityDimensions**.</span><span class="sxs-lookup"><span data-stu-id="59f08-409">In the **Fields** pane, expand **prd.CityDimensions**.</span></span>

7. <span data-ttu-id="59f08-410">Перетащите **prd.CityDimensions** > **Идентификатор города WWI** в область **Ось**.</span><span class="sxs-lookup"><span data-stu-id="59f08-410">Drag **prd.CityDimensions** > **WWI City ID** to the **Axis** well.</span></span>

8. <span data-ttu-id="59f08-411">Перетащите **prd.CityDimensions** > **Город** в **Условные обозначения**.</span><span class="sxs-lookup"><span data-stu-id="59f08-411">Drag **prd.CityDimensions** > **City** to the **Legend** well.</span></span>

9. <span data-ttu-id="59f08-412">В области **Поля** разверните узел **prd.SalesFact**.</span><span class="sxs-lookup"><span data-stu-id="59f08-412">In the **Fields** pane, expand **prd.SalesFact**.</span></span>

10. <span data-ttu-id="59f08-413">Перетащите **prd.SalesFact** > **Общая сумма без учета налогов** в **Значение**.</span><span class="sxs-lookup"><span data-stu-id="59f08-413">Drag **prd.SalesFact** > **Total Excluding Tax** to the **Value** well.</span></span>

    ![](./images/power-bi-visualization.png)

11. <span data-ttu-id="59f08-414">В **фильтрах уровня визуальных элементов** выберите **идентификатор города WWI**.</span><span class="sxs-lookup"><span data-stu-id="59f08-414">Under **Visual Level Filters**, select **WWI City ID**.</span></span>

12. <span data-ttu-id="59f08-415">Задайте **Тип фильтра** как `Top N` и установите **Показать элементы** как `Top 10`.</span><span class="sxs-lookup"><span data-stu-id="59f08-415">Set the **Filter Type** to `Top N`, and set **Show Items** to `Top 10`.</span></span>

13. <span data-ttu-id="59f08-416">Перетащите **prd.SalesFact** > **Общая сумма без учета налога** в **По значению**.</span><span class="sxs-lookup"><span data-stu-id="59f08-416">Drag **prd.SalesFact** > **Total Excluding Tax** to the **By Value** well</span></span>

    ![](./images/power-bi-visualization2.png)

14. <span data-ttu-id="59f08-417">Нажмите кнопку **Применить фильтр**.</span><span class="sxs-lookup"><span data-stu-id="59f08-417">Click **Apply Filter**.</span></span> <span data-ttu-id="59f08-418">Визуализация показывает 10 лучших объемов продаж по городу.</span><span class="sxs-lookup"><span data-stu-id="59f08-418">The visualization shows the top 10 total sales by city.</span></span>

    ![](./images/power-bi-report.png)

<span data-ttu-id="59f08-419">Дополнительные сведения о Power BI Desktop см. в статье [Начало работы с Power BI Desktop](/power-bi/desktop-getting-started).</span><span class="sxs-lookup"><span data-stu-id="59f08-419">To learn more about Power BI Desktop, see [Getting started with Power BI Desktop](/power-bi/desktop-getting-started).</span></span>

## <a name="next-steps"></a><span data-ttu-id="59f08-420">Дополнительная информация</span><span class="sxs-lookup"><span data-stu-id="59f08-420">Next steps</span></span>

- <span data-ttu-id="59f08-421">Для получения дополнительных сведений об этой эталонной архитектуре посетите наш [репозиторий GitHub][ref-arch-repo-folder].</span><span class="sxs-lookup"><span data-stu-id="59f08-421">For more information about this reference architecture, visit our [GitHub repository][ref-arch-repo-folder].</span></span>
- <span data-ttu-id="59f08-422">Узнать больше о [стандартных блоках Azure][azbb-repo].</span><span class="sxs-lookup"><span data-stu-id="59f08-422">Learn about the [Azure Building Blocks][azbb-repo].</span></span>

<!-- links -->

[azure-cli-2]: /azure/install-azure-cli
[azbb-repo]: https://github.com/mspnp/template-building-blocks
[azbb-wiki]: https://github.com/mspnp/template-building-blocks/wiki/Install-Azure-Building-Blocks
[github-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[ref-arch-repo]: https://github.com/mspnp/reference-architectures
[ref-arch-repo-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database
