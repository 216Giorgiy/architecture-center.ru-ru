---
title: Корпоративная бизнес-аналитика
titleSuffix: Azure Reference Architectures
description: Использование Azure для получения бизнес-информацию на основе реляционных данных, хранимых локально.
author: MikeWasson
ms.date: 11/06/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: seodec18
ms.openlocfilehash: 14adb9de7f46c3196e893451859385d87212b375
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/20/2019
ms.locfileid: "58243865"
---
# <a name="enterprise-bi-in-azure-with-sql-data-warehouse"></a><span data-ttu-id="15e16-103">Корпоративная бизнес-аналитика в Azure с использованием Хранилища данных SQL</span><span class="sxs-lookup"><span data-stu-id="15e16-103">Enterprise BI in Azure with SQL Data Warehouse</span></span>

<span data-ttu-id="15e16-104">Эта эталонная архитектура реализует конвейер [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (извлечение — загрузка — преобразование), который перемещает данные из локальной базы данных SQL Server в хранилище данных SQL и преобразует данные для анализа.</span><span class="sxs-lookup"><span data-stu-id="15e16-104">This reference architecture implements an [extract, load, and transform (ELT)](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) pipeline that moves data from an on-premises SQL Server database into SQL Data Warehouse and transforms the data for analysis.</span></span>

<span data-ttu-id="15e16-105">Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github-folder].</span><span class="sxs-lookup"><span data-stu-id="15e16-105">A reference implementation for this architecture is available on [GitHub][github-folder].</span></span>

![Схема архитектуры для корпоративной бизнес-аналитики в Azure с использованием Хранилища данных SQL](./images/enterprise-bi-sqldw.png)

<span data-ttu-id="15e16-107">**Сценарий**. Организация имеет большой набор данных OLTP, хранящийся локально в базе данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="15e16-107">**Scenario**: An organization has a large OLTP data set stored in a SQL Server database on premises.</span></span> <span data-ttu-id="15e16-108">Организация хочет использовать хранилище данных SQL для проведения анализа с использованием Power BI.</span><span class="sxs-lookup"><span data-stu-id="15e16-108">The organization wants to use SQL Data Warehouse to perform analysis using Power BI.</span></span>

<span data-ttu-id="15e16-109">Эта эталонная архитектура предназначена для однократных заданий или заданий по требованию.</span><span class="sxs-lookup"><span data-stu-id="15e16-109">This reference architecture is designed for one-time or on-demand jobs.</span></span> <span data-ttu-id="15e16-110">Если необходимо регулярно перемещать данные (ежечасно или ежедневно), рекомендуется использовать фабрику данных Azure для автоматизации рабочего процесса.</span><span class="sxs-lookup"><span data-stu-id="15e16-110">If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow.</span></span> <span data-ttu-id="15e16-111">Описание эталонной архитектуры, в которой используется Фабрика данных, см. в статье [Автоматизированная корпоративная бизнес-аналитика с использованием Хранилища данных SQL и Фабрики данных Azure][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="15e16-111">For a reference architecture that uses Data Factory, see [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="architecture"></a><span data-ttu-id="15e16-112">Архитектура</span><span class="sxs-lookup"><span data-stu-id="15e16-112">Architecture</span></span>

<span data-ttu-id="15e16-113">Архитектура состоит из следующих компонентов:</span><span class="sxs-lookup"><span data-stu-id="15e16-113">The architecture consists of the following components.</span></span>

### <a name="data-source"></a><span data-ttu-id="15e16-114">Источник данных</span><span class="sxs-lookup"><span data-stu-id="15e16-114">Data source</span></span>

<span data-ttu-id="15e16-115">**SQL Server.**</span><span class="sxs-lookup"><span data-stu-id="15e16-115">**SQL Server**.</span></span> <span data-ttu-id="15e16-116">Исходные данные размещаются локально в базе данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="15e16-116">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="15e16-117">Чтобы имитировать локальную среду, скрипты развертывания для этой архитектуры предоставляют виртуальную машину в Azure с установленной платформой SQL Server.</span><span class="sxs-lookup"><span data-stu-id="15e16-117">To simulate the on-premises environment, the deployment scripts for this architecture provision a VM in Azure with SQL Server installed.</span></span> <span data-ttu-id="15e16-118">В качестве исходных данных используется [пример базы данных OLTP Wide World Importers][wwi].</span><span class="sxs-lookup"><span data-stu-id="15e16-118">The [Wide World Importers OLTP sample database][wwi] is used as the source data.</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="15e16-119">Прием и хранение данных</span><span class="sxs-lookup"><span data-stu-id="15e16-119">Ingestion and data storage</span></span>

<span data-ttu-id="15e16-120">**Хранилище больших двоичных объектов**.</span><span class="sxs-lookup"><span data-stu-id="15e16-120">**Blob Storage**.</span></span> <span data-ttu-id="15e16-121">Хранилище больших двоичных объектов используется в качестве промежуточной области для копирования данных перед загрузкой в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-121">Blob storage is used as a staging area to copy the data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="15e16-122">**Хранилище данных Azure SQL.**</span><span class="sxs-lookup"><span data-stu-id="15e16-122">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="15e16-123">[Хранилище данных SQL](/azure/sql-data-warehouse/) — распределенная система, предназначенная для анализа больших объемов данных.</span><span class="sxs-lookup"><span data-stu-id="15e16-123">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="15e16-124">Она поддерживает массовую параллельную обработку (MPP), что делает ее пригодной для запуска высокопроизводительной аналитики.</span><span class="sxs-lookup"><span data-stu-id="15e16-124">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span>

### <a name="analysis-and-reporting"></a><span data-ttu-id="15e16-125">Анализ и создание отчетов</span><span class="sxs-lookup"><span data-stu-id="15e16-125">Analysis and reporting</span></span>

<span data-ttu-id="15e16-126">**Службы Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="15e16-126">**Azure Analysis Services**.</span></span> <span data-ttu-id="15e16-127">[Analysis Services](/azure/analysis-services/) — полностью управляемая служба, которая предоставляет возможности моделирования данных.</span><span class="sxs-lookup"><span data-stu-id="15e16-127">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="15e16-128">Используйте службу Analysis Services для создания семантической модели, которую могут запрашивать пользователи.</span><span class="sxs-lookup"><span data-stu-id="15e16-128">Use Analysis Services to create a semantic model that users can query.</span></span> <span data-ttu-id="15e16-129">Служба Analysis Services особенно полезна в сценарии информационной панели бизнес-аналитики.</span><span class="sxs-lookup"><span data-stu-id="15e16-129">Analysis Services is especially useful in a BI dashboard scenario.</span></span> <span data-ttu-id="15e16-130">В этой архитектуре служба Analysis Services считывает данные из хранилища данных для обработки семантической модели и эффективно обслуживает запросы информационной панели.</span><span class="sxs-lookup"><span data-stu-id="15e16-130">In this architecture, Analysis Services reads data from the data warehouse to process the semantic model, and efficiently serves dashboard queries.</span></span> <span data-ttu-id="15e16-131">Она также поддерживает гибкий параллелизм путем масштабирования реплик, чтобы быстрее обрабатывать запросы.</span><span class="sxs-lookup"><span data-stu-id="15e16-131">It also supports elastic concurrency, by scaling out replicas for faster query processing.</span></span>

<span data-ttu-id="15e16-132">В настоящее время Azure Analysis Services поддерживает табличные модели, но не поддерживает многомерные.</span><span class="sxs-lookup"><span data-stu-id="15e16-132">Currently, Azure Analysis Services supports tabular models but not multidimensional models.</span></span> <span data-ttu-id="15e16-133">В табличных моделях используются конструкции реляционного моделирования (таблицы и столбцы), тогда как в многомерных моделях используются моделирующие конструкции OLAP (кубы, размеры и меры).</span><span class="sxs-lookup"><span data-stu-id="15e16-133">Tabular models use relational modeling constructs (tables and columns), whereas multidimensional models use OLAP modeling constructs (cubes, dimensions, and measures).</span></span> <span data-ttu-id="15e16-134">Если требуются многомерные модели, используйте SQL Server Analysis Services (SSAS).</span><span class="sxs-lookup"><span data-stu-id="15e16-134">If you require multidimensional models, use SQL Server Analysis Services (SSAS).</span></span> <span data-ttu-id="15e16-135">Дополнительные сведения см. в разделе [Сравнение табличных и многомерных решений](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span><span class="sxs-lookup"><span data-stu-id="15e16-135">For more information, see [Comparing tabular and multidimensional solutions](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span></span>

<span data-ttu-id="15e16-136">**Power BI**.</span><span class="sxs-lookup"><span data-stu-id="15e16-136">**Power BI**.</span></span> <span data-ttu-id="15e16-137">Power BI — набор средств бизнес-аналитики для анализа информации о бизнесе.</span><span class="sxs-lookup"><span data-stu-id="15e16-137">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="15e16-138">В этой архитектуре он запрашивает семантическую модель, хранящуюся в службе Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="15e16-138">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="15e16-139">Authentication</span><span class="sxs-lookup"><span data-stu-id="15e16-139">Authentication</span></span>

<span data-ttu-id="15e16-140">**Azure Active Directory** (Azure AD) аутентифицирует пользователей, которые подключаются к серверу Analysis Services через Power BI.</span><span class="sxs-lookup"><span data-stu-id="15e16-140">**Azure Active Directory (Azure AD)** authenticates users who connect to the Analysis Services server through Power BI.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="15e16-141">Конвейер данных</span><span class="sxs-lookup"><span data-stu-id="15e16-141">Data pipeline</span></span>

<span data-ttu-id="15e16-142">В этой эталонной архитектуре в качестве источника данных используется база данных [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database).</span><span class="sxs-lookup"><span data-stu-id="15e16-142">This reference architecture uses the [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) sample database as a data source.</span></span> <span data-ttu-id="15e16-143">Конвейер данных состоит из перечисленных ниже этапов.</span><span class="sxs-lookup"><span data-stu-id="15e16-143">The data pipeline has the following stages:</span></span>

1. <span data-ttu-id="15e16-144">Экспортирование данных из SQL Server в неструктурированные файлы (утилита bcp).</span><span class="sxs-lookup"><span data-stu-id="15e16-144">Export the data from SQL Server to flat files (bcp utility).</span></span>
2. <span data-ttu-id="15e16-145">Копирование неструктурированных файлов в хранилище больших двоичных объектов Azure (AzCopy)</span><span class="sxs-lookup"><span data-stu-id="15e16-145">Copy the flat files to Azure Blob Storage (AzCopy).</span></span>
3. <span data-ttu-id="15e16-146">Загрузка данных в хранилище данных SQL (PolyBase).</span><span class="sxs-lookup"><span data-stu-id="15e16-146">Load the data into SQL Data Warehouse (PolyBase).</span></span>
4. <span data-ttu-id="15e16-147">Преобразование данных в схему типа "звезда" (T-SQL).</span><span class="sxs-lookup"><span data-stu-id="15e16-147">Transform the data into a star schema (T-SQL).</span></span>
5. <span data-ttu-id="15e16-148">Загрузка семантической модели в службу Analysis Services (средства SQL Server Data Tools).</span><span class="sxs-lookup"><span data-stu-id="15e16-148">Load a semantic model into Analysis Services (SQL Server Data Tools).</span></span>

![Схема конвейера корпоративной бизнес-аналитики](./images/enterprise-bi-sqldw-pipeline.png)

> [!NOTE]
> <span data-ttu-id="15e16-150">Для шагов 1 &ndash; 3 рассмотрите использование Redgate Data Platform Studio.</span><span class="sxs-lookup"><span data-stu-id="15e16-150">For steps 1 &ndash; 3, consider using Redgate Data Platform Studio.</span></span> <span data-ttu-id="15e16-151">Так как к Data Platform Studio применены наиболее подходящие оптимизации и исправления совместимости, это самый быстрый способ начать работу с хранилищем данных SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-151">Data Platform Studio applies the most appropriate compatibility fixes and optimizations, so it's the quickest way to get started with SQL Data Warehouse.</span></span> <span data-ttu-id="15e16-152">Дополнительную информацию см. в разделе [Загрузка данных с помощью Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span><span class="sxs-lookup"><span data-stu-id="15e16-152">For more information, see [Load data with Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span></span>
>

<span data-ttu-id="15e16-153">Следующие разделы описывают эти этапы более подробно.</span><span class="sxs-lookup"><span data-stu-id="15e16-153">The next sections describe these stages in more detail.</span></span>

### <a name="export-data-from-sql-server"></a><span data-ttu-id="15e16-154">Экспорт данных из SQL Server</span><span class="sxs-lookup"><span data-stu-id="15e16-154">Export data from SQL Server</span></span>

<span data-ttu-id="15e16-155">Программа массового копирования [bcp](/sql/tools/bcp-utility) — это быстрый способ создания неструктурированных текстовых файлов из таблиц SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-155">The [bcp](/sql/tools/bcp-utility) (bulk copy program) utility is a fast way to create flat text files from SQL tables.</span></span> <span data-ttu-id="15e16-156">На этом шаге выбираются столбцы, которые нужно экспортировать, но данные не надо преобразовывать.</span><span class="sxs-lookup"><span data-stu-id="15e16-156">In this step, you select the columns that you want to export, but don't transform the data.</span></span> <span data-ttu-id="15e16-157">Любые преобразования данных должны происходить в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-157">Any data transformations should happen in SQL Data Warehouse.</span></span>

<span data-ttu-id="15e16-158">**Рекомендации**</span><span class="sxs-lookup"><span data-stu-id="15e16-158">**Recommendations:**</span></span>

<span data-ttu-id="15e16-159">Если возможно, планируйте извлечение данных в часы с наименьшей загрузкой, чтобы свести к минимуму конфликт ресурсов в рабочей среде.</span><span class="sxs-lookup"><span data-stu-id="15e16-159">If possible, schedule data extraction during off-peak hours, to minimize resource contention in the production environment.</span></span>

<span data-ttu-id="15e16-160">Избегайте запуска bcp на сервере базы данных.</span><span class="sxs-lookup"><span data-stu-id="15e16-160">Avoid running bcp on the database server.</span></span> <span data-ttu-id="15e16-161">Вместо этого запустите его с другого компьютера.</span><span class="sxs-lookup"><span data-stu-id="15e16-161">Instead, run it from another machine.</span></span> <span data-ttu-id="15e16-162">Записывайте файлы на локальный диск.</span><span class="sxs-lookup"><span data-stu-id="15e16-162">Write the files to a local drive.</span></span> <span data-ttu-id="15e16-163">Убедитесь, что имеется достаточно ресурсов ввода-вывода для обработки параллельных операций записи.</span><span class="sxs-lookup"><span data-stu-id="15e16-163">Ensure that you have sufficient I/O resources to handle the concurrent writes.</span></span> <span data-ttu-id="15e16-164">Для обеспечения максимальной производительности экспортируйте файлы в специализированные высокоскоростные хранилища.</span><span class="sxs-lookup"><span data-stu-id="15e16-164">For best performance, export the files to dedicated fast storage drives.</span></span>

<span data-ttu-id="15e16-165">Вы можете ускорить сетевой перенос, сохранив экспортированные данные в сжатом формате Gzip.</span><span class="sxs-lookup"><span data-stu-id="15e16-165">You can speed up the network transfer by saving the exported data in Gzip compressed format.</span></span> <span data-ttu-id="15e16-166">Однако загрузка сжатых файлов в хранилище происходит медленнее, чем загрузка несжатых файлов, поэтому существует компромисс между более быстрой передачей сети и более быстрой загрузкой.</span><span class="sxs-lookup"><span data-stu-id="15e16-166">However, loading compressed files into the warehouse is slower than loading uncompressed files, so there is a tradeoff between faster network transfer versus faster loading.</span></span> <span data-ttu-id="15e16-167">Если решено использовать сжатие Gzip, не создавайте отдельные файлы Gzip.</span><span class="sxs-lookup"><span data-stu-id="15e16-167">If you decide to use Gzip compression, don't create a single Gzip file.</span></span> <span data-ttu-id="15e16-168">Вместо этого разделите данные на несколько сжатых файлов.</span><span class="sxs-lookup"><span data-stu-id="15e16-168">Instead, split the data into multiple compressed files.</span></span>

### <a name="copy-flat-files-into-blob-storage"></a><span data-ttu-id="15e16-169">Копирование неструктурированных файлов в хранилище больших двоичных объектов</span><span class="sxs-lookup"><span data-stu-id="15e16-169">Copy flat files into blob storage</span></span>

<span data-ttu-id="15e16-170">Утилита [AzCopy](/azure/storage/common/storage-use-azcopy) предназначена для высокопроизводительного копирования данных в хранилище больших двоичных объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="15e16-170">The [AzCopy](/azure/storage/common/storage-use-azcopy) utility is designed for high-performance copying of data into Azure blob storage.</span></span>

<span data-ttu-id="15e16-171">**Рекомендации**</span><span class="sxs-lookup"><span data-stu-id="15e16-171">**Recommendations:**</span></span>

<span data-ttu-id="15e16-172">Создайте учетную запись хранения в регионе, расположенном рядом с исходными данными.</span><span class="sxs-lookup"><span data-stu-id="15e16-172">Create the storage account in a region near the location of the source data.</span></span> <span data-ttu-id="15e16-173">Разверните учетную запись хранения и экземпляр хранилища данных SQL в том же регионе.</span><span class="sxs-lookup"><span data-stu-id="15e16-173">Deploy the storage account and the SQL Data Warehouse instance in the same region.</span></span>

<span data-ttu-id="15e16-174">Не запускайте AzCopy на том же компьютере, на котором выполняются производственные рабочие нагрузки, поскольку потребление процессора и ввода-вывода может влиять на рабочую нагрузку.</span><span class="sxs-lookup"><span data-stu-id="15e16-174">Don't run AzCopy on the same machine that runs your production workloads, because the CPU and I/O consumption can interfere with the production workload.</span></span>

<span data-ttu-id="15e16-175">Сначала проверьте загрузку, чтобы изучить скорость загрузки.</span><span class="sxs-lookup"><span data-stu-id="15e16-175">Test the upload first to see what the upload speed is like.</span></span> <span data-ttu-id="15e16-176">Чтобы указать количество параллельных операций копирования, в AzCopy можно использовать параметр /NC.</span><span class="sxs-lookup"><span data-stu-id="15e16-176">You can use the /NC option in AzCopy to specify the number of concurrent copy operations.</span></span> <span data-ttu-id="15e16-177">Чтобы настроить производительность, начните со значения по умолчанию и затем поэкспериментируйте с этим параметром.</span><span class="sxs-lookup"><span data-stu-id="15e16-177">Start with the default value, then experiment with this setting to tune the performance.</span></span> <span data-ttu-id="15e16-178">В среде с низкой пропускной способностью слишком много параллельных операций могут привести к сбою сетевого соединения и не допустить успешного завершения операций.</span><span class="sxs-lookup"><span data-stu-id="15e16-178">In a low-bandwidth environment, too many concurrent operations can overwhelm the network connection and prevent the operations from completing successfully.</span></span>

<span data-ttu-id="15e16-179">AzCopy перемещает данные в хранилище через общий доступ в Интернет.</span><span class="sxs-lookup"><span data-stu-id="15e16-179">AzCopy moves data to storage over the public internet.</span></span> <span data-ttu-id="15e16-180">Если это недостаточно быстро, рассмотрите создание схемы [ExpressRoute](/azure/expressroute/).</span><span class="sxs-lookup"><span data-stu-id="15e16-180">If this isn't fast enough, consider setting up an [ExpressRoute](/azure/expressroute/) circuit.</span></span> <span data-ttu-id="15e16-181">ExpressRoute — это служба, которая направляет данные с помощью выделенного частного подключения в Azure.</span><span class="sxs-lookup"><span data-stu-id="15e16-181">ExpressRoute is a service that routes your data through a dedicated private connection to Azure.</span></span> <span data-ttu-id="15e16-182">Если ваше сетевое соединение слишком медленное, то другой вариант заключается в физической отправке данных на диск в центр данных Azure.</span><span class="sxs-lookup"><span data-stu-id="15e16-182">Another option, if your network connection is too slow, is to physically ship the data on disk to an Azure datacenter.</span></span> <span data-ttu-id="15e16-183">Дополнительные сведения см. в разделе [Передача данных в Azure и обратно](/azure/architecture/data-guide/scenarios/data-transfer).</span><span class="sxs-lookup"><span data-stu-id="15e16-183">For more information, see [Transferring data to and from Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span></span>

<span data-ttu-id="15e16-184">Во время операции копирования AzCopy создает временный файл журнала, который позволяет AzCopy перезапустить операцию, если она прервется (например, из-за сетевой ошибки).</span><span class="sxs-lookup"><span data-stu-id="15e16-184">During a copy operation, AzCopy creates a temporary journal file, which enables AzCopy to restart the operation if it gets interrupted (for example, due to a network error).</span></span> <span data-ttu-id="15e16-185">Убедитесь, что для хранения файлов журнала на диске достаточно свободного места.</span><span class="sxs-lookup"><span data-stu-id="15e16-185">Make sure there is enough disk space to store the journal files.</span></span> <span data-ttu-id="15e16-186">Чтобы указать, где записываются файлы журнала, можно использовать параметр /Z.</span><span class="sxs-lookup"><span data-stu-id="15e16-186">You can use the /Z option to specify where the journal files are written.</span></span>

### <a name="load-data-into-sql-data-warehouse"></a><span data-ttu-id="15e16-187">Загрузка данных в хранилище данных SQL</span><span class="sxs-lookup"><span data-stu-id="15e16-187">Load data into SQL Data Warehouse</span></span>

<span data-ttu-id="15e16-188">Используйте [PolyBase](/sql/relational-databases/polybase/polybase-guide), чтобы загрузить файлы из хранилища больших двоичных объектов в хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="15e16-188">Use [PolyBase](/sql/relational-databases/polybase/polybase-guide) to load the files from blob storage into the data warehouse.</span></span> <span data-ttu-id="15e16-189">PolyBase предназначен для использования архитектуры MPP (массовой параллельной обработки) хранилища данных SQL, которая делает ее самым быстрым способом загрузки данных в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-189">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse, which makes it the fastest way to load data into SQL Data Warehouse.</span></span>

<span data-ttu-id="15e16-190">Загрузка данных — это двухэтапный процесс:</span><span class="sxs-lookup"><span data-stu-id="15e16-190">Loading the data is a two-step process:</span></span>

1. <span data-ttu-id="15e16-191">Создание набора внешних таблиц для данных.</span><span class="sxs-lookup"><span data-stu-id="15e16-191">Create a set of external tables for the data.</span></span> <span data-ttu-id="15e16-192">Внешняя таблица — это определение таблицы, которое указывает на данные, хранящиеся вне хранилища &mdash; в этом случае, неструктурированные файлы в хранилище памяти.</span><span class="sxs-lookup"><span data-stu-id="15e16-192">An external table is a table definition that points to data stored outside of the warehouse &mdash; in this case, the flat files in blob storage.</span></span> <span data-ttu-id="15e16-193">Этот этап не перемещает никаких данных в хранилище.</span><span class="sxs-lookup"><span data-stu-id="15e16-193">This step does not move any data into the warehouse.</span></span>
2. <span data-ttu-id="15e16-194">Создание промежуточных таблиц и загрузка данных в промежуточные таблицы.</span><span class="sxs-lookup"><span data-stu-id="15e16-194">Create staging tables, and load the data into the staging tables.</span></span> <span data-ttu-id="15e16-195">Этот этап копирует данные в хранилище.</span><span class="sxs-lookup"><span data-stu-id="15e16-195">This step copies the data into the warehouse.</span></span>

<span data-ttu-id="15e16-196">**Рекомендации**</span><span class="sxs-lookup"><span data-stu-id="15e16-196">**Recommendations:**</span></span>

<span data-ttu-id="15e16-197">Если имеется большой объем данных (более 1 ТБ) и используется рабочая нагрузка аналитики, которая выиграет от параллелизма, то рассмотрите возможности хранилища данных SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-197">Consider SQL Data Warehouse when you have large amounts of data (more than 1 TB) and are running an analytics workload that will benefit from parallelism.</span></span> <span data-ttu-id="15e16-198">Хранилище данных SQL не подходит для рабочих нагрузок OLTP или малых наборов данных (<250 ГБ).</span><span class="sxs-lookup"><span data-stu-id="15e16-198">SQL Data Warehouse is not a good fit for OLTP workloads or smaller data sets (< 250GB).</span></span> <span data-ttu-id="15e16-199">Для наборов данных менее 250 ГБ рассмотрите базу данных Azure SQL или SQL Server.</span><span class="sxs-lookup"><span data-stu-id="15e16-199">For data sets less than 250GB, consider Azure SQL Database or SQL Server.</span></span> <span data-ttu-id="15e16-200">Дополнительные сведения см. в разделе [Хранение данных](../../data-guide/relational-data/data-warehousing.md).</span><span class="sxs-lookup"><span data-stu-id="15e16-200">For more information, see [Data warehousing](../../data-guide/relational-data/data-warehousing.md).</span></span>

<span data-ttu-id="15e16-201">Создайте промежуточные таблицы в виде таблиц без кластеризованных индексов, которые не индексируются.</span><span class="sxs-lookup"><span data-stu-id="15e16-201">Create the staging tables as heap tables, which are not indexed.</span></span> <span data-ttu-id="15e16-202">Запросы, которые создают производственные таблицы, приведут к полному сканированию таблицы, поэтому нет причин индексировать промежуточные таблицы.</span><span class="sxs-lookup"><span data-stu-id="15e16-202">The queries that create the production tables will result in a full table scan, so there is no reason to index the staging tables.</span></span>

<span data-ttu-id="15e16-203">PolyBase автоматически использует преимущества параллелизма в хранилище.</span><span class="sxs-lookup"><span data-stu-id="15e16-203">PolyBase automatically takes advantage of parallelism in the warehouse.</span></span> <span data-ttu-id="15e16-204">Производительность нагрузки масштабируется при увеличении DWU.</span><span class="sxs-lookup"><span data-stu-id="15e16-204">The load performance scales as you increase DWUs.</span></span> <span data-ttu-id="15e16-205">Для достижения оптимальной производительности используйте операции одинарной загрузки.</span><span class="sxs-lookup"><span data-stu-id="15e16-205">For best performance, use a single load operation.</span></span> <span data-ttu-id="15e16-206">Разбивка входных данных на фрагменты и выполнение нескольких одновременных нагрузок не повышает производительность.</span><span class="sxs-lookup"><span data-stu-id="15e16-206">There is no performance benefit to breaking the input data into chunks and running multiple concurrent loads.</span></span>

<span data-ttu-id="15e16-207">PolyBase может читать данные, сжатые с помощью GZip.</span><span class="sxs-lookup"><span data-stu-id="15e16-207">PolyBase can read Gzip compressed files.</span></span> <span data-ttu-id="15e16-208">Тем не менее для сжатого файла используется только один модуль чтения, потому что распаковка файла является однопоточной операцией.</span><span class="sxs-lookup"><span data-stu-id="15e16-208">However, only a single reader is used per compressed file, because uncompressing the file is a single-threaded operation.</span></span> <span data-ttu-id="15e16-209">Поэтому следует избегать загрузки одного большого сжатого файла.</span><span class="sxs-lookup"><span data-stu-id="15e16-209">Therefore, avoid loading a single large compressed file.</span></span> <span data-ttu-id="15e16-210">Вместо этого разбейте данные на несколько сжатых файлов, чтобы воспользоваться преимуществами параллелизма.</span><span class="sxs-lookup"><span data-stu-id="15e16-210">Instead, split the data into multiple compressed files, in order to take advantage of parallelism.</span></span>

<span data-ttu-id="15e16-211">Следует учитывать следующие ограничения.</span><span class="sxs-lookup"><span data-stu-id="15e16-211">Be aware of the following limitations:</span></span>

- <span data-ttu-id="15e16-212">PolyBase поддерживает максимальный размер столбца из `varchar(8000)`, `nvarchar(4000)` или `varbinary(8000)`.</span><span class="sxs-lookup"><span data-stu-id="15e16-212">PolyBase supports a maximum column size of `varchar(8000)`, `nvarchar(4000)`, or `varbinary(8000)`.</span></span> <span data-ttu-id="15e16-213">Если имеются данные, превышающие эти лимиты, то при экспорте следует разбить данные на блоки, а затем собрать эти блоки после импорта.</span><span class="sxs-lookup"><span data-stu-id="15e16-213">If you have data that exceeds these limits, one option is to break the data up into chunks when you export it, and then reassemble the chunks after import.</span></span>

- <span data-ttu-id="15e16-214">PolyBase использует фиксированный признак конца строки \n или новой строки.</span><span class="sxs-lookup"><span data-stu-id="15e16-214">PolyBase uses a fixed row terminator of \n or newline.</span></span> <span data-ttu-id="15e16-215">Если в исходных данных появляются символы новой строки, это может вызвать проблемы.</span><span class="sxs-lookup"><span data-stu-id="15e16-215">This can cause problems if newline characters appear in the source data.</span></span>

- <span data-ttu-id="15e16-216">Схема исходных данных может содержать типы данных, которые не поддерживаются в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-216">Your source data schema might contain data types that are not supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="15e16-217">Чтобы обойти эти ограничения, можно создать хранимую процедуру, которая выполнит необходимые преобразования.</span><span class="sxs-lookup"><span data-stu-id="15e16-217">To work around these limitations, you can create a stored procedure that performs the necessary conversions.</span></span> <span data-ttu-id="15e16-218">При запуске bcp найдите по ссылке эту хранимую процедуру.</span><span class="sxs-lookup"><span data-stu-id="15e16-218">Reference this stored procedure when you run bcp.</span></span> <span data-ttu-id="15e16-219">Как альтернатива [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) автоматически преобразует типы данных, которые не поддерживаются в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="15e16-219">Alternatively, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatically converts data types that aren’t supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="15e16-220">Дополнительные сведения см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="15e16-220">For more information, see the following articles:</span></span>

- <span data-ttu-id="15e16-221">[Рекомендации по загрузке данных в хранилище данных SQL Azure](/azure/sql-data-warehouse/guidance-for-loading-data).</span><span class="sxs-lookup"><span data-stu-id="15e16-221">[Best practices for loading data into Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span></span>
- <span data-ttu-id="15e16-222">[Перенос схем в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema).</span><span class="sxs-lookup"><span data-stu-id="15e16-222">[Migrate your schemas to SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema)</span></span>
- <span data-ttu-id="15e16-223">[Руководство по определению типов данных для таблиц в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types).</span><span class="sxs-lookup"><span data-stu-id="15e16-223">[Guidance for defining data types for tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types)</span></span>

### <a name="transform-the-data"></a><span data-ttu-id="15e16-224">Преобразование данных</span><span class="sxs-lookup"><span data-stu-id="15e16-224">Transform the data</span></span>

<span data-ttu-id="15e16-225">Преобразование данных и перемещение их в производственные таблицы.</span><span class="sxs-lookup"><span data-stu-id="15e16-225">Transform the data and move it into production tables.</span></span> <span data-ttu-id="15e16-226">На этом этапе данные преобразуются в схему типа "звезда" с таблицами измерений и таблицами фактов, подходящими для семантического моделирования.</span><span class="sxs-lookup"><span data-stu-id="15e16-226">In this step, the data is transformed into a star schema with dimension tables and fact tables, suitable for semantic modeling.</span></span>

<span data-ttu-id="15e16-227">Создайте рабочие таблицы с кластерными индексами columnstore, которые обеспечивают наилучшую общую производительность запросов.</span><span class="sxs-lookup"><span data-stu-id="15e16-227">Create the production tables with clustered columnstore indexes, which offer the best overall query performance.</span></span> <span data-ttu-id="15e16-228">Индексы columnstore оптимизированы для запросов, которые сканируют большое количество записей.</span><span class="sxs-lookup"><span data-stu-id="15e16-228">Columnstore indexes are optimized for queries that scan many records.</span></span> <span data-ttu-id="15e16-229">Индексы columnstore также не работают для отдельных поисковых запросов (которые просматривают одну строку).</span><span class="sxs-lookup"><span data-stu-id="15e16-229">Columnstore indexes don't perform as well for singleton lookups (that is, looking up a single row).</span></span> <span data-ttu-id="15e16-230">Если необходимо выполнять частые отдельные запросы, можно добавить некластеризованный индекс в таблицу.</span><span class="sxs-lookup"><span data-stu-id="15e16-230">If you need to perform frequent singleton lookups, you can add a non-clustered index to a table.</span></span> <span data-ttu-id="15e16-231">Выполнение отдельных запросов происходит значительно быстрее с помощью некластеризованного индекса.</span><span class="sxs-lookup"><span data-stu-id="15e16-231">Singleton lookups can run significantly faster using a non-clustered index.</span></span> <span data-ttu-id="15e16-232">Однако отдельный поиск обычно менее распространен в сценариях хранилища данных, чем рабочие нагрузки OLTP.</span><span class="sxs-lookup"><span data-stu-id="15e16-232">However, singleton lookups are typically less common in data warehouse scenarios than OLTP workloads.</span></span> <span data-ttu-id="15e16-233">Дополнительные сведения см. в разделе [Индексирование таблиц в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span><span class="sxs-lookup"><span data-stu-id="15e16-233">For more information, see [Indexing tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span></span>

> [!NOTE]
> <span data-ttu-id="15e16-234">Кластерные таблицы columnstore не поддерживают типы данных `varchar(max)`, `nvarchar(max)` или `varbinary(max)`.</span><span class="sxs-lookup"><span data-stu-id="15e16-234">Clustered columnstore tables do not support `varchar(max)`, `nvarchar(max)`, or `varbinary(max)` data types.</span></span> <span data-ttu-id="15e16-235">В этом случае рассмотрим кучу или кластеризованный индекс.</span><span class="sxs-lookup"><span data-stu-id="15e16-235">In that case, consider a heap or clustered index.</span></span> <span data-ttu-id="15e16-236">Эти столбцы можно поместить в отдельную таблицу.</span><span class="sxs-lookup"><span data-stu-id="15e16-236">You might put those columns into a separate table.</span></span>

<span data-ttu-id="15e16-237">Поскольку база данных примеров не очень велика, были созданы реплицированные таблицы без разделов.</span><span class="sxs-lookup"><span data-stu-id="15e16-237">Because the sample database is not very large, we created replicated tables with no partitions.</span></span> <span data-ttu-id="15e16-238">Для производственных нагрузок использование распределенных таблиц, вероятно, улучшит производительность запросов.</span><span class="sxs-lookup"><span data-stu-id="15e16-238">For production workloads, using distributed tables is likely to improve query performance.</span></span> <span data-ttu-id="15e16-239">См. [Руководство по проектированию распределенных таблиц в хранилище данных SQL Azure](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span><span class="sxs-lookup"><span data-stu-id="15e16-239">See [Guidance for designing distributed tables in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span></span> <span data-ttu-id="15e16-240">В примерах скрипты запускают запросы, используя статический [класс ресурсов](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span><span class="sxs-lookup"><span data-stu-id="15e16-240">Our example scripts run the queries using a static [resource class](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span></span>

### <a name="load-the-semantic-model"></a><span data-ttu-id="15e16-241">Загрузка семантической модели</span><span class="sxs-lookup"><span data-stu-id="15e16-241">Load the semantic model</span></span>

<span data-ttu-id="15e16-242">Загрузка данных в табличную модель в Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="15e16-242">Load the data into a tabular model in Azure Analysis Services.</span></span> <span data-ttu-id="15e16-243">На этом этапе создается семантическая модель данных с помощью средства SQL Server Data Tools (SSDT).</span><span class="sxs-lookup"><span data-stu-id="15e16-243">In this step, you create a semantic data model by using SQL Server Data Tools (SSDT).</span></span> <span data-ttu-id="15e16-244">Можно также создать модель путем импорта из файла Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="15e16-244">You can also create a model by importing it from a Power BI Desktop file.</span></span> <span data-ttu-id="15e16-245">Поскольку хранилище данных SQL не поддерживает внешние ключи, необходимо добавить связи для семантической модели, чтобы можно было присоединиться к таблицам.</span><span class="sxs-lookup"><span data-stu-id="15e16-245">Because SQL Data Warehouse does not support foreign keys, you must add the relationships to the semantic model, so that you can join across tables.</span></span>

### <a name="use-power-bi-to-visualize-the-data"></a><span data-ttu-id="15e16-246">Использование Power BI для визуализации данных</span><span class="sxs-lookup"><span data-stu-id="15e16-246">Use Power BI to visualize the data</span></span>

<span data-ttu-id="15e16-247">Существует два варианта подключения Power BI к Azure Analysis Services:</span><span class="sxs-lookup"><span data-stu-id="15e16-247">Power BI supports two options for connecting to Azure Analysis Services:</span></span>

- <span data-ttu-id="15e16-248">Импорт.</span><span class="sxs-lookup"><span data-stu-id="15e16-248">Import.</span></span> <span data-ttu-id="15e16-249">Данные импортируются в модель Power BI.</span><span class="sxs-lookup"><span data-stu-id="15e16-249">The data is imported into the Power BI model.</span></span>
- <span data-ttu-id="15e16-250">Активное подключение.</span><span class="sxs-lookup"><span data-stu-id="15e16-250">Live Connection.</span></span> <span data-ttu-id="15e16-251">Данные извлекаются непосредственно из Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="15e16-251">Data is pulled directly from Analysis Services.</span></span>

<span data-ttu-id="15e16-252">Корпорация Майкрософт рекомендует активное подключение, так как оно не требует копирования данных в модели Power BI.</span><span class="sxs-lookup"><span data-stu-id="15e16-252">We recommend Live Connection because it doesn't require copying data into the Power BI model.</span></span> <span data-ttu-id="15e16-253">Кроме того, использование DirectQuery гарантирует, что результаты всегда соответствуют последним исходным данным.</span><span class="sxs-lookup"><span data-stu-id="15e16-253">Also, using DirectQuery ensures that results are always consistent with the latest source data.</span></span> <span data-ttu-id="15e16-254">Дополнительные сведения см. в разделе [Подключение с помощью Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span><span class="sxs-lookup"><span data-stu-id="15e16-254">For more information, see [Connect with Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span></span>

<span data-ttu-id="15e16-255">**Рекомендации**</span><span class="sxs-lookup"><span data-stu-id="15e16-255">**Recommendations:**</span></span>

<span data-ttu-id="15e16-256">Избегайте запуска запросов панели управления бизнес-аналитики непосредственно к хранилищу данных.</span><span class="sxs-lookup"><span data-stu-id="15e16-256">Avoid running BI dashboard queries directly against the data warehouse.</span></span> <span data-ttu-id="15e16-257">Информационные панели бизнес-аналитики требуют очень малого времени отклика, которого может не хватить на прямые запросы к хранилищу.</span><span class="sxs-lookup"><span data-stu-id="15e16-257">BI dashboards require very low response times, which direct queries against the warehouse may be unable to satisfy.</span></span> <span data-ttu-id="15e16-258">Кроме того, при обновлении информационной панели будет учитываться количество одновременных запросов, что может повлиять на производительность.</span><span class="sxs-lookup"><span data-stu-id="15e16-258">Also, refreshing the dashboard will count against the number of concurrent queries, which could impact performance.</span></span>

<span data-ttu-id="15e16-259">Azure Analysis Services предназначена для обработки требований к запросу информационной панели бизнес-аналитики, поэтому рекомендуемая практика заключается в том, чтобы запрашивать Analysis Services из Power BI.</span><span class="sxs-lookup"><span data-stu-id="15e16-259">Azure Analysis Services is designed to handle the query requirements of a BI dashboard, so the recommended practice is to query Analysis Services from Power BI.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="15e16-260">Вопросы масштабируемости</span><span class="sxs-lookup"><span data-stu-id="15e16-260">Scalability considerations</span></span>

### <a name="sql-data-warehouse"></a><span data-ttu-id="15e16-261">Хранилище данных SQL</span><span class="sxs-lookup"><span data-stu-id="15e16-261">SQL Data Warehouse</span></span>

<span data-ttu-id="15e16-262">С хранилищем данных SQL можно по требованию масштабировать вычислительные ресурсы.</span><span class="sxs-lookup"><span data-stu-id="15e16-262">With SQL Data Warehouse, you can scale out your compute resources on demand.</span></span> <span data-ttu-id="15e16-263">Механизм запросов оптимизирует запросы для параллельной обработки на основе количества вычислительных узлов и перемещает данные между узлами по мере необходимости.</span><span class="sxs-lookup"><span data-stu-id="15e16-263">The query engine optimizes queries for parallel processing based on the number of compute nodes, and moves data between nodes as necessary.</span></span> <span data-ttu-id="15e16-264">Дополнительные сведения см. в разделе [Управление вычислительными ресурсами в хранилище данных SQL Azure](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span><span class="sxs-lookup"><span data-stu-id="15e16-264">For more information, see [Manage compute in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span></span>

### <a name="analysis-services"></a><span data-ttu-id="15e16-265">Analysis Services</span><span class="sxs-lookup"><span data-stu-id="15e16-265">Analysis Services</span></span>

<span data-ttu-id="15e16-266">Для рабочих нагрузок рекомендуется уровень "Стандартный" для служб Azure Analysis Services, так как он поддерживает секционирование и DirectQuery.</span><span class="sxs-lookup"><span data-stu-id="15e16-266">For production workloads, we recommend the Standard Tier for Azure Analysis Services, because it supports partitioning and DirectQuery.</span></span> <span data-ttu-id="15e16-267">В пределах уровня размер экземпляра определяет память и мощность обработки.</span><span class="sxs-lookup"><span data-stu-id="15e16-267">Within a tier, the instance size determines the memory and processing power.</span></span> <span data-ttu-id="15e16-268">Вычислительная мощность измеряется в единицах обработки запроса (QPUs).</span><span class="sxs-lookup"><span data-stu-id="15e16-268">Processing power is measured in Query Processing Units (QPUs).</span></span> <span data-ttu-id="15e16-269">Контролируйте использование QPU, чтобы выбрать необходимый размер.</span><span class="sxs-lookup"><span data-stu-id="15e16-269">Monitor your QPU usage to select the appropriate size.</span></span> <span data-ttu-id="15e16-270">Дополнительные сведения см. в разделе [Мониторинг производительности сервера](/azure/analysis-services/analysis-services-monitor).</span><span class="sxs-lookup"><span data-stu-id="15e16-270">For more information, see [Monitor server metrics](/azure/analysis-services/analysis-services-monitor).</span></span>

<span data-ttu-id="15e16-271">При высокой нагрузке производительность запросов может ухудшиться из-за параллелизма запросов.</span><span class="sxs-lookup"><span data-stu-id="15e16-271">Under high load, query performance can become degraded due to query concurrency.</span></span> <span data-ttu-id="15e16-272">Чтобы одновременно выполнять больше запросов, можно масштабировать службы Analysis Services, создавая пул реплик для обработки запросов.</span><span class="sxs-lookup"><span data-stu-id="15e16-272">You can scale out Analysis Services by creating a pool of replicas to process queries, so that more queries can be performed concurrently.</span></span> <span data-ttu-id="15e16-273">Работа по обработке модели данных всегда происходит на основном сервере.</span><span class="sxs-lookup"><span data-stu-id="15e16-273">The work of processing the data model always happens on the primary server.</span></span> <span data-ttu-id="15e16-274">Основной сервер по умолчанию также обрабатывает запросы.</span><span class="sxs-lookup"><span data-stu-id="15e16-274">By default, the primary server also handles queries.</span></span> <span data-ttu-id="15e16-275">При необходимости можно назначить сервер-источник исключительно для обработки, чтобы пул запросов обрабатывал все запросы.</span><span class="sxs-lookup"><span data-stu-id="15e16-275">Optionally, you can designate the primary server to run processing exclusively, so that the query pool handles all queries.</span></span> <span data-ttu-id="15e16-276">В случае высоких требований к обработке нужно отделить обработку от пула запросов.</span><span class="sxs-lookup"><span data-stu-id="15e16-276">If you have high processing requirements, you should separate the processing from the query pool.</span></span> <span data-ttu-id="15e16-277">В случае высокой нагрузки запросов и относительно несложной обработки можно включить сервер-источник в пул запросов.</span><span class="sxs-lookup"><span data-stu-id="15e16-277">If you have high query loads, and relatively light processing, you can include the primary server in the query pool.</span></span> <span data-ttu-id="15e16-278">Дополнительные сведения см. в разделе [Горизонтальное масштабирование служб Azure Analysis Services](/azure/analysis-services/analysis-services-scale-out).</span><span class="sxs-lookup"><span data-stu-id="15e16-278">For more information, see [Azure Analysis Services scale-out](/azure/analysis-services/analysis-services-scale-out).</span></span>

<span data-ttu-id="15e16-279">Чтобы уменьшить объем ненужной обработки, рассмотрите возможность использования секций для разделения табличной модели на логические части.</span><span class="sxs-lookup"><span data-stu-id="15e16-279">To reduce the amount of unnecessary processing, consider using partitions to divide the tabular model into logical parts.</span></span> <span data-ttu-id="15e16-280">Каждая секция может обрабатываться отдельно.</span><span class="sxs-lookup"><span data-stu-id="15e16-280">Each partition can be processed separately.</span></span> <span data-ttu-id="15e16-281">Дополнительные сведения см. в разделе [Секция](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span><span class="sxs-lookup"><span data-stu-id="15e16-281">For more information, see [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span></span>

## <a name="security-considerations"></a><span data-ttu-id="15e16-282">Вопросы безопасности</span><span class="sxs-lookup"><span data-stu-id="15e16-282">Security considerations</span></span>

### <a name="ip-whitelisting-of-analysis-services-clients"></a><span data-ttu-id="15e16-283">Список разрешенных IP-адресов клиентов службы Analysis Services</span><span class="sxs-lookup"><span data-stu-id="15e16-283">IP whitelisting of Analysis Services clients</span></span>

<span data-ttu-id="15e16-284">Рассмотрите возможность использования функции брандмауэра службы Analysis Services белого списка клиентских IP-адресов.</span><span class="sxs-lookup"><span data-stu-id="15e16-284">Consider using the Analysis Services firewall feature to whitelist client IP addresses.</span></span> <span data-ttu-id="15e16-285">Если параметр включен, брандмауэр блокирует все клиентские соединения, которые отличаются от указанных в правилах брандмауэра.</span><span class="sxs-lookup"><span data-stu-id="15e16-285">If enabled, the firewall blocks all client connections other than those specified in the firewall rules.</span></span> <span data-ttu-id="15e16-286">Стандартные правила присваивают белый список службе Power BI, но при необходимости можно отключить это правило.</span><span class="sxs-lookup"><span data-stu-id="15e16-286">The default rules whitelist the Power BI service, but you can disable this rule if desired.</span></span> <span data-ttu-id="15e16-287">Дополнительные сведения см. в разделе [Усиление защиты Azure Analysis Services благодаря новым возможностям брандмауэра](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span><span class="sxs-lookup"><span data-stu-id="15e16-287">For more information, see [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span></span>

### <a name="authorization"></a><span data-ttu-id="15e16-288">Авторизация</span><span class="sxs-lookup"><span data-stu-id="15e16-288">Authorization</span></span>

<span data-ttu-id="15e16-289">Azure Analysis Services использует Azure Active Directory (Azure AD) для аутентификации пользователей, подключающихся к серверу служб Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="15e16-289">Azure Analysis Services uses Azure Active Directory (Azure AD) to authenticate users who connect to an Analysis Services server.</span></span> <span data-ttu-id="15e16-290">Создавая роли и затем назначая их пользователям или группам Azure AD, можно ограничить данные, которые может просматривать конкретный пользователь.</span><span class="sxs-lookup"><span data-stu-id="15e16-290">You can restrict what data a particular user is able to view, by creating roles and then assigning Azure AD users or groups to those roles.</span></span> <span data-ttu-id="15e16-291">Для каждой роли можно сделать следующее.</span><span class="sxs-lookup"><span data-stu-id="15e16-291">For each role, you can:</span></span>

- <span data-ttu-id="15e16-292">Защитить таблицы или отдельные столбцы.</span><span class="sxs-lookup"><span data-stu-id="15e16-292">Protect tables or individual columns.</span></span>
- <span data-ttu-id="15e16-293">Защитить отдельные строки на основе выражения фильтра.</span><span class="sxs-lookup"><span data-stu-id="15e16-293">Protect individual rows based on filter expressions.</span></span>

<span data-ttu-id="15e16-294">Дополнительные сведения см. в разделе [Управление ролями и пользователями базы данных](/azure/analysis-services/analysis-services-database-users).</span><span class="sxs-lookup"><span data-stu-id="15e16-294">For more information, see [Manage database roles and users](/azure/analysis-services/analysis-services-database-users).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="15e16-295">Развертывание решения</span><span class="sxs-lookup"><span data-stu-id="15e16-295">Deploy the solution</span></span>

<span data-ttu-id="15e16-296">Чтобы выполнить развертывание и запуск эталонной реализации, выполните действия, описанные в [файле сведений на GitHub][github-folder].</span><span class="sxs-lookup"><span data-stu-id="15e16-296">To the deploy and run the reference implementation, follow the steps in the [GitHub readme][github-folder].</span></span> <span data-ttu-id="15e16-297">Он позволяет развернуть следующее:</span><span class="sxs-lookup"><span data-stu-id="15e16-297">It deploys the following:</span></span>

- <span data-ttu-id="15e16-298">Виртуальную машину Windows для имитации локального сервера базы данных.</span><span class="sxs-lookup"><span data-stu-id="15e16-298">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="15e16-299">Она включает SQL Server 2017 и связанные с ним инструменты, а также Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="15e16-299">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
- <span data-ttu-id="15e16-300">Учетная запись хранения Azure, которая обеспечивает хранилище больших двоичных объектов для хранения данных, экспортированных из базы данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="15e16-300">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
- <span data-ttu-id="15e16-301">Экземпляр хранилища данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="15e16-301">An Azure SQL Data Warehouse instance.</span></span>
- <span data-ttu-id="15e16-302">Экземпляр службы Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="15e16-302">An Azure Analysis Services instance.</span></span>

## <a name="next-steps"></a><span data-ttu-id="15e16-303">Дополнительная информация</span><span class="sxs-lookup"><span data-stu-id="15e16-303">Next steps</span></span>

- <span data-ttu-id="15e16-304">Для автоматизации этого конвейера используйте Фабрика данных Azure.</span><span class="sxs-lookup"><span data-stu-id="15e16-304">Use Azure Data Factory to automate the ELT pipeline.</span></span> <span data-ttu-id="15e16-305">См. сведения об [автоматизированной корпоративной бизнес-аналитике с использованием Хранилища данных SQL и Фабрики данных Azure][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="15e16-305">See [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="related-resources"></a><span data-ttu-id="15e16-306">Связанные ресурсы</span><span class="sxs-lookup"><span data-stu-id="15e16-306">Related resources</span></span>

<span data-ttu-id="15e16-307">Вы можете просмотреть следующий [пример сценария Azure](/azure/architecture/example-scenario), в котором описываются конкретные решения, использующие некоторые из этих технологий:</span><span class="sxs-lookup"><span data-stu-id="15e16-307">You may want to review the following [Azure example scenarios](/azure/architecture/example-scenario) that demonstrate specific solutions using some of the same technologies:</span></span>

- [<span data-ttu-id="15e16-308">Решения по хранению и анализу данных для продаж и маркетинга</span><span class="sxs-lookup"><span data-stu-id="15e16-308">Data warehousing and analytics for sales and marketing</span></span>](/azure/architecture/example-scenario/data/data-warehouse)
- [<span data-ttu-id="15e16-309">Гибридное извлечение, преобразование и загрузка данных с помощью существующих локальных служб SSIS и Фабрики данных Azure</span><span class="sxs-lookup"><span data-stu-id="15e16-309">Hybrid ETL with existing on-premises SSIS and Azure Data Factory</span></span>](/azure/architecture/example-scenario/data/hybrid-etl-with-adf)

<!-- links -->

[adf-ra]: ./enterprise-bi-adf.md
[github-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database
