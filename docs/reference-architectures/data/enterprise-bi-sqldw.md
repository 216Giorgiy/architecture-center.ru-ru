---
title: Корпоративная бизнес-аналитика с использованием хранилища данных SQL
description: Используйте Azure для получения информации о бизнесе из реляционных данных, хранящихся локально
author: MikeWasson
ms.date: 11/06/2018
ms.openlocfilehash: 2822cf6d2a75d521f182c267f4bf2bac462d2b7f
ms.sourcegitcommit: 877777094b554559dc9cb1f0d9214d6d38197439
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/11/2018
ms.locfileid: "51527717"
---
# <a name="enterprise-bi-in-azure-with-sql-data-warehouse"></a><span data-ttu-id="cc29b-103">Корпоративная бизнес-аналитика в Azure с использованием Хранилища данных SQL</span><span class="sxs-lookup"><span data-stu-id="cc29b-103">Enterprise BI in Azure with SQL Data Warehouse</span></span>

<span data-ttu-id="cc29b-104">Эта эталонная архитектура реализует конвейер [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (извлечение-загрузка-преобразование), который перемещает данные из локальной базы данных SQL Server в хранилище данных SQL и преобразует данные для анализа.</span><span class="sxs-lookup"><span data-stu-id="cc29b-104">This reference architecture implements an [ELT](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) (extract-load-transform) pipeline that moves data from an on-premises SQL Server database into SQL Data Warehouse and transforms the data for analysis.</span></span> 

<span data-ttu-id="cc29b-105">Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github-folder].</span><span class="sxs-lookup"><span data-stu-id="cc29b-105">A reference implementation for this architecture is available on [GitHub][github-folder]</span></span>

![](./images/enterprise-bi-sqldw.png)

<span data-ttu-id="cc29b-106">**Сценарий**. Организация имеет большой набор данных OLTP, хранящийся локально в базе данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="cc29b-106">**Scenario**: An organization has a large OLTP data set stored in a SQL Server database on premises.</span></span> <span data-ttu-id="cc29b-107">Организация хочет использовать хранилище данных SQL для проведения анализа с использованием Power BI.</span><span class="sxs-lookup"><span data-stu-id="cc29b-107">The organization wants to use SQL Data Warehouse to perform analysis using Power BI.</span></span> 

<span data-ttu-id="cc29b-108">Эта эталонная архитектура предназначена для однократных заданий или заданий по требованию.</span><span class="sxs-lookup"><span data-stu-id="cc29b-108">This reference architecture is designed for one-time or on-demand jobs.</span></span> <span data-ttu-id="cc29b-109">Если необходимо регулярно перемещать данные (ежечасно или ежедневно), рекомендуется использовать фабрику данных Azure для автоматизации рабочего процесса.</span><span class="sxs-lookup"><span data-stu-id="cc29b-109">If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow.</span></span> <span data-ttu-id="cc29b-110">Описание эталонной архитектуры, в которой используется Фабрика данных, см. в статье [Автоматизированная корпоративная бизнес-аналитика с использованием Хранилища данных SQL и Фабрики данных Azure][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="cc29b-110">For a reference architecture that uses Data Factory, see [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

## <a name="architecture"></a><span data-ttu-id="cc29b-111">Архитектура</span><span class="sxs-lookup"><span data-stu-id="cc29b-111">Architecture</span></span>

<span data-ttu-id="cc29b-112">Архитектура состоит из следующих компонентов:</span><span class="sxs-lookup"><span data-stu-id="cc29b-112">The architecture consists of the following components.</span></span>

### <a name="data-source"></a><span data-ttu-id="cc29b-113">Источник данных</span><span class="sxs-lookup"><span data-stu-id="cc29b-113">Data source</span></span>

<span data-ttu-id="cc29b-114">**SQL Server.**</span><span class="sxs-lookup"><span data-stu-id="cc29b-114">**SQL Server**.</span></span> <span data-ttu-id="cc29b-115">Исходные данные размещаются локально в базе данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="cc29b-115">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="cc29b-116">Чтобы имитировать локальную среду, скрипты развертывания для этой архитектуры предоставляют виртуальную машину в Azure с установленной платформой SQL Server.</span><span class="sxs-lookup"><span data-stu-id="cc29b-116">To simulate the on-premises environment, the deployment scripts for this architecture provision a VM in Azure with SQL Server installed.</span></span> <span data-ttu-id="cc29b-117">В качестве исходных данных используется [пример базы данных OLTP Wide World Importers][wwi].</span><span class="sxs-lookup"><span data-stu-id="cc29b-117">The [Wide World Importers OLTP sample database][wwi] is used as the source data.</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="cc29b-118">Прием и хранение данных</span><span class="sxs-lookup"><span data-stu-id="cc29b-118">Ingestion and data storage</span></span>

<span data-ttu-id="cc29b-119">**Хранилище больших двоичных объектов**.</span><span class="sxs-lookup"><span data-stu-id="cc29b-119">**Blob Storage**.</span></span> <span data-ttu-id="cc29b-120">Хранилище больших двоичных объектов используется в качестве промежуточной области для копирования данных перед загрузкой в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-120">Blob storage is used as a staging area to copy the data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="cc29b-121">**Хранилище данных Azure SQL.**</span><span class="sxs-lookup"><span data-stu-id="cc29b-121">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="cc29b-122">[Хранилище данных SQL](/azure/sql-data-warehouse/) — распределенная система, предназначенная для анализа больших объемов данных.</span><span class="sxs-lookup"><span data-stu-id="cc29b-122">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="cc29b-123">Она поддерживает массовую параллельную обработку (MPP), что делает ее пригодной для запуска высокопроизводительной аналитики.</span><span class="sxs-lookup"><span data-stu-id="cc29b-123">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span> 

### <a name="analysis-and-reporting"></a><span data-ttu-id="cc29b-124">Анализ и создание отчетов</span><span class="sxs-lookup"><span data-stu-id="cc29b-124">Analysis and reporting</span></span>

<span data-ttu-id="cc29b-125">**Службы Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="cc29b-125">**Azure Analysis Services**.</span></span> <span data-ttu-id="cc29b-126">[Analysis Services](/azure/analysis-services/) — полностью управляемая служба, которая предоставляет возможности моделирования данных.</span><span class="sxs-lookup"><span data-stu-id="cc29b-126">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="cc29b-127">Используйте службу Analysis Services для создания семантической модели, которую могут запрашивать пользователи.</span><span class="sxs-lookup"><span data-stu-id="cc29b-127">Use Analysis Services to create a semantic model that users can query.</span></span> <span data-ttu-id="cc29b-128">Служба Analysis Services особенно полезна в сценарии информационной панели бизнес-аналитики.</span><span class="sxs-lookup"><span data-stu-id="cc29b-128">Analysis Services is especially useful in a BI dashboard scenario.</span></span> <span data-ttu-id="cc29b-129">В этой архитектуре служба Analysis Services считывает данные из хранилища данных для обработки семантической модели и эффективно обслуживает запросы информационной панели.</span><span class="sxs-lookup"><span data-stu-id="cc29b-129">In this architecture, Analysis Services reads data from the data warehouse to process the semantic model, and efficiently serves dashboard queries.</span></span> <span data-ttu-id="cc29b-130">Она также поддерживает гибкий параллелизм путем масштабирования реплик, чтобы быстрее обрабатывать запросы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-130">It also supports elastic concurrency, by scaling out replicas for faster query processing.</span></span>

<span data-ttu-id="cc29b-131">В настоящее время Azure Analysis Services поддерживает табличные модели, но не поддерживает многомерные.</span><span class="sxs-lookup"><span data-stu-id="cc29b-131">Currently, Azure Analysis Services supports tabular models but not multidimensional models.</span></span> <span data-ttu-id="cc29b-132">В табличных моделях используются конструкции реляционного моделирования (таблицы и столбцы), тогда как в многомерных моделях используются моделирующие конструкции OLAP (кубы, размеры и меры).</span><span class="sxs-lookup"><span data-stu-id="cc29b-132">Tabular models use relational modeling constructs (tables and columns), whereas multidimensional models use OLAP modeling constructs (cubes, dimensions, and measures).</span></span> <span data-ttu-id="cc29b-133">Если требуются многомерные модели, используйте SQL Server Analysis Services (SSAS).</span><span class="sxs-lookup"><span data-stu-id="cc29b-133">If you require multidimensional models, use SQL Server Analysis Services (SSAS).</span></span> <span data-ttu-id="cc29b-134">Дополнительные сведения см. в разделе [Сравнение табличных и многомерных решений](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span><span class="sxs-lookup"><span data-stu-id="cc29b-134">For more information, see [Comparing tabular and multidimensional solutions](/sql/analysis-services/comparing-tabular-and-multidimensional-solutions-ssas).</span></span>

<span data-ttu-id="cc29b-135">**Power BI**.</span><span class="sxs-lookup"><span data-stu-id="cc29b-135">**Power BI**.</span></span> <span data-ttu-id="cc29b-136">Power BI — набор средств бизнес-аналитики для анализа информации о бизнесе.</span><span class="sxs-lookup"><span data-stu-id="cc29b-136">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="cc29b-137">В этой архитектуре он запрашивает семантическую модель, хранящуюся в службе Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="cc29b-137">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="cc29b-138">Authentication</span><span class="sxs-lookup"><span data-stu-id="cc29b-138">Authentication</span></span>

<span data-ttu-id="cc29b-139">**Azure Active Directory** (Azure AD) аутентифицирует пользователей, которые подключаются к серверу Analysis Services через Power BI.</span><span class="sxs-lookup"><span data-stu-id="cc29b-139">**Azure Active Directory** (Azure AD) authenticates users who connect to the Analysis Services server through Power BI.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="cc29b-140">Конвейер данных</span><span class="sxs-lookup"><span data-stu-id="cc29b-140">Data pipeline</span></span>
 
<span data-ttu-id="cc29b-141">В этой эталонной архитектуре в качестве источника данных используется база данных [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database).</span><span class="sxs-lookup"><span data-stu-id="cc29b-141">This reference architecture uses the [WorldWideImporters](/sql/sample/world-wide-importers/wide-world-importers-oltp-database) sample database as a data source.</span></span> <span data-ttu-id="cc29b-142">Конвейер данных состоит из перечисленных ниже этапов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-142">The data pipeline has the following stages:</span></span>

1. <span data-ttu-id="cc29b-143">Экспортирование данных из SQL Server в неструктурированные файлы (утилита bcp).</span><span class="sxs-lookup"><span data-stu-id="cc29b-143">Export the data from SQL Server to flat files (bcp utility).</span></span>
2. <span data-ttu-id="cc29b-144">Копирование неструктурированных файлов в хранилище больших двоичных объектов Azure (AzCopy)</span><span class="sxs-lookup"><span data-stu-id="cc29b-144">Copy the flat files to Azure Blob Storage (AzCopy).</span></span>
3. <span data-ttu-id="cc29b-145">Загрузка данных в хранилище данных SQL (PolyBase).</span><span class="sxs-lookup"><span data-stu-id="cc29b-145">Load the data into SQL Data Warehouse (PolyBase).</span></span>
4. <span data-ttu-id="cc29b-146">Преобразование данных в схему типа "звезда" (T-SQL).</span><span class="sxs-lookup"><span data-stu-id="cc29b-146">Transform the data into a star schema (T-SQL).</span></span>
5. <span data-ttu-id="cc29b-147">Загрузка семантической модели в службу Analysis Services (средства SQL Server Data Tools).</span><span class="sxs-lookup"><span data-stu-id="cc29b-147">Load a semantic model into Analysis Services (SQL Server Data Tools).</span></span>

![](./images/enterprise-bi-sqldw-pipeline.png)
 
> [!NOTE]
> <span data-ttu-id="cc29b-148">Для шагов 1 &ndash; 3 рассмотрите использование Redgate Data Platform Studio.</span><span class="sxs-lookup"><span data-stu-id="cc29b-148">For steps 1 &ndash; 3, consider using Redgate Data Platform Studio.</span></span> <span data-ttu-id="cc29b-149">Так как к Data Platform Studio применены наиболее подходящие оптимизации и исправления совместимости, это самый быстрый способ начать работу с хранилищем данных SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-149">Data Platform Studio applies the most appropriate compatibility fixes and optimizations, so it's the quickest way to get started with SQL Data Warehouse.</span></span> <span data-ttu-id="cc29b-150">Дополнительную информацию см. в разделе [Загрузка данных с помощью Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span><span class="sxs-lookup"><span data-stu-id="cc29b-150">For more information, see [Load data with Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate).</span></span> 

<span data-ttu-id="cc29b-151">Следующие разделы описывают эти этапы более подробно.</span><span class="sxs-lookup"><span data-stu-id="cc29b-151">The next sections describe these stages in more detail.</span></span>

### <a name="export-data-from-sql-server"></a><span data-ttu-id="cc29b-152">Экспорт данных из SQL Server</span><span class="sxs-lookup"><span data-stu-id="cc29b-152">Export data from SQL Server</span></span>

<span data-ttu-id="cc29b-153">Программа массового копирования [bcp](/sql/tools/bcp-utility) — это быстрый способ создания неструктурированных текстовых файлов из таблиц SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-153">The [bcp](/sql/tools/bcp-utility) (bulk copy program) utility is a fast way to create flat text files from SQL tables.</span></span> <span data-ttu-id="cc29b-154">На этом шаге выбираются столбцы, которые нужно экспортировать, но данные не надо преобразовывать.</span><span class="sxs-lookup"><span data-stu-id="cc29b-154">In this step, you select the columns that you want to export, but don't transform the data.</span></span> <span data-ttu-id="cc29b-155">Любые преобразования данных должны происходить в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-155">Any data transformations should happen in SQL Data Warehouse.</span></span>

<span data-ttu-id="cc29b-156">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="cc29b-156">**Recommendations**</span></span>

<span data-ttu-id="cc29b-157">Если возможно, планируйте извлечение данных в часы с наименьшей загрузкой, чтобы свести к минимуму конфликт ресурсов в рабочей среде.</span><span class="sxs-lookup"><span data-stu-id="cc29b-157">If possible, schedule data extraction during off-peak hours, to minimize resource contention in the production environment.</span></span> 

<span data-ttu-id="cc29b-158">Избегайте запуска bcp на сервере базы данных.</span><span class="sxs-lookup"><span data-stu-id="cc29b-158">Avoid running bcp on the database server.</span></span> <span data-ttu-id="cc29b-159">Вместо этого запустите его с другого компьютера.</span><span class="sxs-lookup"><span data-stu-id="cc29b-159">Instead, run it from another machine.</span></span> <span data-ttu-id="cc29b-160">Записывайте файлы на локальный диск.</span><span class="sxs-lookup"><span data-stu-id="cc29b-160">Write the files to a local drive.</span></span> <span data-ttu-id="cc29b-161">Убедитесь, что имеется достаточно ресурсов ввода-вывода для обработки параллельных операций записи.</span><span class="sxs-lookup"><span data-stu-id="cc29b-161">Ensure that you have sufficient I/O resources to handle the concurrent writes.</span></span> <span data-ttu-id="cc29b-162">Для обеспечения максимальной производительности экспортируйте файлы в специализированные высокоскоростные хранилища.</span><span class="sxs-lookup"><span data-stu-id="cc29b-162">For best performance, export the files to dedicated fast storage drives.</span></span>

<span data-ttu-id="cc29b-163">Вы можете ускорить сетевой перенос, сохранив экспортированные данные в сжатом формате Gzip.</span><span class="sxs-lookup"><span data-stu-id="cc29b-163">You can speed up the network transfer by saving the exported data in Gzip compressed format.</span></span> <span data-ttu-id="cc29b-164">Однако загрузка сжатых файлов в хранилище происходит медленнее, чем загрузка несжатых файлов, поэтому существует компромисс между более быстрой передачей сети и более быстрой загрузкой.</span><span class="sxs-lookup"><span data-stu-id="cc29b-164">However, loading compressed files into the warehouse is slower than loading uncompressed files, so there is a tradeoff between faster network transfer versus faster loading.</span></span> <span data-ttu-id="cc29b-165">Если решено использовать сжатие Gzip, не создавайте отдельные файлы Gzip.</span><span class="sxs-lookup"><span data-stu-id="cc29b-165">If you decide to use Gzip compression, don't create a single Gzip file.</span></span> <span data-ttu-id="cc29b-166">Вместо этого разделите данные на несколько сжатых файлов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-166">Instead, split the data into multiple compressed files.</span></span>

### <a name="copy-flat-files-into-blob-storage"></a><span data-ttu-id="cc29b-167">Копирование неструктурированных файлов в хранилище больших двоичных объектов</span><span class="sxs-lookup"><span data-stu-id="cc29b-167">Copy flat files into blob storage</span></span>

<span data-ttu-id="cc29b-168">Утилита [AzCopy](/azure/storage/common/storage-use-azcopy) предназначена для высокопроизводительного копирования данных в хранилище больших двоичных объектов Azure.</span><span class="sxs-lookup"><span data-stu-id="cc29b-168">The [AzCopy](/azure/storage/common/storage-use-azcopy) utility is designed for high-performance copying of data into Azure blob storage.</span></span>

<span data-ttu-id="cc29b-169">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="cc29b-169">**Recommendations**</span></span>

<span data-ttu-id="cc29b-170">Создайте учетную запись хранения в регионе, расположенном рядом с исходными данными.</span><span class="sxs-lookup"><span data-stu-id="cc29b-170">Create the storage account in a region near the location of the source data.</span></span> <span data-ttu-id="cc29b-171">Разверните учетную запись хранения и экземпляр хранилища данных SQL в том же регионе.</span><span class="sxs-lookup"><span data-stu-id="cc29b-171">Deploy the storage account and the SQL Data Warehouse instance in the same region.</span></span> 

<span data-ttu-id="cc29b-172">Не запускайте AzCopy на том же компьютере, на котором выполняются производственные рабочие нагрузки, поскольку потребление процессора и ввода-вывода может влиять на рабочую нагрузку.</span><span class="sxs-lookup"><span data-stu-id="cc29b-172">Don't run AzCopy on the same machine that runs your production workloads, because the CPU and I/O consumption can interfere with the production workload.</span></span> 

<span data-ttu-id="cc29b-173">Сначала проверьте загрузку, чтобы изучить скорость загрузки.</span><span class="sxs-lookup"><span data-stu-id="cc29b-173">Test the upload first to see what the upload speed is like.</span></span> <span data-ttu-id="cc29b-174">Чтобы указать количество параллельных операций копирования, в AzCopy можно использовать параметр /NC.</span><span class="sxs-lookup"><span data-stu-id="cc29b-174">You can use the /NC option in AzCopy to specify the number of concurrent copy operations.</span></span> <span data-ttu-id="cc29b-175">Чтобы настроить производительность, начните со значения по умолчанию и затем поэкспериментируйте с этим параметром.</span><span class="sxs-lookup"><span data-stu-id="cc29b-175">Start with the default value, then experiment with this setting to tune the performance.</span></span> <span data-ttu-id="cc29b-176">В среде с низкой пропускной способностью слишком много параллельных операций могут привести к сбою сетевого соединения и не допустить успешного завершения операций.</span><span class="sxs-lookup"><span data-stu-id="cc29b-176">In a low-bandwidth environment, too many concurrent operations can overwhelm the network connection and prevent the operations from completing successfully.</span></span>  

<span data-ttu-id="cc29b-177">AzCopy перемещает данные в хранилище через общий доступ в Интернет.</span><span class="sxs-lookup"><span data-stu-id="cc29b-177">AzCopy moves data to storage over the public internet.</span></span> <span data-ttu-id="cc29b-178">Если это недостаточно быстро, рассмотрите создание схемы [ExpressRoute](/azure/expressroute/).</span><span class="sxs-lookup"><span data-stu-id="cc29b-178">If this isn't fast enough, consider setting up an [ExpressRoute](/azure/expressroute/) circuit.</span></span> <span data-ttu-id="cc29b-179">ExpressRoute — это служба, которая направляет данные с помощью выделенного частного подключения в Azure.</span><span class="sxs-lookup"><span data-stu-id="cc29b-179">ExpressRoute is a service that routes your data through a dedicated private connection to Azure.</span></span> <span data-ttu-id="cc29b-180">Если ваше сетевое соединение слишком медленное, то другой вариант заключается в физической отправке данных на диск в центр данных Azure.</span><span class="sxs-lookup"><span data-stu-id="cc29b-180">Another option, if your network connection is too slow, is to physically ship the data on disk to an Azure datacenter.</span></span> <span data-ttu-id="cc29b-181">Дополнительные сведения см. в разделе [Передача данных в Azure и обратно](/azure/architecture/data-guide/scenarios/data-transfer).</span><span class="sxs-lookup"><span data-stu-id="cc29b-181">For more information, see [Transferring data to and from Azure](/azure/architecture/data-guide/scenarios/data-transfer).</span></span>

<span data-ttu-id="cc29b-182">Во время операции копирования AzCopy создает временный файл журнала, который позволяет AzCopy перезапустить операцию, если она прервется (например, из-за сетевой ошибки).</span><span class="sxs-lookup"><span data-stu-id="cc29b-182">During a copy operation, AzCopy creates a temporary journal file, which enables AzCopy to restart the operation if it gets interrupted (for example, due to a network error).</span></span> <span data-ttu-id="cc29b-183">Убедитесь, что для хранения файлов журнала на диске достаточно свободного места.</span><span class="sxs-lookup"><span data-stu-id="cc29b-183">Make sure there is enough disk space to store the journal files.</span></span> <span data-ttu-id="cc29b-184">Чтобы указать, где записываются файлы журнала, можно использовать параметр /Z.</span><span class="sxs-lookup"><span data-stu-id="cc29b-184">You can use the /Z option to specify where the journal files are written.</span></span>

### <a name="load-data-into-sql-data-warehouse"></a><span data-ttu-id="cc29b-185">Загрузка данных в хранилище данных SQL</span><span class="sxs-lookup"><span data-stu-id="cc29b-185">Load data into SQL Data Warehouse</span></span>

<span data-ttu-id="cc29b-186">Используйте [PolyBase](/sql/relational-databases/polybase/polybase-guide), чтобы загрузить файлы из хранилища больших двоичных объектов в хранилище данных.</span><span class="sxs-lookup"><span data-stu-id="cc29b-186">Use [PolyBase](/sql/relational-databases/polybase/polybase-guide) to load the files from blob storage into the data warehouse.</span></span> <span data-ttu-id="cc29b-187">PolyBase предназначен для использования архитектуры MPP (массовой параллельной обработки) хранилища данных SQL, которая делает ее самым быстрым способом загрузки данных в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-187">PolyBase is designed to leverage the MPP (Massively Parallel Processing) architecture of SQL Data Warehouse, which makes it the fastest way to load data into SQL Data Warehouse.</span></span> 

<span data-ttu-id="cc29b-188">Загрузка данных — это двухэтапный процесс:</span><span class="sxs-lookup"><span data-stu-id="cc29b-188">Loading the data is a two-step process:</span></span>

1. <span data-ttu-id="cc29b-189">Создание набора внешних таблиц для данных.</span><span class="sxs-lookup"><span data-stu-id="cc29b-189">Create a set of external tables for the data.</span></span> <span data-ttu-id="cc29b-190">Внешняя таблица — это определение таблицы, которое указывает на данные, хранящиеся вне хранилища &mdash; в этом случае, неструктурированные файлы в хранилище памяти.</span><span class="sxs-lookup"><span data-stu-id="cc29b-190">An external table is a table definition that points to data stored outside of the warehouse &mdash; in this case, the flat files in blob storage.</span></span> <span data-ttu-id="cc29b-191">Этот этап не перемещает никаких данных в хранилище.</span><span class="sxs-lookup"><span data-stu-id="cc29b-191">This step does not move any data into the warehouse.</span></span>
2. <span data-ttu-id="cc29b-192">Создание промежуточных таблиц и загрузка данных в промежуточные таблицы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-192">Create staging tables, and load the data into the staging tables.</span></span> <span data-ttu-id="cc29b-193">Этот этап копирует данные в хранилище.</span><span class="sxs-lookup"><span data-stu-id="cc29b-193">This step copies the data into the warehouse.</span></span>

<span data-ttu-id="cc29b-194">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="cc29b-194">**Recommendations**</span></span>

<span data-ttu-id="cc29b-195">Если имеется большой объем данных (более 1 ТБ) и используется рабочая нагрузка аналитики, которая выиграет от параллелизма, то рассмотрите возможности хранилища данных SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-195">Consider SQL Data Warehouse when you have large amounts of data (more than 1 TB) and are running an analytics workload that will benefit from parallelism.</span></span> <span data-ttu-id="cc29b-196">Хранилище данных SQL не подходит для рабочих нагрузок OLTP или малых наборов данных (<250 ГБ).</span><span class="sxs-lookup"><span data-stu-id="cc29b-196">SQL Data Warehouse is not a good fit for OLTP workloads or smaller data sets (< 250GB).</span></span> <span data-ttu-id="cc29b-197">Для наборов данных менее 250 ГБ рассмотрите базу данных Azure SQL или SQL Server.</span><span class="sxs-lookup"><span data-stu-id="cc29b-197">For data sets less than 250GB, consider Azure SQL Database or SQL Server.</span></span> <span data-ttu-id="cc29b-198">Дополнительные сведения см. в разделе [Хранение данных](../../data-guide/relational-data/data-warehousing.md).</span><span class="sxs-lookup"><span data-stu-id="cc29b-198">For more information, see [Data warehousing](../../data-guide/relational-data/data-warehousing.md).</span></span>

<span data-ttu-id="cc29b-199">Создайте промежуточные таблицы в виде таблиц без кластеризованных индексов, которые не индексируются.</span><span class="sxs-lookup"><span data-stu-id="cc29b-199">Create the staging tables as heap tables, which are not indexed.</span></span> <span data-ttu-id="cc29b-200">Запросы, которые создают производственные таблицы, приведут к полному сканированию таблицы, поэтому нет причин индексировать промежуточные таблицы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-200">The queries that create the production tables will result in a full table scan, so there is no reason to index the staging tables.</span></span>

<span data-ttu-id="cc29b-201">PolyBase автоматически использует преимущества параллелизма в хранилище.</span><span class="sxs-lookup"><span data-stu-id="cc29b-201">PolyBase automatically takes advantage of parallelism in the warehouse.</span></span> <span data-ttu-id="cc29b-202">Производительность нагрузки масштабируется при увеличении DWU.</span><span class="sxs-lookup"><span data-stu-id="cc29b-202">The load performance scales as you increase DWUs.</span></span> <span data-ttu-id="cc29b-203">Для достижения оптимальной производительности используйте операции одинарной загрузки.</span><span class="sxs-lookup"><span data-stu-id="cc29b-203">For best performance, use a single load operation.</span></span> <span data-ttu-id="cc29b-204">Разбивка входных данных на фрагменты и выполнение нескольких одновременных нагрузок не повышает производительность.</span><span class="sxs-lookup"><span data-stu-id="cc29b-204">There is no performance benefit to breaking the input data into chunks and running multiple concurrent loads.</span></span>

<span data-ttu-id="cc29b-205">PolyBase может читать данные, сжатые с помощью GZip.</span><span class="sxs-lookup"><span data-stu-id="cc29b-205">PolyBase can read Gzip compressed files.</span></span> <span data-ttu-id="cc29b-206">Тем не менее для сжатого файла используется только один модуль чтения, потому что распаковка файла является однопоточной операцией.</span><span class="sxs-lookup"><span data-stu-id="cc29b-206">However, only a single reader is used per compressed file, because uncompressing the file is a single-threaded operation.</span></span> <span data-ttu-id="cc29b-207">Поэтому следует избегать загрузки одного большого сжатого файла.</span><span class="sxs-lookup"><span data-stu-id="cc29b-207">Therefore, avoid loading a single large compressed file.</span></span> <span data-ttu-id="cc29b-208">Вместо этого разбейте данные на несколько сжатых файлов, чтобы воспользоваться преимуществами параллелизма.</span><span class="sxs-lookup"><span data-stu-id="cc29b-208">Instead, split the data into multiple compressed files, in order to take advantage of parallelism.</span></span> 

<span data-ttu-id="cc29b-209">Следует учитывать следующие ограничения.</span><span class="sxs-lookup"><span data-stu-id="cc29b-209">Be aware of the following limitations:</span></span>

- <span data-ttu-id="cc29b-210">PolyBase поддерживает максимальный размер столбца из `varchar(8000)`, `nvarchar(4000)` или `varbinary(8000)`.</span><span class="sxs-lookup"><span data-stu-id="cc29b-210">PolyBase supports a maximum column size of `varchar(8000)`, `nvarchar(4000)`, or `varbinary(8000)`.</span></span> <span data-ttu-id="cc29b-211">Если имеются данные, превышающие эти лимиты, то при экспорте следует разбить данные на блоки, а затем собрать эти блоки после импорта.</span><span class="sxs-lookup"><span data-stu-id="cc29b-211">If you have data that exceeds these limits, one option is to break the data up into chunks when you export it, and then reassemble the chunks after import.</span></span> 

- <span data-ttu-id="cc29b-212">PolyBase использует фиксированный признак конца строки \n или новой строки.</span><span class="sxs-lookup"><span data-stu-id="cc29b-212">PolyBase uses a fixed row terminator of \n or newline.</span></span> <span data-ttu-id="cc29b-213">Если в исходных данных появляются символы новой строки, это может вызвать проблемы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-213">This can cause problems if newline characters appear in the source data.</span></span>

- <span data-ttu-id="cc29b-214">Схема исходных данных может содержать типы данных, которые не поддерживаются в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-214">Your source data schema might contain data types that are not supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="cc29b-215">Чтобы обойти эти ограничения, можно создать хранимую процедуру, которая выполнит необходимые преобразования.</span><span class="sxs-lookup"><span data-stu-id="cc29b-215">To work around these limitations, you can create a stored procedure that performs the necessary conversions.</span></span> <span data-ttu-id="cc29b-216">При запуске bcp найдите по ссылке эту хранимую процедуру.</span><span class="sxs-lookup"><span data-stu-id="cc29b-216">Reference this stored procedure when you run bcp.</span></span> <span data-ttu-id="cc29b-217">Как альтернатива [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) автоматически преобразует типы данных, которые не поддерживаются в хранилище данных SQL.</span><span class="sxs-lookup"><span data-stu-id="cc29b-217">Alternatively, [Redgate Data Platform Studio](/azure/sql-data-warehouse/sql-data-warehouse-load-with-redgate) automatically converts data types that aren’t supported in SQL Data Warehouse.</span></span>

<span data-ttu-id="cc29b-218">Дополнительные сведения см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="cc29b-218">For more information, see the following articles:</span></span>

- <span data-ttu-id="cc29b-219">[Рекомендации по загрузке данных в хранилище данных SQL Azure](/azure/sql-data-warehouse/guidance-for-loading-data).</span><span class="sxs-lookup"><span data-stu-id="cc29b-219">[Best practices for loading data into Azure SQL Data Warehouse](/azure/sql-data-warehouse/guidance-for-loading-data).</span></span>
- <span data-ttu-id="cc29b-220">[Перенос схем в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema).</span><span class="sxs-lookup"><span data-stu-id="cc29b-220">[Migrate your schemas to SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema)</span></span>
- <span data-ttu-id="cc29b-221">[Руководство по определению типов данных для таблиц в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types).</span><span class="sxs-lookup"><span data-stu-id="cc29b-221">[Guidance for defining data types for tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types)</span></span>

### <a name="transform-the-data"></a><span data-ttu-id="cc29b-222">Преобразование данных</span><span class="sxs-lookup"><span data-stu-id="cc29b-222">Transform the data</span></span>

<span data-ttu-id="cc29b-223">Преобразование данных и перемещение их в производственные таблицы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-223">Transform the data and move it into production tables.</span></span> <span data-ttu-id="cc29b-224">На этом этапе данные преобразуются в схему типа "звезда" с таблицами измерений и таблицами фактов, подходящими для семантического моделирования.</span><span class="sxs-lookup"><span data-stu-id="cc29b-224">In this step, the data is transformed into a star schema with dimension tables and fact tables, suitable for semantic modeling.</span></span>

<span data-ttu-id="cc29b-225">Создайте рабочие таблицы с кластерными индексами columnstore, которые обеспечивают наилучшую общую производительность запросов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-225">Create the production tables with clustered columnstore indexes, which offer the best overall query performance.</span></span> <span data-ttu-id="cc29b-226">Индексы columnstore оптимизированы для запросов, которые сканируют большое количество записей.</span><span class="sxs-lookup"><span data-stu-id="cc29b-226">Columnstore indexes are optimized for queries that scan many records.</span></span> <span data-ttu-id="cc29b-227">Индексы columnstore также не работают для отдельных поисковых запросов (которые просматривают одну строку).</span><span class="sxs-lookup"><span data-stu-id="cc29b-227">Columnstore indexes don't perform as well for singleton lookups (that is, looking up a single row).</span></span> <span data-ttu-id="cc29b-228">Если необходимо выполнять частые отдельные запросы, можно добавить некластеризованный индекс в таблицу.</span><span class="sxs-lookup"><span data-stu-id="cc29b-228">If you need to perform frequent singleton lookups, you can add a non-clustered index to a table.</span></span> <span data-ttu-id="cc29b-229">Выполнение отдельных запросов происходит значительно быстрее с помощью некластеризованного индекса.</span><span class="sxs-lookup"><span data-stu-id="cc29b-229">Singleton lookups can run significantly faster using a non-clustered index.</span></span> <span data-ttu-id="cc29b-230">Однако отдельный поиск обычно менее распространен в сценариях хранилища данных, чем рабочие нагрузки OLTP.</span><span class="sxs-lookup"><span data-stu-id="cc29b-230">However, singleton lookups are typically less common in data warehouse scenarios than OLTP workloads.</span></span> <span data-ttu-id="cc29b-231">Дополнительные сведения см. в разделе [Индексирование таблиц в хранилище данных SQL](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span><span class="sxs-lookup"><span data-stu-id="cc29b-231">For more information, see [Indexing tables in SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-index).</span></span>

> [!NOTE]
> <span data-ttu-id="cc29b-232">Кластерные таблицы columnstore не поддерживают типы данных `varchar(max)`, `nvarchar(max)` или `varbinary(max)`.</span><span class="sxs-lookup"><span data-stu-id="cc29b-232">Clustered columnstore tables do not support `varchar(max)`, `nvarchar(max)`, or `varbinary(max)` data types.</span></span> <span data-ttu-id="cc29b-233">В этом случае рассмотрим кучу или кластеризованный индекс.</span><span class="sxs-lookup"><span data-stu-id="cc29b-233">In that case, consider a heap or clustered index.</span></span> <span data-ttu-id="cc29b-234">Эти столбцы можно поместить в отдельную таблицу.</span><span class="sxs-lookup"><span data-stu-id="cc29b-234">You might put those columns into a separate table.</span></span>

<span data-ttu-id="cc29b-235">Поскольку база данных примеров не очень велика, были созданы реплицированные таблицы без разделов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-235">Because the sample database is not very large, we created replicated tables with no partitions.</span></span> <span data-ttu-id="cc29b-236">Для производственных нагрузок использование распределенных таблиц, вероятно, улучшит производительность запросов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-236">For production workloads, using distributed tables is likely to improve query performance.</span></span> <span data-ttu-id="cc29b-237">См. [Руководство по проектированию распределенных таблиц в хранилище данных SQL Azure](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span><span class="sxs-lookup"><span data-stu-id="cc29b-237">See [Guidance for designing distributed tables in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-tables-distribute).</span></span> <span data-ttu-id="cc29b-238">В примерах скрипты запускают запросы, используя статический [класс ресурсов](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span><span class="sxs-lookup"><span data-stu-id="cc29b-238">Our example scripts run the queries using a static [resource class](/azure/sql-data-warehouse/resource-classes-for-workload-management).</span></span>

### <a name="load-the-semantic-model"></a><span data-ttu-id="cc29b-239">Загрузка семантической модели</span><span class="sxs-lookup"><span data-stu-id="cc29b-239">Load the semantic model</span></span>

<span data-ttu-id="cc29b-240">Загрузка данных в табличную модель в Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="cc29b-240">Load the data into a tabular model in Azure Analysis Services.</span></span> <span data-ttu-id="cc29b-241">На этом этапе создается семантическая модель данных с помощью средства SQL Server Data Tools (SSDT).</span><span class="sxs-lookup"><span data-stu-id="cc29b-241">In this step, you create a semantic data model by using SQL Server Data Tools (SSDT).</span></span> <span data-ttu-id="cc29b-242">Можно также создать модель путем импорта из файла Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="cc29b-242">You can also create a model by importing it from a Power BI Desktop file.</span></span> <span data-ttu-id="cc29b-243">Поскольку хранилище данных SQL не поддерживает внешние ключи, необходимо добавить связи для семантической модели, чтобы можно было присоединиться к таблицам.</span><span class="sxs-lookup"><span data-stu-id="cc29b-243">Because SQL Data Warehouse does not support foreign keys, you must add the relationships to the semantic model, so that you can join across tables.</span></span>

### <a name="use-power-bi-to-visualize-the-data"></a><span data-ttu-id="cc29b-244">Использование Power BI для визуализации данных</span><span class="sxs-lookup"><span data-stu-id="cc29b-244">Use Power BI to visualize the data</span></span>

<span data-ttu-id="cc29b-245">Существует два варианта подключения Power BI к Azure Analysis Services:</span><span class="sxs-lookup"><span data-stu-id="cc29b-245">Power BI supports two options for connecting to Azure Analysis Services:</span></span>

- <span data-ttu-id="cc29b-246">Импорт.</span><span class="sxs-lookup"><span data-stu-id="cc29b-246">Import.</span></span> <span data-ttu-id="cc29b-247">Данные импортируются в модель Power BI.</span><span class="sxs-lookup"><span data-stu-id="cc29b-247">The data is imported into the Power BI model.</span></span>
- <span data-ttu-id="cc29b-248">Активное подключение.</span><span class="sxs-lookup"><span data-stu-id="cc29b-248">Live Connection.</span></span> <span data-ttu-id="cc29b-249">Данные извлекаются непосредственно из Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="cc29b-249">Data is pulled directly from Analysis Services.</span></span>

<span data-ttu-id="cc29b-250">Корпорация Майкрософт рекомендует активное подключение, так как оно не требует копирования данных в модели Power BI.</span><span class="sxs-lookup"><span data-stu-id="cc29b-250">We recommend Live Connection because it doesn't require copying data into the Power BI model.</span></span> <span data-ttu-id="cc29b-251">Кроме того, использование DirectQuery гарантирует, что результаты всегда соответствуют последним исходным данным.</span><span class="sxs-lookup"><span data-stu-id="cc29b-251">Also, using DirectQuery ensures that results are always consistent with the latest source data.</span></span> <span data-ttu-id="cc29b-252">Дополнительные сведения см. в разделе [Подключение с помощью Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span><span class="sxs-lookup"><span data-stu-id="cc29b-252">For more information, see [Connect with Power BI](/azure/analysis-services/analysis-services-connect-pbi).</span></span>

<span data-ttu-id="cc29b-253">**рекомендации**;</span><span class="sxs-lookup"><span data-stu-id="cc29b-253">**Recommendations**</span></span>

<span data-ttu-id="cc29b-254">Избегайте запуска запросов панели управления бизнес-аналитики непосредственно к хранилищу данных.</span><span class="sxs-lookup"><span data-stu-id="cc29b-254">Avoid running BI dashboard queries directly against the data warehouse.</span></span> <span data-ttu-id="cc29b-255">Информационные панели бизнес-аналитики требуют очень малого времени отклика, которого может не хватить на прямые запросы к хранилищу.</span><span class="sxs-lookup"><span data-stu-id="cc29b-255">BI dashboards require very low response times, which direct queries against the warehouse may be unable to satisfy.</span></span> <span data-ttu-id="cc29b-256">Кроме того, при обновлении информационной панели будет учитываться количество одновременных запросов, что может повлиять на производительность.</span><span class="sxs-lookup"><span data-stu-id="cc29b-256">Also, refreshing the dashboard will count against the number of concurrent queries, which could impact performance.</span></span> 

<span data-ttu-id="cc29b-257">Azure Analysis Services предназначена для обработки требований к запросу информационной панели бизнес-аналитики, поэтому рекомендуемая практика заключается в том, чтобы запрашивать Analysis Services из Power BI.</span><span class="sxs-lookup"><span data-stu-id="cc29b-257">Azure Analysis Services is designed to handle the query requirements of a BI dashboard, so the recommended practice is to query Analysis Services from Power BI.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="cc29b-258">Вопросы масштабируемости</span><span class="sxs-lookup"><span data-stu-id="cc29b-258">Scalability considerations</span></span>

### <a name="sql-data-warehouse"></a><span data-ttu-id="cc29b-259">Хранилище данных SQL</span><span class="sxs-lookup"><span data-stu-id="cc29b-259">SQL Data Warehouse</span></span>

<span data-ttu-id="cc29b-260">С хранилищем данных SQL можно по требованию масштабировать вычислительные ресурсы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-260">With SQL Data Warehouse, you can scale out your compute resources on demand.</span></span> <span data-ttu-id="cc29b-261">Механизм запросов оптимизирует запросы для параллельной обработки на основе количества вычислительных узлов и перемещает данные между узлами по мере необходимости.</span><span class="sxs-lookup"><span data-stu-id="cc29b-261">The query engine optimizes queries for parallel processing based on the number of compute nodes, and moves data between nodes as necessary.</span></span> <span data-ttu-id="cc29b-262">Дополнительные сведения см. в разделе [Управление вычислительными ресурсами в хранилище данных SQL Azure](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span><span class="sxs-lookup"><span data-stu-id="cc29b-262">For more information, see [Manage compute in Azure SQL Data Warehouse](/azure/sql-data-warehouse/sql-data-warehouse-manage-compute-overview).</span></span>

### <a name="analysis-services"></a><span data-ttu-id="cc29b-263">Analysis Services</span><span class="sxs-lookup"><span data-stu-id="cc29b-263">Analysis Services</span></span>

<span data-ttu-id="cc29b-264">Для рабочих нагрузок рекомендуется уровень "Стандартный" для служб Azure Analysis Services, так как он поддерживает секционирование и DirectQuery.</span><span class="sxs-lookup"><span data-stu-id="cc29b-264">For production workloads, we recommend the Standard Tier for Azure Analysis Services, because it supports partitioning and DirectQuery.</span></span> <span data-ttu-id="cc29b-265">В пределах уровня размер экземпляра определяет память и мощность обработки.</span><span class="sxs-lookup"><span data-stu-id="cc29b-265">Within a tier, the instance size determines the memory and processing power.</span></span> <span data-ttu-id="cc29b-266">Вычислительная мощность измеряется в единицах обработки запроса (QPUs).</span><span class="sxs-lookup"><span data-stu-id="cc29b-266">Processing power is measured in Query Processing Units (QPUs).</span></span> <span data-ttu-id="cc29b-267">Контролируйте использование QPU, чтобы выбрать необходимый размер.</span><span class="sxs-lookup"><span data-stu-id="cc29b-267">Monitor your QPU usage to select the appropriate size.</span></span> <span data-ttu-id="cc29b-268">Дополнительные сведения см. в разделе [Мониторинг производительности сервера](/azure/analysis-services/analysis-services-monitor).</span><span class="sxs-lookup"><span data-stu-id="cc29b-268">For more information, see [Monitor server metrics](/azure/analysis-services/analysis-services-monitor).</span></span>

<span data-ttu-id="cc29b-269">При высокой нагрузке производительность запросов может ухудшиться из-за параллелизма запросов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-269">Under high load, query performance can become degraded due to query concurrency.</span></span> <span data-ttu-id="cc29b-270">Чтобы одновременно выполнять больше запросов, можно масштабировать службы Analysis Services, создавая пул реплик для обработки запросов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-270">You can scale out Analysis Services by creating a pool of replicas to process queries, so that more queries can be performed concurrently.</span></span> <span data-ttu-id="cc29b-271">Работа по обработке модели данных всегда происходит на основном сервере.</span><span class="sxs-lookup"><span data-stu-id="cc29b-271">The work of processing the data model always happens on the primary server.</span></span> <span data-ttu-id="cc29b-272">Основной сервер по умолчанию также обрабатывает запросы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-272">By default, the primary server also handles queries.</span></span> <span data-ttu-id="cc29b-273">При необходимости можно назначить сервер-источник исключительно для обработки, чтобы пул запросов обрабатывал все запросы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-273">Optionally, you can designate the primary server to run processing exclusively, so that the query pool handles all queries.</span></span> <span data-ttu-id="cc29b-274">В случае высоких требований к обработке нужно отделить обработку от пула запросов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-274">If you have high processing requirements, you should separate the processing from the query pool.</span></span> <span data-ttu-id="cc29b-275">В случае высокой нагрузки запросов и относительно несложной обработки можно включить сервер-источник в пул запросов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-275">If you have high query loads, and relatively light processing, you can include the primary server in the query pool.</span></span> <span data-ttu-id="cc29b-276">Дополнительные сведения см. в разделе [Горизонтальное масштабирование служб Azure Analysis Services](/azure/analysis-services/analysis-services-scale-out).</span><span class="sxs-lookup"><span data-stu-id="cc29b-276">For more information, see [Azure Analysis Services scale-out](/azure/analysis-services/analysis-services-scale-out).</span></span> 

<span data-ttu-id="cc29b-277">Чтобы уменьшить объем ненужной обработки, рассмотрите возможность использования секций для разделения табличной модели на логические части.</span><span class="sxs-lookup"><span data-stu-id="cc29b-277">To reduce the amount of unnecessary processing, consider using partitions to divide the tabular model into logical parts.</span></span> <span data-ttu-id="cc29b-278">Каждая секция может обрабатываться отдельно.</span><span class="sxs-lookup"><span data-stu-id="cc29b-278">Each partition can be processed separately.</span></span> <span data-ttu-id="cc29b-279">Дополнительные сведения см. в разделе [Секция](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span><span class="sxs-lookup"><span data-stu-id="cc29b-279">For more information, see [Partitions](/sql/analysis-services/tabular-models/partitions-ssas-tabular).</span></span>

## <a name="security-considerations"></a><span data-ttu-id="cc29b-280">Вопросы безопасности</span><span class="sxs-lookup"><span data-stu-id="cc29b-280">Security considerations</span></span>

### <a name="ip-whitelisting-of-analysis-services-clients"></a><span data-ttu-id="cc29b-281">Список разрешенных IP-адресов клиентов службы Analysis Services</span><span class="sxs-lookup"><span data-stu-id="cc29b-281">IP whitelisting of Analysis Services clients</span></span>

<span data-ttu-id="cc29b-282">Рассмотрите возможность использования функции брандмауэра службы Analysis Services белого списка клиентских IP-адресов.</span><span class="sxs-lookup"><span data-stu-id="cc29b-282">Consider using the Analysis Services firewall feature to whitelist client IP addresses.</span></span> <span data-ttu-id="cc29b-283">Если параметр включен, брандмауэр блокирует все клиентские соединения, которые отличаются от указанных в правилах брандмауэра.</span><span class="sxs-lookup"><span data-stu-id="cc29b-283">If enabled, the firewall blocks all client connections other than those specified in the firewall rules.</span></span> <span data-ttu-id="cc29b-284">Стандартные правила присваивают белый список службе Power BI, но при необходимости можно отключить это правило.</span><span class="sxs-lookup"><span data-stu-id="cc29b-284">The default rules whitelist the Power BI service, but you can disable this rule if desired.</span></span> <span data-ttu-id="cc29b-285">Дополнительные сведения см. в разделе [Усиление защиты Azure Analysis Services благодаря новым возможностям брандмауэра](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span><span class="sxs-lookup"><span data-stu-id="cc29b-285">For more information, see [Hardening Azure Analysis Services with the new firewall capability](https://azure.microsoft.com/blog/hardening-azure-analysis-services-with-the-new-firewall-capability/).</span></span>

### <a name="authorization"></a><span data-ttu-id="cc29b-286">Авторизация</span><span class="sxs-lookup"><span data-stu-id="cc29b-286">Authorization</span></span>

<span data-ttu-id="cc29b-287">Azure Analysis Services использует Azure Active Directory (Azure AD) для аутентификации пользователей, подключающихся к серверу служб Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="cc29b-287">Azure Analysis Services uses Azure Active Directory (Azure AD) to authenticate users who connect to an Analysis Services server.</span></span> <span data-ttu-id="cc29b-288">Создавая роли и затем назначая их пользователям или группам Azure AD, можно ограничить данные, которые может просматривать конкретный пользователь.</span><span class="sxs-lookup"><span data-stu-id="cc29b-288">You can restrict what data a particular user is able to view, by creating roles and then assigning Azure AD users or groups to those roles.</span></span> <span data-ttu-id="cc29b-289">Для каждой роли можно сделать следующее.</span><span class="sxs-lookup"><span data-stu-id="cc29b-289">For each role, you can:</span></span> 

- <span data-ttu-id="cc29b-290">Защитить таблицы или отдельные столбцы.</span><span class="sxs-lookup"><span data-stu-id="cc29b-290">Protect tables or individual columns.</span></span> 
- <span data-ttu-id="cc29b-291">Защитить отдельные строки на основе выражения фильтра.</span><span class="sxs-lookup"><span data-stu-id="cc29b-291">Protect individual rows based on filter expressions.</span></span> 

<span data-ttu-id="cc29b-292">Дополнительные сведения см. в разделе [Управление ролями и пользователями базы данных](/azure/analysis-services/analysis-services-database-users).</span><span class="sxs-lookup"><span data-stu-id="cc29b-292">For more information, see [Manage database roles and users](/azure/analysis-services/analysis-services-database-users).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="cc29b-293">Развертывание решения</span><span class="sxs-lookup"><span data-stu-id="cc29b-293">Deploy the solution</span></span>

<span data-ttu-id="cc29b-294">Чтобы выполнить развертывание и запуск эталонной реализации, выполните действия, описанные в [файле сведений на GitHub][github-folder].</span><span class="sxs-lookup"><span data-stu-id="cc29b-294">To the deploy and run the reference implementation, follow the steps in the [GitHub readme][github-folder].</span></span> <span data-ttu-id="cc29b-295">Он позволяет развернуть следующее:</span><span class="sxs-lookup"><span data-stu-id="cc29b-295">It deploys the following:</span></span>

  * <span data-ttu-id="cc29b-296">Виртуальную машину Windows для имитации локального сервера базы данных.</span><span class="sxs-lookup"><span data-stu-id="cc29b-296">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="cc29b-297">Она включает SQL Server 2017 и связанные с ним инструменты, а также Power BI Desktop.</span><span class="sxs-lookup"><span data-stu-id="cc29b-297">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
  * <span data-ttu-id="cc29b-298">Учетная запись хранения Azure, которая обеспечивает хранилище больших двоичных объектов для хранения данных, экспортированных из базы данных SQL Server.</span><span class="sxs-lookup"><span data-stu-id="cc29b-298">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
  * <span data-ttu-id="cc29b-299">Экземпляр хранилища данных SQL Azure.</span><span class="sxs-lookup"><span data-stu-id="cc29b-299">An Azure SQL Data Warehouse instance.</span></span>
  * <span data-ttu-id="cc29b-300">Экземпляр службы Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="cc29b-300">An Azure Analysis Services instance.</span></span>


## <a name="next-steps"></a><span data-ttu-id="cc29b-301">Дополнительная информация</span><span class="sxs-lookup"><span data-stu-id="cc29b-301">Next steps</span></span>

- <span data-ttu-id="cc29b-302">Для автоматизации этого конвейера используйте Фабрика данных Azure.</span><span class="sxs-lookup"><span data-stu-id="cc29b-302">Use Azure Data Factory to automate the ELT pipeline.</span></span> <span data-ttu-id="cc29b-303">См. сведения об [автоматизированной корпоративной бизнес-аналитике с использованием Хранилища данных SQL и Фабрики данных Azure][adf-ra].</span><span class="sxs-lookup"><span data-stu-id="cc29b-303">See [Automated enterprise BI with SQL Data Warehouse and Azure Data Factory][adf-ra].</span></span>

<!-- links -->

[adf-ra]: ./enterprise-bi-adf.md
[github-folder]: https://github.com/mspnp/reference-architectures/tree/master/data/enterprise_bi_sqldw
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database

