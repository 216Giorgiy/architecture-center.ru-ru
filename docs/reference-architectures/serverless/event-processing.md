---
title: Обработка событий без использования сервера с помощью Функций Azure
titleSuffix: Azure Reference Architectures
description: Эталонная архитектура решения для бессерверного приема событий и обработки событий с помощью Функций Azure.
author: MikeWasson
ms.date: 10/16/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: seodec18, serverless
ms.openlocfilehash: 9d2535c3e350000783265dc58c83d00a38d45448
ms.sourcegitcommit: 1b50810208354577b00e89e5c031b774b02736e2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/23/2019
ms.locfileid: "54486222"
---
# <a name="serverless-event-processing-using-azure-functions"></a>Обработка событий без использования сервера с помощью Функций Azure

Эта эталонная архитектура демонстрирует [бессерверную](https://azure.microsoft.com/solutions/serverless/) и управляемую событиями архитектуру, которая принимает поток данных, обрабатывает его и записывает результаты в серверную базу данных. Эталонную реализацию для этой архитектуры можно найти на сайте [GitHub][github].

![Эталонная архитектура для бессерверной обработки событий с помощью Функций Azure](./_images/serverless-event-processing.png)

## <a name="architecture"></a>Архитектура

**Центры событий** принимают поток данных. Служба [Центры событий][eh] предназначена для сценариев потоковой передачи данных с высокой пропускной способностью.

> [!NOTE]
> Для сценариев Интернета вещей мы рекомендуем использовать Центр Интернета вещей. Центр Интернета вещей содержит встроенную конечную точку, которая совместима с API Центров событий Azure, поэтому вы можете использовать любую службу в этой архитектуре без существенных изменений внутренней обработки. Дополнительные сведения см. в статье [Подключение устройств Интернета вещей в Azure. Центр Интернета вещей и Центры событий][iot].

**Приложение-функция**. [Функции Azure][functions] — это независимая от сервера служба вычислений. Она использует управляемую событиями модель, где часть кода ("функция") вызывается триггером. В этой архитектуре, когда события поступают в Центры событий, они инициируют функцию, которая обрабатывает события и записывает результаты в хранилище.

Приложения-функции подходят для обработки отдельных записей из Центров событий. Для более сложных сценариев обработки потока рассмотрите Apache Spark с использованием Azure Databricks или Azure Stream Analytics.

**Cosmos DB**. [Azure Cosmos DB][cosmosdb] — это служба многомодельной базы данных. В этом сценарии функция обработки событий сохраняет записи JSON с помощью [SQL API][cosmosdb-sql] Cosmos DB.

**Хранилище очередей**. [Хранилище очередей][queue] используется для недоставленных сообщений. Если при обработке события возникает ошибка, функция сохраняет данные события в очереди недоставленных сообщений для последующей обработки. Дополнительные сведения см. в разделе [Рекомендации по обеспечению устойчивости](#resiliency-considerations).

**Azure Monitor**. [Monitor][monitor] собирает метрики производительности о службах Azure, развернутых в решении. Отобразив эти данные в визуализации на панели мониторинга, можно получить сведения о работоспособности решения.

**Azure Pipelines**. [Pipelines][pipelines] — это служба непрерывной интеграции (CI) и непрерывной поставки (CD), которая выполняет сборку, тестирование и развертывание приложений.

## <a name="scalability-considerations"></a>Вопросы масштабируемости

### <a name="event-hubs"></a>Центры событий;

Пропускная способность Центров событий вычисляется в [единицах пропускной способности][eh-throughput]. Вы можете автоматически масштабировать концентратор событий, включив [автоматическое расширение][eh-autoscale]. Это позволит автоматически масштабировать единицы пропускной способности в зависимости от трафика вплоть до заданного максимума.

[Триггер концентратора событий][eh-trigger] в приложении-функции масштабируется в соответствии с числом секций в концентраторе событий. Каждой секции назначается один экземпляр функции за раз. Для увеличения пропускной способности получайте события в пакете, а не по одному за раз.

### <a name="cosmos-db"></a>База данных Cosmos

Пропускная способность для Cosmos DB измеряется в [единицах запроса][ru] (ЕЗ). Чтобы масштабировать контейнер Cosmos DB на более чем 10 000 единиц запросов, необходимо указать [ключ секции][partition-key] при создании контейнера и добавить этот ключ в каждый создаваемый документ.

Вот некоторые характеристики хорошего ключа секции:

- Значение пространства ключа велико.
- Будет существовать равномерное распределение операций чтения и записи на значение ключа, что позволит избежать горячих ключей.
- Максимальный объем данных, хранимых для любого отдельного значения ключа, не может превышать максимальный физический размер секции (10 ГБ).
- Ключ секции для документа не изменится. Обновить ключ секции для существующего документа невозможно.

В сценарии для этой эталонной архитектуры функция хранит только один документ для устройства, отправляющего данные. Функция постоянно обновляет в документах последнее состояние устройства, используя операцию Upsert. Идентификатор устройства является подходящим ключом секции для этого сценария, так как записи будут равномерно распределены по ключам, а размер каждой секции будет строго ограничен, потому что для каждого значения ключа существует отдельный документ. Дополнительные сведения о ключах секций см. в статье [Секционирование и масштабирование в Azure Cosmos DB][cosmosdb-scale].

## <a name="resiliency-considerations"></a>Рекомендации по обеспечению устойчивости

При использовании триггера Центров событий с Функциями перехват исключений происходит в цикле обработки. Если возникает необработанное исключение, среда выполнения Функций не выполняет повторную попытку отправки сообщения. Если сообщение не может быть обработано, поместите его в очередь недоставленных сообщений. Используйте внешний процесс, чтобы изучить сообщения и определить корректирующее действие.

В следующем коде показано, как функция приема перехватывает исключения и помещает необработанные сообщения в очередь недоставленных сообщений.

```csharp
[FunctionName("RawTelemetryFunction")]
[StorageAccount("DeadLetterStorage")]
public static async Task RunAsync(
    [EventHubTrigger("%EventHubName%", Connection = "EventHubConnection", ConsumerGroup ="%EventHubConsumerGroup%")]EventData[] messages,
    [Queue("deadletterqueue")] IAsyncCollector<DeadLetterMessage> deadLetterMessages,
    ILogger logger)
{
    foreach (var message in messages)
    {
        DeviceState deviceState = null;

        try
        {
            deviceState = telemetryProcessor.Deserialize(message.Body.Array, logger);
        }
        catch (Exception ex)
        {
            logger.LogError(ex, "Error deserializing message", message.SystemProperties.PartitionKey, message.SystemProperties.SequenceNumber);
            await deadLetterMessages.AddAsync(new DeadLetterMessage { Issue = ex.Message, EventData = message });
        }

        try
        {
            await stateChangeProcessor.UpdateState(deviceState, logger);
        }
        catch (Exception ex)
        {
            logger.LogError(ex, "Error updating status document", deviceState);
            await deadLetterMessages.AddAsync(new DeadLetterMessage { Issue = ex.Message, EventData = message, DeviceState = deviceState });
        }
    }
}
```

Обратите внимание, что функция использует [выходную привязку хранилища очередей][queue-binding], чтобы поместить элементы в очередь.

Приведенный выше код также регистрирует исключения в Application Insights. Ключ секции и порядковый номер можно использовать для корреляции сообщений в очереди недоставленных сообщений с исключениями в журналах.

Сообщения в очереди недоставленных сообщений должны содержать достаточно информации, чтобы можно было понять контекст ошибки. В этом примере класс `DeadLetterMessage` содержит сообщение об исключении, исходные данные события и десериализованное сообщение о событии (если доступно).

```csharp
public class DeadLetterMessage
{
    public string Issue { get; set; }
    public EventData EventData { get; set; }
    public DeviceState DeviceState { get; set; }
}
```

Используйте [Azure Monitor][monitor] для мониторинга концентратора событий. Если вы видите, что есть входные данные, но нет выходных, это означает, что сообщения не обрабатываются. В таком случае перейдите в [Log Analytics][log-analytics] и поищите исключения или другие ошибки.

## <a name="disaster-recovery-considerations"></a>Рекомендации по аварийному восстановлению

Представленное здесь развертывание расположено в одном регионе Azure. Для более гибкого подхода к аварийному восстановлению воспользуйтесь функциями геораспределения в различных службах:

- **Центры событий**. Создайте два пространства имен Центров событий: основное (активное) и дополнительное (пассивное). Сообщения автоматически перенаправляются в активное пространство имен, если вы не выполните отработку отказа в дополнительное пространство имен. Дополнительные сведения см. в статье [Географическое аварийное восстановление в Центрах событий Azure][eh-dr].

- **Приложение-функция**. Разверните второе приложение-функцию, которое ожидает считывания из дополнительного пространства имен Центров событий. Эта функция выполняет запись в дополнительную учетную запись хранения для очереди недоставленных сообщений.

- **Cosmos DB**. Cosmos DB поддерживает [несколько основных регионов][cosmosdb-geo], что позволяет записывать данные в любой регион, добавляемый в учетную запись Cosmos DB. Если не включить несколько источников, можно по-прежнему выполнить отработку отказа в основной регион записи. Клиентские пакеты SDK Cosmos DB и привязки функций Azure автоматически выполняют отработку отказа, поэтому нет необходимости обновлять параметры конфигурации приложения.

- **Хранилище Azure.** Используйте хранилище [RA-GRS][ra-grs] для очереди недоставленных сообщений. В таком случае создается реплика только для чтения в другом регионе. Если основной регион становится недоступным, вы можете считывать элементы, находящиеся в очереди. Кроме того, можно подготовить другую учетную запись хранения в дополнительном регионе, в которую функция сможет записывать данные после отработки отказа.

## <a name="deploy-the-solution"></a>Развертывание решения

Чтобы развернуть эту эталонную архитектуру, просмотрите [файл сведений на GitHub][readme].

<!-- links -->

[cosmosdb]: /azure/cosmos-db/introduction
[cosmosdb-geo]: /azure/cosmos-db/distribute-data-globally
[cosmosdb-scale]: /azure/cosmos-db/partition-data
[cosmosdb-sql]: /azure/cosmos-db/sql-api-introduction
[eh]: /azure/event-hubs/
[eh-autoscale]: /azure/event-hubs/event-hubs-auto-inflate
[eh-dr]: /azure/event-hubs/event-hubs-geo-dr
[eh-throughput]: /azure/event-hubs/event-hubs-features#throughput-units
[eh-trigger]: /azure/azure-functions/functions-bindings-event-hubs
[functions]: /azure/azure-functions/functions-overview
[iot]: /azure/iot-hub/iot-hub-compare-event-hubs
[log-analytics]: /azure/log-analytics/log-analytics-queries
[monitor]: /azure/azure-monitor/overview
[partition-key]: /azure/cosmos-db/partition-data
[pipelines]: /azure/devops/pipelines/index
[queue]: /azure/storage/queues/storage-queues-introduction
[queue-binding]: /azure/azure-functions/functions-bindings-storage-queue#output
[ra-grs]: /azure/storage/common/storage-redundancy-grs
[ru]: /azure/cosmos-db/request-units

[github]: https://github.com/mspnp/serverless-reference-implementation
[readme]: https://github.com/mspnp/serverless-reference-implementation/blob/master/README.md
