---
title: Реализация звездообразной топологии сети в Azure
titleSuffix: Azure Reference Architectures
description: Реализуйте звездообразную топологию сети в Azure.
author: telmosampaio
ms.date: 10/08/2018
ms.custom: seodec18
pnp.series.title: Implement a hub-spoke network topology in Azure
pnp.series.prev: expressroute
ms.openlocfilehash: 23821353fe943d3e389ed89ca26b946ff6afeed3
ms.sourcegitcommit: 88a68c7e9b6b772172b7faa4b9fd9c061a9f7e9d
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/08/2018
ms.locfileid: "53120309"
---
# <a name="implement-a-hub-spoke-network-topology-in-azure"></a>Реализация звездообразной топологии сети в Azure

На схеме эталонной архитектуры представлены сведения о том, как реализовать звездообразную топологию в Azure. *Концентратор* является виртуальной сетью в Azure, которая выступает в качестве центральной точки подключения к вашей локальной сети. *Периферийные зоны* — это виртуальные сети, которые устанавливают пиринг с концентратором и могут использоваться для изоляции рабочих нагрузок. Трафик передается между локальным центром обработки данных и концентратором через подключение ExpressRoute или VPN-шлюз. [**Разверните это решение**](#deploy-the-solution).

![[0]][0]

*Скачайте [файл Visio][visio-download] этой архитектуры*

Преимущества этой топологии:

- **Сокращение затрат** путем централизации служб, которые могут совместно использоваться несколькими рабочими нагрузками, такими как сетевые виртуальные устройства (NVA) и DNS-серверы в одном расположении.
- **Превышение лимитов подписки** путем пиринга виртуальных сетей из разных подписок к центральному концентратору.
- **Разделение областей ответственности** между центральным ИТ-отделом (SecOps, InfraOps) и рабочими нагрузками (DevOps).

Типичные способы использования этой архитектуры:

- Рабочая нагрузка, развернутая в разных средах, например в среде для разработки, тестирования и в рабочей среде, для которых требуются общие службы, например DNS, IDS, NTP или AD DS. Общие службы размещаются в виртуальной сети концентратора, в то время как каждая среда развертывается в периферийной зоне для обеспечения изоляции.
- Рабочие нагрузки, которые не требуют подключения друг к другу, но требуют доступа к общим службам.
- Предприятия, которые требуют централизованного контроля над аспектами безопасности, такими как брандмауэр в концентраторе, таком как сеть периметра, и отдельного управления для рабочих нагрузок в каждой периферийной зоне.

## <a name="architecture"></a>Архитектура

Архитектура состоит из следующих компонентов:

- **Локальная сеть.** Частная локальная сеть, работающая внутри организации.

- **VPN-устройство**. Устройство или служба, предоставляющая возможность внешнего подключения к локальной сети. VPN-устройство может быть аппаратным устройством или программным решением, таким как служба маршрутизации и удаленного доступа (RRAS) в Windows Server 2012. Список поддерживаемых VPN-устройств и информацию о настройке выбранных VPN-устройств для подключения к Azure см. в статье [VPN-устройства и параметры IPsec/IKE для подключений типа "сеть — сеть" через VPN-шлюз][vpn-appliance].

- **Сетевой шлюз виртуальной сети VPN или шлюз ExpressRoute**. Шлюз виртуальной сети позволяет виртуальной сети подключаться к VPN-устройству или к каналу ExpressRoute, которые используются для подключения к вашей локальной сети. Дополнительные сведения см. в статье [Подключение локальной сети к виртуальной сети Microsoft Azure][connect-to-an-Azure-vnet].

> [!NOTE]
> В сценариях развертывания для этой эталонной архитектуры используется VPN-шлюз для подключения, а виртуальная сеть в Azure используется для имитации вашей локальной сети.

- **Виртуальная сеть концентратора**. Виртуальная сеть Azure используется в качестве концентратора в звездообразной топологии. Концентратор является центральной точкой подключения к вашей локальной сети и местом для размещения служб, которые могут использоваться различными рабочими нагрузками, размещенными в виртуальных сетях.

- **Подсеть шлюза**. Шлюзы виртуальных сетей хранятся в одной подсети.

- **Виртуальные сети периферийных зон**. Одна или несколько виртуальных сетей Azure, которые используются в качестве периферийных зон в звездообразной топологии. Периферийные зоны можно использовать для изоляции рабочих нагрузок в их виртуальных сетях, управляемых отдельно от других периферийных зон. Каждая рабочая нагрузка может содержать несколько уровней с несколькими подсетями, подключенными через подсистемы балансировки нагрузки Azure. Дополнительные сведения об инфраструктуре приложений см. в статьях [Запуск рабочих нагрузок на виртуальных машинах Windows][windows-vm-ra] и [Запуск рабочих нагрузок на виртуальной машине Linux][linux-vm-ra].

- **Пиринговая связь между виртуальными сетями**. Две виртуальные сети можно подключить между собой с помощью [пирингового подключения][vnet-peering]. Пиринговые подключения представляют собой нетранзитивные подключения между виртуальными подсетями с низкой задержкой. После установки пирингового подключения виртуальные сети обмениваются трафиком по магистрали Azure без необходимости использования маршрутизатора. В звездообразной топологии сети пиринг виртуальной сети используется для подключения концентратора к каждой периферийной зоне. Пиринг можно создать между виртуальными сетями в одном или в разных регионах. Дополнительные сведения см. в разделе [Требования и ограничения][vnet-peering-requirements].

> [!NOTE]
> В этой статье рассматриваются только [развертывания Resource Manager](/azure/azure-resource-manager/resource-group-overview), но вы также можете подключить классическую виртуальную сеть к виртуальной сети Resource Manager в той же подписке. Таким образом, ваши периферийные зоны могут размещать классические развертывания и по-прежнему пользоваться преимуществами общих служб в концентраторе.

## <a name="recommendations"></a>Рекомендации

Следующие рекомендации применимы для большинства ситуаций. Следуйте этим рекомендациям, если они не противоречат особым требованиям для вашего случая.

### <a name="resource-groups"></a>Группы ресурсов

Центральную виртуальную сеть и каждую периферийную виртуальную сеть, можно реализовать в разных группах ресурсов и даже в разных подписках. Если вы устанавливаете пиринг виртуальных сетей в разных подписках, обе подписки могут быть связаны с одним и тем же или с разными клиентами Azure Active Directory. Это позволяет осуществлять децентрализованное управление каждой рабочей нагрузкой при совместном использовании служб, поддерживаемых в концентраторе виртуальной сети.

### <a name="vnet-and-gatewaysubnet"></a>Виртуальная сеть и подсеть шлюза

Создание подсети с именем *GatewaySubnet* с диапазоном адресов /27. Эта подсеть необходима для шлюза виртуальной сети. Выделение 32 адресов этой подсети поможет предотвратить достижение ограничения размера шлюза в будущем.

Дополнительные сведения о настройке шлюза см. в следующих статьях с данными об эталонных архитектурах в зависимости от типа подключения:

- [Connect an on-premises network to Azure using ExpressRoute][guidance-expressroute] (Подключение локальной сети к Azure с помощью ExpressRoute).
- [Connect an on-premises network to Azure using a VPN gateway][guidance-vpn] (Подключение локальной сети к Azure с помощью VPN-шлюза).

Для обеспечения высокой доступности вы можете использовать ExpressRoute вместе с VPN для отработки отказа. Ознакомьтесь со статьей [Connect an on-premises network to Azure using ExpressRoute with VPN failover][hybrid-ha] (Подключение локальной сети к Azure с помощью ExpressRoute с отработкой отказа VPN).

Звездообразная топология может также использоваться без шлюза, если вам не требуется связь с локальной сетью.

### <a name="vnet-peering"></a>Пиринговая связь между виртуальными сетями

Пиринговая связь между виртуальными сетями — это нетранзитивная связь между двумя виртуальными сетями. Если вам требуется, чтобы периферийные зоны соединялись друг с другом, подумайте над добавлением отдельного пирингового подключения между ними.

Однако при наличии нескольких периферийных зон, которые требуется подключить между собой, очень скоро возникнет нехватка пиринговых подключений из-за ограничения [числа пиринговых подключений на каждую виртуальную сеть][vnet-peering-limit]. В этом случае рассмотрите возможность использования пользовательских маршрутов (UDR) для принудительной передачи трафика, предназначенного для периферийной зоны, на виртуальное сетевое устройство (NVA), выступающее в роли маршрутизатора в виртуальной сети концентратора. Это позволит периферийным зонам подключаться друг к другу.

Вы также можете настроить периферийные зоны для использования шлюза виртуальной сети концентратора для подключения к удаленным сетям. Чтобы разрешить передачу трафика шлюза из периферийной зоны в концентратор и подключение к удаленным сетям, требуется сделать следующее:

- Настроить пиринговую связь между виртуальными сетями в концентраторе, чтобы **разрешить транзит шлюзов**.
- Настроить пиринговое подключение виртуальной сети к каждой периферийной зоне для **использования удаленных шлюзов**.
- Настроить все пиринговые соединения виртуальных сетей, чтобы **разрешить перенаправление трафика**.

## <a name="considerations"></a>Рекомендации

### <a name="spoke-connectivity"></a>Подключение периферийной зоны

Если вам требуется подключение между периферийными зонами, подумайте о внедрении виртуального сетевого устройства для маршрутизации в концентраторе и использовании определяемых пользователем маршрутов в периферийных зонах для направления трафика в концентратор.

![[2]][2]

В этом случае необходимо настроить пиринговые соединения, чтобы **разрешить перенаправленный трафик**.

### <a name="overcoming-vnet-peering-limits"></a>Преодоление ограничения пиринговых подключений виртуальной сети

Убедитесь, что вы учли [ограничение числа пиринговых подключений виртуальных сетей на одну виртуальную сеть][vnet-peering-limit] в Azure. Если вам нужно превысить лимит по периферийным зонам, подумайте о создании вложенной звездообразной топологии, где первый уровень периферийных зон также выступает в качестве концентраторов. Этот подход показан на схеме ниже.

![[3]][3]

Кроме того, следует учитывать, какие службы используются совместно в концентраторе, чтобы убедиться, что концентратор масштабируется в соответствии с большим количеством периферийных зон. Например, если ваш концентратор предоставляет службы брандмауэра, рассмотрите возможность ограничения пропускной способности решения брандмауэра при добавлении нескольких периферийных зон. Возможно, вам захочется перенести некоторые из этих общих служб на второй уровень концентраторов.

## <a name="deploy-the-solution"></a>Развертывание решения

Пример развертывания для этой архитектуры можно найти на портале [GitHub][ref-arch-repo]. В нем используются виртуальные машины в каждой виртуальной сети для проверки возможности подключения. В подсети **shared-services** в **виртуальной сети концентратора** нет настоящих служб.

Развертывание создает в вашей подписке следующие группы ресурсов:

- hub-nva-rg
- hub-vnet-rg
- onprem-jb-rg
- onprem-vnet-rg
- spoke1-vnet-rg
- spoke2-vent-rg

Файлы параметров шаблона ссылаются на эти имена, поэтому, если вы их изменяете, соответствующим образом обновите файлы параметров.

### <a name="prerequisites"></a>Предварительные требования

[!INCLUDE [ref-arch-prerequisites.md](../../../includes/ref-arch-prerequisites.md)]

### <a name="deploy-the-simulated-on-premises-datacenter"></a>Развертывание имитации локального центра обработки данных

Чтобы развернуть имитацию локального центра обработки данных в виртуальной сети Azure, следуйте этим инструкциям:

1. Перейдите в папку `hybrid-networking/hub-spoke` в репозитории эталонных архитектур.

2. Откройте файл `onprem.json` . Замените значения для `adminUsername` и `adminPassword`.

    ```json
    "adminUsername": "<user name>",
    "adminPassword": "<password>",
    ```

3. Для развертывания Linux установите `osType` как `Linux` (необязательно).

4. Выполните следующую команду:

    ```bash
    azbb -s <subscription_id> -g onprem-vnet-rg -l <location> -p onprem.json --deploy
    ```

5. Дождитесь завершения развертывания. При развертывании создается виртуальная сеть, виртуальная машина и VPN-шлюз. Для создания VPN-шлюза может потребоваться около 40 минут.

### <a name="deploy-the-hub-vnet"></a>Развертывание концентратора виртуальной сети

Чтобы развернуть концентратор виртуальной сети, выполните следующие действия.

1. Откройте файл `hub-vnet.json` . Замените значения для `adminUsername` и `adminPassword`.

    ```json
    "adminUsername": "<user name>",
    "adminPassword": "<password>",
    ```

2. Для развертывания Linux установите `osType` как `Linux` (необязательно).

3. Найдите оба экземпляра `sharedKey` и введите общий ключ для подключения VPN. Значения должны совпадать.

    ```json
    "sharedKey": "",
    ```

4. Выполните следующую команду:

    ```bash
    azbb -s <subscription_id> -g hub-vnet-rg -l <location> -p hub-vnet.json --deploy
    ```

5. Дождитесь завершения развертывания. В ходе этого развертывания создается виртуальная сеть, виртуальная машина, VPN-шлюз и подключение к шлюзу.  Для создания VPN-шлюза может потребоваться около 40 минут.

### <a name="test-connectivity-with-the-hub"></a>Проверка подключения к концентратору

Протестируйте подключение от моделируемой локальной среды к концентратору виртуальной сети.

**Развертывание ОС Windows**

1. Используйте портал Azure для поиска в группе ресурсов `onprem-jb-rg` виртуальной машины с именем `jb-vm1`.

2. Нажмите `Connect`, чтобы открыть сеанс удаленного рабочего стола для виртуальной машины. Используйте пароль, указанный в файле параметров `onprem.json`.

3. Откройте консоль PowerShell в виртуальной машине и используйте командлет `Test-NetConnection`, чтобы убедиться, что вы можете подключиться к виртуальной машине Jumpbox в виртуальной сети концентратора.

   ```powershell
   Test-NetConnection 10.0.0.68 -CommonTCPPort RDP
   ```

Результат должен выглядеть следующим образом.

```powershell
ComputerName     : 10.0.0.68
RemoteAddress    : 10.0.0.68
RemotePort       : 3389
InterfaceAlias   : Ethernet 2
SourceAddress    : 192.168.1.000
TcpTestSucceeded : True
```

> [!NOTE]
> По умолчанию виртуальные машины Windows Server не разрешают трафик ICMP в Azure. Если вы хотите использовать команду `ping` для проверки возможности подключения, включите трафик ICMP в расширенном брандмауэре Windows для каждой виртуальной машины.

**Развертывание ОС Linux**

1. Используйте портал Azure для поиска в группе ресурсов `onprem-jb-rg` виртуальной машины с именем `jb-vm1`.

2. Нажмите `Connect` и скопируйте команду `ssh`, показанную на портале. 

3. В командной строке Linux запустите `ssh`, чтобы подключиться к моделируемой локальной среде. Используйте пароль, указанный в файле параметров `onprem.json`.

4. Используйте команду `ping` для проверки подключения к виртуальной машине Jumpbox в виртуальной сети концентратора:

   ```shell
   ping 10.0.0.68
   ```

### <a name="deploy-the-spoke-vnets"></a>Развертывание виртуальных сетей периферийных зон

Чтобы развернуть виртуальные сети периферийных зон, сделайте следующее.

1. Откройте файл `spoke1.json` . Замените значения для `adminUsername` и `adminPassword`.

    ```json
    "adminUsername": "<user name>",
    "adminPassword": "<password>",
    ```

2. Для развертывания Linux установите `osType` как `Linux` (необязательно).

3. Выполните следующую команду:

   ```bash
   azbb -s <subscription_id> -g spoke1-vnet-rg -l <location> -p spoke1.json --deploy
   ```

4. Повторите шаги 1–2 для файла `spoke2.json`.

5. Выполните следующую команду:

   ```bash
   azbb -s <subscription_id> -g spoke2-vnet-rg -l <location> -p spoke2.json --deploy
   ```

6. Выполните следующую команду:

   ```bash
   azbb -s <subscription_id> -g hub-vnet-rg -l <location> -p hub-vnet-peering.json --deploy
   ```

### <a name="test-connectivity"></a>Проверка подключения

Протестируйте подключение от моделируемой локальной среды к виртуальным сетям периферийных зон.

**Развертывание ОС Windows**

1. Используйте портал Azure для поиска в группе ресурсов `onprem-jb-rg` виртуальной машины с именем `jb-vm1`.

2. Нажмите `Connect`, чтобы открыть сеанс удаленного рабочего стола для виртуальной машины. Используйте пароль, указанный в файле параметров `onprem.json`.

3. Откройте консоль PowerShell в виртуальной машине и используйте командлет `Test-NetConnection`, чтобы проверить возможность подключения к виртуальным машинам Jumpbox в виртуальных сетях периферийных зон.

   ```powershell
   Test-NetConnection 10.1.0.68 -CommonTCPPort RDP
   Test-NetConnection 10.2.0.68 -CommonTCPPort RDP
   ```

**Развертывание ОС Linux**

Чтобы проверить возможность подключения из имитированной локальной среды к виртуальной сети периферийных зон с помощью виртуальных машин Linux, сделайте следующее:

1. Используйте портал Azure для поиска в группе ресурсов `onprem-jb-rg` виртуальной машины с именем `jb-vm1`.

2. Нажмите `Connect` и скопируйте команду `ssh`, показанную на портале.

3. В командной строке Linux запустите `ssh`, чтобы подключиться к моделируемой локальной среде. Используйте пароль, указанный в файле параметров `onprem.json`.

4. Используйте команду `ping`, чтобы проверить возможность подключения к виртуальным машинам jumpbox в каждой периферийной зоне.

   ```bash
   ping 10.1.0.68
   ping 10.2.0.68
   ```

### <a name="add-connectivity-between-spokes"></a>Добавление подключения между периферийными зонами

Этот шаг не является обязательным. Чтобы включить возможность подключения между периферийными зонами, используйте виртуальный сетевой модуль в качестве маршрутизатора виртуальной сети концентратора и принудительно отправляйте трафик из периферийных зон на маршрутизатор при попытке подключения к другой периферийной зоне. Чтобы развернуть базовый пример виртуального сетевого модуля в качестве одной виртуальной машины и разрешить определяемым пользователем маршрутам соединять две виртуальные машины периферийных зон, сделайте следующее:

1. Откройте файл `hub-nva.json` . Замените значения для `adminUsername` и `adminPassword`.

    ```json
    "adminUsername": "<user name>",
    "adminPassword": "<password>",
    ```

2. Выполните следующую команду:

   ```bash
   azbb -s <subscription_id> -g hub-nva-rg -l <location> -p hub-nva.json --deploy
   ```

<!-- links -->

[azure-cli-2]: /azure/install-azure-cli
[azbb]: https://github.com/mspnp/template-building-blocks/wiki/Install-Azure-Building-Blocks
[azure-vpn-gateway]: /azure/vpn-gateway/vpn-gateway-about-vpngateways
[best-practices-security]: /azure/best-practices-network-securit
[connect-to-an-Azure-vnet]: https://technet.microsoft.com/library/dn786406.aspx
[guidance-expressroute]: ./expressroute.md
[guidance-vpn]: ./vpn.md
[linux-vm-ra]: ../virtual-machines-linux/index.md
[hybrid-ha]: ./expressroute-vpn-failover.md
[naming conventions]: /azure/guidance/guidance-naming-conventions
[resource-manager-overview]: /azure/azure-resource-manager/resource-group-overview
[vnet-peering]: /azure/virtual-network/virtual-network-peering-overview
[vnet-peering-limit]: /azure/azure-subscription-service-limits#networking-limits
[vnet-peering-requirements]: /azure/virtual-network/virtual-network-manage-peering#requirements-and-constraints
[vpn-appliance]: /azure/vpn-gateway/vpn-gateway-about-vpn-devices
[windows-vm-ra]: ../virtual-machines-windows/index.md
[visio-download]: https://archcenter.blob.core.windows.net/cdn/hybrid-network-hub-spoke.vsdx
[ref-arch-repo]: https://github.com/mspnp/reference-architectures

[0]: ./images/hub-spoke.png "Звездообразная топология в Azure"
[1]: ./images/hub-spoke-gateway-routing.svg "Звездообразная топология в Azure с транзитивной маршрутизацией"
[2]: ./images/hub-spoke-no-gateway-routing.svg "Звездообразная топология в Azure с транзитивной маршрутизацией с использованием виртуального сетевого устройства (NVA)"
[3]: ./images/hub-spokehub-spoke.svg "Вложенная звездообразная топология в Azure"
[ARM-Templates]: https://azure.microsoft.com/documentation/articles/resource-group-authoring-templates/
