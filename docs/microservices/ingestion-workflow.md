---
title: Прием данных и рабочий процесс в микрослужбах
description: Прием данных и рабочий процесс в микрослужбах
author: MikeWasson
ms.date: 10/23/2018
ms.openlocfilehash: 8a6d2d3209ca61e0588c96ed92862c1a7b91109f
ms.sourcegitcommit: 1f4cdb08fe73b1956e164ad692f792f9f635b409
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/08/2019
ms.locfileid: "54112810"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="db0b5-103">Проектирование микрослужб. Прием данных и рабочий процесс</span><span class="sxs-lookup"><span data-stu-id="db0b5-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="db0b5-104">У микрослужб часто есть рабочий процесс, который охватывает несколько служб для одной транзакции.</span><span class="sxs-lookup"><span data-stu-id="db0b5-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="db0b5-105">Рабочий процесс должен быть надежным. Он не должен терять транзакции или оставлять их в частично завершенном состоянии.</span><span class="sxs-lookup"><span data-stu-id="db0b5-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="db0b5-106">Также важно управлять скоростью приема входящих запросов.</span><span class="sxs-lookup"><span data-stu-id="db0b5-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="db0b5-107">Когда большое количество небольших служб обмениваются данными друг с другом, большой пакет входящих запросов может вызвать перегрузку взаимодействия служб.</span><span class="sxs-lookup"><span data-stu-id="db0b5-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span>

![Схема рабочего процесса приема](./images/ingestion-workflow.png)

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="db0b5-109">Рабочий процесс доставки с помощью дронов</span><span class="sxs-lookup"><span data-stu-id="db0b5-109">The drone delivery workflow</span></span>

<span data-ttu-id="db0b5-110">Чтобы запланировать доставку в приложении доставки с помощью дронов, необходимо выполнить следующие операции:</span><span class="sxs-lookup"><span data-stu-id="db0b5-110">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="db0b5-111">Проверьте состояние учетной записи пользователя (служба учетных записей).</span><span class="sxs-lookup"><span data-stu-id="db0b5-111">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="db0b5-112">Создайте сущность посылки (служба посылок).</span><span class="sxs-lookup"><span data-stu-id="db0b5-112">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="db0b5-113">Проверьте, требуется ли для этой доставки транспортировка сторонними лицами на основе местоположения для выемки и доставки (сторонняя служба транспортировки).</span><span class="sxs-lookup"><span data-stu-id="db0b5-113">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="db0b5-114">Запланируйте выемку с помощью дрона (служба дронов).</span><span class="sxs-lookup"><span data-stu-id="db0b5-114">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="db0b5-115">Создайте сущность доставки (служба доставки).</span><span class="sxs-lookup"><span data-stu-id="db0b5-115">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="db0b5-116">Это ядро ​​всего приложения, поэтому сквозной процесс должен быть эффективным и надежным.</span><span class="sxs-lookup"><span data-stu-id="db0b5-116">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="db0b5-117">Необходимо решить некоторые задачи:</span><span class="sxs-lookup"><span data-stu-id="db0b5-117">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="db0b5-118">**Выравнивание нагрузки.**</span><span class="sxs-lookup"><span data-stu-id="db0b5-118">**Load leveling**.</span></span> <span data-ttu-id="db0b5-119">Большое количество клиентских запросов может перегрузить систему сетевым трафиком между службами.</span><span class="sxs-lookup"><span data-stu-id="db0b5-119">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="db0b5-120">Это также может переполнять серверные зависимости, такие как службы хранения или удаленные службы.</span><span class="sxs-lookup"><span data-stu-id="db0b5-120">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="db0b5-121">Это может привести к регулированию вызывающих служб, что замедлит обратную реакцию в системе.</span><span class="sxs-lookup"><span data-stu-id="db0b5-121">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="db0b5-122">Поэтому важно загрузить уровни запросов, поступающих в систему, путем помещения их в буфер или очередь для обработки.</span><span class="sxs-lookup"><span data-stu-id="db0b5-122">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span>

- <span data-ttu-id="db0b5-123">**Гарантированная доставка.**</span><span class="sxs-lookup"><span data-stu-id="db0b5-123">**Guaranteed delivery**.</span></span> <span data-ttu-id="db0b5-124">Чтобы избежать удаления каких-либо клиентских запросов, компонент приема данных должен гарантировать по меньшей мере однократную доставку сообщений.</span><span class="sxs-lookup"><span data-stu-id="db0b5-124">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span>

- <span data-ttu-id="db0b5-125">**Обработка ошибок**.</span><span class="sxs-lookup"><span data-stu-id="db0b5-125">**Error handling**.</span></span> <span data-ttu-id="db0b5-126">Если какая-либо из служб возвращает код ошибки или происходит повторяющаяся ошибка, доставка не может быть запланирована.</span><span class="sxs-lookup"><span data-stu-id="db0b5-126">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="db0b5-127">Код ошибки может указывать на ожидаемое условие ошибки (например, учетная запись клиента заблокирована) или неожиданную ошибку сервера (HTTP 5xx).</span><span class="sxs-lookup"><span data-stu-id="db0b5-127">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="db0b5-128">Служба также может быть недоступна, в результате чего истекает время ожидания сетевого вызова.</span><span class="sxs-lookup"><span data-stu-id="db0b5-128">A service might also be unavailable, causing the network call to time out.</span></span>

<span data-ttu-id="db0b5-129">Сначала мы рассмотрим принимающую часть уравнения &mdash;, как система может принимать входящие запросы пользователей с высокой пропускной способностью.</span><span class="sxs-lookup"><span data-stu-id="db0b5-129">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="db0b5-130">Затем мы рассмотрим, как приложение доставки с помощью дронов может реализовать надежный рабочий процесс.</span><span class="sxs-lookup"><span data-stu-id="db0b5-130">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="db0b5-131">Оказывается, что архитектура подсистемы приема данных влияет на серверную часть рабочего процесса.</span><span class="sxs-lookup"><span data-stu-id="db0b5-131">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span>

## <a name="ingestion"></a><span data-ttu-id="db0b5-132">Прием</span><span class="sxs-lookup"><span data-stu-id="db0b5-132">Ingestion</span></span>

<span data-ttu-id="db0b5-133">С учетом бизнес-требований команда разработчиков определила следующие нефункциональные требования к приему данных:</span><span class="sxs-lookup"><span data-stu-id="db0b5-133">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="db0b5-134">Постоянная пропускная способность — 10 000 запросов в секунду.</span><span class="sxs-lookup"><span data-stu-id="db0b5-134">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="db0b5-135">Возможность обрабатывать пиковые нагрузки до 50 000 запросов/с без удаления клиентских запросов или превышения времени ожидания.</span><span class="sxs-lookup"><span data-stu-id="db0b5-135">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="db0b5-136">Задержка менее 500 мс на уровне 99-го процентиля.</span><span class="sxs-lookup"><span data-stu-id="db0b5-136">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="db0b5-137">Требования к обработке случайного пикового трафика представляют определенные трудности при проектировании.</span><span class="sxs-lookup"><span data-stu-id="db0b5-137">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="db0b5-138">Теоретически систему можно масштабировать для обработки максимального объема ожидаемого трафика.</span><span class="sxs-lookup"><span data-stu-id="db0b5-138">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="db0b5-139">Тем не менее, подготовка большого количества ресурсов будет очень неэффективной.</span><span class="sxs-lookup"><span data-stu-id="db0b5-139">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="db0b5-140">Большую часть времени приложение не будет нуждаться в такой емкости, поэтому основные компоненты будут простаивать, а оплата продолжит взиматься.</span><span class="sxs-lookup"><span data-stu-id="db0b5-140">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="db0b5-141">Рекомендуется поместить входящие запросы в буфер и позволить ему действовать как средство выравнивания уровня нагрузки.</span><span class="sxs-lookup"><span data-stu-id="db0b5-141">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="db0b5-142">При такой структуре служба приема должна быть способна обрабатывать максимальную скорость приема данных в течение коротких периодов времени, но серверные службы должны обрабатывать только максимальную длительную нагрузку.</span><span class="sxs-lookup"><span data-stu-id="db0b5-142">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="db0b5-143">При буферизации на стороне интерфейса серверным службам не нужно обрабатывать большие пиковые нагрузки трафика.</span><span class="sxs-lookup"><span data-stu-id="db0b5-143">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="db0b5-144">В масштабе, требуемом для приложения доставки с помощью дронов, для выравнивания нагрузки подходят [Центры событий Azure](/azure/event-hubs/).</span><span class="sxs-lookup"><span data-stu-id="db0b5-144">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="db0b5-145">Центры событий обеспечивают низкую задержку и высокую пропускную способность и являются экономически эффективным решением при высоких объемах приема данных.</span><span class="sxs-lookup"><span data-stu-id="db0b5-145">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span>

<span data-ttu-id="db0b5-146">В нашем тестировании мы использовали концентратор событий уровня "Стандартный" с 32 разделами и 100 единицами пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="db0b5-146">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="db0b5-147">Мы наблюдали прием около 32 000 событий в секунду с задержкой примерно 90 мс.</span><span class="sxs-lookup"><span data-stu-id="db0b5-147">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="db0b5-148">Сейчас ограничение по умолчанию составляет 20 единиц пропускной способности, но клиенты Azure могут запросить дополнительные единицы, отправив запрос в службу технической поддержки.</span><span class="sxs-lookup"><span data-stu-id="db0b5-148">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="db0b5-149">Дополнительные сведения см. в статье [Квоты на Центры событий](/azure/event-hubs/event-hubs-quotas).</span><span class="sxs-lookup"><span data-stu-id="db0b5-149">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="db0b5-150">Как и в случае со всеми метриками производительности, на производительность могут повлиять многие факторы, такие ​​как объем полезных данных сообщения, поэтому не рассматривайте эти числа в качестве эталона.</span><span class="sxs-lookup"><span data-stu-id="db0b5-150">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="db0b5-151">Если требуется более высокая пропускная способность, служба приема может сегментироваться между несколькими концентраторами событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-151">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="db0b5-152">Для более высокой пропускной способности [Центры событий ценовой категории "Выделенный"](/azure/event-hubs/event-hubs-dedicated-overview) предлагают развертывания с одним клиентом, которые могут принимать более 2 миллионов событий в секунду.</span><span class="sxs-lookup"><span data-stu-id="db0b5-152">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="db0b5-153">Важно понять, как Центры событий могут достичь такой высокой пропускной способности. Это влияет на то, как клиент должен потреблять сообщения от Центров событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-153">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="db0b5-154">В Центрах событий не используются *очереди*.</span><span class="sxs-lookup"><span data-stu-id="db0b5-154">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="db0b5-155">Вместо этого они используют *поток событий*.</span><span class="sxs-lookup"><span data-stu-id="db0b5-155">Rather, it implements an *event stream*.</span></span>

<span data-ttu-id="db0b5-156">Отдельный потребитель может удалить сообщение из очереди, и следующий потребитель не увидит его.</span><span class="sxs-lookup"><span data-stu-id="db0b5-156">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="db0b5-157">Таким образом, очереди позволяют использовать [шаблон конкурирующих потребителей](../patterns/competing-consumers.md) для обработки сообщений в параллельном режиме и повышения масштабируемости.</span><span class="sxs-lookup"><span data-stu-id="db0b5-157">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="db0b5-158">Для большей отказоустойчивости потребитель блокирует сообщение и снимает блокировку после его обработки.</span><span class="sxs-lookup"><span data-stu-id="db0b5-158">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="db0b5-159">Если происходит сбой потребителя, например, на узле, на котором он работает, возникает сбой, срок блокировки истекает и сообщение возвращается в очередь.</span><span class="sxs-lookup"><span data-stu-id="db0b5-159">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span>

![Схема семантики очереди](./images/queue-semantics.png)

<span data-ttu-id="db0b5-161">Центры событий, в свою очередь, используют потоковую семантику.</span><span class="sxs-lookup"><span data-stu-id="db0b5-161">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="db0b5-162">Потребители считывают поток независимо друг от друга в своем темпе.</span><span class="sxs-lookup"><span data-stu-id="db0b5-162">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="db0b5-163">Каждый потребитель отвечает за отслеживание своего текущего положения в потоке.</span><span class="sxs-lookup"><span data-stu-id="db0b5-163">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="db0b5-164">Потребитель должен записывать свою текущую позицию в постоянное хранилище с предопределенным интервалом.</span><span class="sxs-lookup"><span data-stu-id="db0b5-164">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="db0b5-165">Таким образом, если работа потребителя приостановлена (например, происходит сбой потребителя или сбой узла), то новый экземпляр может возобновить чтение потока с последней записанной позиции.</span><span class="sxs-lookup"><span data-stu-id="db0b5-165">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="db0b5-166">Этот процесс называется *установкой контрольных точек*.</span><span class="sxs-lookup"><span data-stu-id="db0b5-166">This process is called *checkpointing*.</span></span>

<span data-ttu-id="db0b5-167">Из соображений производительности потребитель обычно не создает контрольную точку после каждого сообщения.</span><span class="sxs-lookup"><span data-stu-id="db0b5-167">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="db0b5-168">Вместо этого он создает контрольные точки с фиксированным интервалом, например, после обработки *n* сообщений или каждые *n* секунд.</span><span class="sxs-lookup"><span data-stu-id="db0b5-168">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="db0b5-169">Как следствие, если происходит сбой потребителя, некоторые события могут обрабатываться дважды, потому что новый экземпляр всегда начинает с последней контрольной точки.</span><span class="sxs-lookup"><span data-stu-id="db0b5-169">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="db0b5-170">Но есть и компромисс. Частая установка контрольных точек может снизить производительность, а редкая установка повлечет повтор большего числа событий после сбоя.</span><span class="sxs-lookup"><span data-stu-id="db0b5-170">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>

![Схема семантики потока](./images/stream-semantics.png)

<span data-ttu-id="db0b5-172">Центры событий не предназначены для конкурирующих потребителей.</span><span class="sxs-lookup"><span data-stu-id="db0b5-172">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="db0b5-173">Хотя несколько потребителей могут считывать поток, каждый из них проходит поток независимо.</span><span class="sxs-lookup"><span data-stu-id="db0b5-173">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="db0b5-174">Вместо этого Центры событий используют шаблон секционированных потребителей.</span><span class="sxs-lookup"><span data-stu-id="db0b5-174">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="db0b5-175">Концентратор событий может иметь до 32 разделов.</span><span class="sxs-lookup"><span data-stu-id="db0b5-175">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="db0b5-176">Горизонтальное масштабирование достигается путем назначения отдельных потребителей для каждого раздела.</span><span class="sxs-lookup"><span data-stu-id="db0b5-176">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="db0b5-177">Что это значит для рабочего процесса доставки с помощью дрона?</span><span class="sxs-lookup"><span data-stu-id="db0b5-177">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="db0b5-178">Чтобы получить максимальную выгоду от использования Центров событий, планировщик доставки не может ожидать обработки каждого сообщения перед переходом к следующему.</span><span class="sxs-lookup"><span data-stu-id="db0b5-178">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="db0b5-179">Если это произойдет, он проведет большую часть своего времени, ожидая завершения сетевых вызовов.</span><span class="sxs-lookup"><span data-stu-id="db0b5-179">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="db0b5-180">Вместо этого он должен обрабатывать пакеты сообщений параллельно, используя асинхронные вызовы для серверных служб.</span><span class="sxs-lookup"><span data-stu-id="db0b5-180">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="db0b5-181">Как мы увидим, выбор правильной стратегии создания контрольных точек также важен.</span><span class="sxs-lookup"><span data-stu-id="db0b5-181">As we'll see, choosing the right checkpointing strategy is also important.</span></span>

## <a name="workflow"></a><span data-ttu-id="db0b5-182">Рабочий процесс</span><span class="sxs-lookup"><span data-stu-id="db0b5-182">Workflow</span></span>

<span data-ttu-id="db0b5-183">Мы рассмотрели три варианта чтения и обработки сообщений: с помощью узла обработчика событий, очередей служебной шины и библиотеки IoTHub React.</span><span class="sxs-lookup"><span data-stu-id="db0b5-183">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="db0b5-184">Мы выбрали IoTHub React, потому что она помогает начать работу с узлом обработчика событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-184">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span>

### <a name="event-processor-host"></a><span data-ttu-id="db0b5-185">Узел обработчика событий</span><span class="sxs-lookup"><span data-stu-id="db0b5-185">Event Processor Host</span></span>

<span data-ttu-id="db0b5-186">Узел обработчика событий предназначен для пакетной обработки сообщений.</span><span class="sxs-lookup"><span data-stu-id="db0b5-186">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="db0b5-187">Приложение реализует интерфейс `IEventProcessor`, а узел обработчика создает один экземпляр обработчика событий для каждого раздела в концентраторе событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-187">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="db0b5-188">Узел обработчика событий затем вызывает метод `ProcessEventsAsync` каждого обработчика событий с пакетами сообщений о событиях.</span><span class="sxs-lookup"><span data-stu-id="db0b5-188">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="db0b5-189">Приложение контролирует процесс создания контрольных точек внутри метода `ProcessEventsAsync`, а узел обработчика событий записывает контрольные точки в хранилище Azure.</span><span class="sxs-lookup"><span data-stu-id="db0b5-189">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span>

<span data-ttu-id="db0b5-190">Внутри раздела узел обработчика событий ожидает возврата `ProcessEventsAsync` перед вызовом следующего пакета.</span><span class="sxs-lookup"><span data-stu-id="db0b5-190">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="db0b5-191">Этот подход упрощает модель программирования, так как код обработки событий не должен быть реентерабельным.</span><span class="sxs-lookup"><span data-stu-id="db0b5-191">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="db0b5-192">Однако это также означает, что обработчик событий обрабатывает один пакет за раз, что приводит к ограничению скорости, с которой узел обработчика может передавать сообщения.</span><span class="sxs-lookup"><span data-stu-id="db0b5-192">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE]
> <span data-ttu-id="db0b5-193">Фактически узел обработчика не *ожидает* снятия блокировки потока.</span><span class="sxs-lookup"><span data-stu-id="db0b5-193">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="db0b5-194">Метод `ProcessEventsAsync` является асинхронным, поэтому узел обработчика может выполнять другую работу параллельно с выполнением метода.</span><span class="sxs-lookup"><span data-stu-id="db0b5-194">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="db0b5-195">Но пока метод не вернется, он не доставит другой пакет сообщений для этого раздела.</span><span class="sxs-lookup"><span data-stu-id="db0b5-195">But it won't deliver another batch of messages for that partition until the method returns.</span></span>

<span data-ttu-id="db0b5-196">В приложении дронов пакеты сообщений могут обрабатываться параллельно.</span><span class="sxs-lookup"><span data-stu-id="db0b5-196">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="db0b5-197">Но ожидание завершения обработки всего пакета по-прежнему может стать узким местом.</span><span class="sxs-lookup"><span data-stu-id="db0b5-197">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="db0b5-198">Обработка не может быть быстрее самого медленного сообщения в пакете.</span><span class="sxs-lookup"><span data-stu-id="db0b5-198">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="db0b5-199">Любое изменение времени отклика может создать длинный "хвост", когда несколько медленных ответов будут отягощать всю систему.</span><span class="sxs-lookup"><span data-stu-id="db0b5-199">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="db0b5-200">Наши тесты производительности показали, что при таком подходе мы не достигли целевой пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="db0b5-200">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="db0b5-201">Это *не* означает, что вам следует избегать использования узла обработчика событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-201">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="db0b5-202">Для достижения высокой пропускной способности избегайте выполнения длительных задач внутри метода `ProcesssEventsAsync`.</span><span class="sxs-lookup"><span data-stu-id="db0b5-202">But for high throughput, avoid doing any long-running tasks inside the `ProcesssEventsAsync` method.</span></span> <span data-ttu-id="db0b5-203">Быстро обрабатывайте каждый пакет.</span><span class="sxs-lookup"><span data-stu-id="db0b5-203">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="db0b5-204">Библиотека IotHub React</span><span class="sxs-lookup"><span data-stu-id="db0b5-204">IotHub React</span></span>

<span data-ttu-id="db0b5-205">[IotHub React](https://github.com/Azure/toketi-iothubreact) — это библиотека Akka Streams для чтения событий из концентратора событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-205">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="db0b5-206">Akka Streams — это платформа программирования на основе потоков, которая реализует спецификацию [реактивных потоков](https://www.reactive-streams.org/).</span><span class="sxs-lookup"><span data-stu-id="db0b5-206">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](https://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="db0b5-207">Она позволяет создавать эффективные потоковые конвейеры, где все потоковые операции выполняются асинхронно, а конвейер корректно обрабатывает обратную реакцию.</span><span class="sxs-lookup"><span data-stu-id="db0b5-207">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="db0b5-208">Замедленная обратная реакция возникает, когда источник событий генерирует события с более высокой скоростью, чем подчиненные потребители могут получить их. Это в точности соответствует ситуации, когда система доставки с помощью дронов создает пик трафика.</span><span class="sxs-lookup"><span data-stu-id="db0b5-208">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="db0b5-209">Если серверные службы работают медленнее, IoTHub React замедлит работу.</span><span class="sxs-lookup"><span data-stu-id="db0b5-209">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="db0b5-210">Если емкость увеличивается, IoTHub React отправляет больше сообщений по конвейеру.</span><span class="sxs-lookup"><span data-stu-id="db0b5-210">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="db0b5-211">Akka Streams также является очень естественной моделью программирования для потоковой передачи событий из Центров событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-211">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="db0b5-212">Вместо циклического перебора пакетов событий нужно определить набор операций, которые будут применяться к каждому событию, а обработку потоковой передачи выполняет Akka Streams.</span><span class="sxs-lookup"><span data-stu-id="db0b5-212">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="db0b5-213">Akka Streams определяет конвейер потоковой передачи, включающий в себя *источники*, *потоки* и *приемники*.</span><span class="sxs-lookup"><span data-stu-id="db0b5-213">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="db0b5-214">Источник генерирует поток вывода, поток обрабатывает входной поток и создает поток вывода, а приемник потребляет поток без каких-либо выходных данных.</span><span class="sxs-lookup"><span data-stu-id="db0b5-214">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="db0b5-215">Ниже приведен код в службе планировщика, который настраивает конвейер Akka Streams:</span><span class="sxs-lookup"><span data-stu-id="db0b5-215">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="db0b5-216">Этот код настраивает Центры событий в качестве источников.</span><span class="sxs-lookup"><span data-stu-id="db0b5-216">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="db0b5-217">Оператор `map` десериализует каждое сообщение о событии в класс Java, который представляет запрос на доставку.</span><span class="sxs-lookup"><span data-stu-id="db0b5-217">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="db0b5-218">Оператор `filter` удаляет любые объекты `null` из потока. Это предотвращает случаи, когда сообщение нельзя десериализовать.</span><span class="sxs-lookup"><span data-stu-id="db0b5-218">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="db0b5-219">Оператор `via` присоединяет источник к потоку, обрабатывающему каждый запрос на доставку.</span><span class="sxs-lookup"><span data-stu-id="db0b5-219">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="db0b5-220">Метод `to` соединяет поток с приемником контрольной точки, который встроен в IoTHub React.</span><span class="sxs-lookup"><span data-stu-id="db0b5-220">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="db0b5-221">IoTHub React использует другую стратегию установки контрольных точек, нежели процессор узла событий.</span><span class="sxs-lookup"><span data-stu-id="db0b5-221">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="db0b5-222">Контрольные точки записываются приемником контрольных точек, что является завершающим этапом в конвейере.</span><span class="sxs-lookup"><span data-stu-id="db0b5-222">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="db0b5-223">Структура Akka Streams позволяет конвейеру продолжать передавать данные, а приемник записывает контрольную точку.</span><span class="sxs-lookup"><span data-stu-id="db0b5-223">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="db0b5-224">Это означает, что вышестоящим стадиям обработки данных не нужно ждать создания контрольной точки.</span><span class="sxs-lookup"><span data-stu-id="db0b5-224">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="db0b5-225">Можно настроить так, чтобы контрольная точка создавалась после истечения времени ожидания или обработки определенного количества сообщений.</span><span class="sxs-lookup"><span data-stu-id="db0b5-225">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="db0b5-226">Метод `deliveryProcessor` создает поток Akka Streams:</span><span class="sxs-lookup"><span data-stu-id="db0b5-226">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(),
                        delivery.getMessageFromDevice().properties());

        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }

        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="db0b5-227">Поток вызывает статический метод `processDeliveryRequestAsync`, который выполняет фактическую обработку каждого сообщения.</span><span class="sxs-lookup"><span data-stu-id="db0b5-227">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="db0b5-228">Масштабирование с IoTHub React</span><span class="sxs-lookup"><span data-stu-id="db0b5-228">Scaling with IoTHub React</span></span>

<span data-ttu-id="db0b5-229">Служба планировщика разработана таким образом, что каждый экземпляр контейнера считывает данные из одного раздела.</span><span class="sxs-lookup"><span data-stu-id="db0b5-229">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="db0b5-230">Например, если концентратор событий содержит 32 раздела, служба планировщика развертывается с 32 репликами.</span><span class="sxs-lookup"><span data-stu-id="db0b5-230">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="db0b5-231">Это обеспечивает большую гибкость с точки зрения горизонтального масштабирования.</span><span class="sxs-lookup"><span data-stu-id="db0b5-231">This allows for a lot of flexibility in terms of horizontal scaling.</span></span>

<span data-ttu-id="db0b5-232">В зависимости от размера кластера на узле кластера может выполняться несколько модулей pod службы планировщика.</span><span class="sxs-lookup"><span data-stu-id="db0b5-232">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="db0b5-233">Но если службе планировщика требуется больше ресурсов, кластер можно развернуть, чтобы распределить модули pod между большим количеством узлов.</span><span class="sxs-lookup"><span data-stu-id="db0b5-233">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="db0b5-234">Наши тесты производительности показали, что служба планировщика связана с памятью и потоками, поэтому производительность сильно зависит от размера виртуальной машины и количества модулей pod на каждом узле.</span><span class="sxs-lookup"><span data-stu-id="db0b5-234">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="db0b5-235">Каждый экземпляр должен знать, из какого раздела концентратора событий следует выполнять чтение.</span><span class="sxs-lookup"><span data-stu-id="db0b5-235">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="db0b5-236">Чтобы настроить номер раздела, воспользуемся типом ресурса [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) в Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="db0b5-236">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="db0b5-237">Модули pod в StatefulSet имеют постоянный идентификатор, который содержит числовой индекс.</span><span class="sxs-lookup"><span data-stu-id="db0b5-237">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="db0b5-238">В частности, имя модуля — `<statefulset name>-<index>`, и это значение доступно контейнеру через [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/) Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="db0b5-238">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="db0b5-239">Во время выполнения служба планировщика считывает имя модуля pod и использует его индекс в качестве идентификатора раздела.</span><span class="sxs-lookup"><span data-stu-id="db0b5-239">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="db0b5-240">Если вам нужно еще больше масштабировать службу планировщика, вы можете назначить несколько модулей pod для каждого раздела концентратора событий, чтобы несколько модулей считывали каждый раздел.</span><span class="sxs-lookup"><span data-stu-id="db0b5-240">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="db0b5-241">Однако в этом случае каждый экземпляр будет считывать все события в назначенном разделе.</span><span class="sxs-lookup"><span data-stu-id="db0b5-241">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="db0b5-242">Чтобы избежать дублирования обработки, нужно использовать алгоритм хэширования, чтобы каждый экземпляр пропускал часть сообщений.</span><span class="sxs-lookup"><span data-stu-id="db0b5-242">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="db0b5-243">Таким образом, несколько модулей чтения могут получать поток, но каждое сообщение обрабатывается только одним экземпляром.</span><span class="sxs-lookup"><span data-stu-id="db0b5-243">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span>

![Схема хэширования концентратора событий](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="db0b5-245">Очереди служебной шины</span><span class="sxs-lookup"><span data-stu-id="db0b5-245">Service Bus queues</span></span>

<span data-ttu-id="db0b5-246">Третий вариант, который мы рассмотрели, заключался в копировании сообщений из Центров событий в очередь служебной шины, а затем настройке службы планировщика для чтения сообщений через служебную шину.</span><span class="sxs-lookup"><span data-stu-id="db0b5-246">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="db0b5-247">Может показаться странным записывать входящие запросы в Центры событий только для того, чтобы скопировать их в служебную шину.</span><span class="sxs-lookup"><span data-stu-id="db0b5-247">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="db0b5-248">Но идея заключалась в том, чтобы использовать различные преимущества каждой службы — Центры событий для выравнивания пиков интенсивного трафика, а семантику очереди в служебной шине для обработки рабочей нагрузки с использованием шаблона конкурирующих потребителей.</span><span class="sxs-lookup"><span data-stu-id="db0b5-248">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="db0b5-249">Помните, что приоритет устойчивой пропускной способности меньше чем ожидаемой максимальной нагрузки, поэтому для обработки очереди служебной шины не требуется такая же скорость, как для приема сообщений.</span><span class="sxs-lookup"><span data-stu-id="db0b5-249">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>

<span data-ttu-id="db0b5-250">При таком подходе в результате нашей экспериментальной концепции удалось достичь показателя — 4000 операций в секунду.</span><span class="sxs-lookup"><span data-stu-id="db0b5-250">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="db0b5-251">Для тестов использовались макеты сервисных служб, которые не выполняли никакой реальной работы, а просто добавляли фиксированную задержку для каждой службы.</span><span class="sxs-lookup"><span data-stu-id="db0b5-251">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="db0b5-252">Обратите внимание, что наши показатели производительности намного меньше теоретических максимальных значений для служебной шины.</span><span class="sxs-lookup"><span data-stu-id="db0b5-252">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="db0b5-253">Возможные причины расхождения:</span><span class="sxs-lookup"><span data-stu-id="db0b5-253">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="db0b5-254">Отсутствие оптимальных значений для различных параметров клиента, таких как ограничение пула подключений, степень параллелизации, количество предварительной выборки и размер пакета.</span><span class="sxs-lookup"><span data-stu-id="db0b5-254">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="db0b5-255">Узкие места сетевых операций ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="db0b5-255">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="db0b5-256">Использование режима [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) вместо [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), что необходимо для обеспечения по меньшей мере однократной доставки сообщений.</span><span class="sxs-lookup"><span data-stu-id="db0b5-256">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="db0b5-257">Последующие тесты производительности помогли бы обнаружить первопричину и решить эти проблемы.</span><span class="sxs-lookup"><span data-stu-id="db0b5-257">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="db0b5-258">Тем не менее, библиотека IotHub React помогла нам достичь целевых показателей, поэтому мы выбрали этот вариант.</span><span class="sxs-lookup"><span data-stu-id="db0b5-258">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="db0b5-259">С другой стороны, служебная шина также приемлема для этого сценария.</span><span class="sxs-lookup"><span data-stu-id="db0b5-259">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="db0b5-260">Обработка сбоев</span><span class="sxs-lookup"><span data-stu-id="db0b5-260">Handling failures</span></span>

<span data-ttu-id="db0b5-261">Существует три общих класса сбоя, которые следует учитывать.</span><span class="sxs-lookup"><span data-stu-id="db0b5-261">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="db0b5-262">В подчиненной службе может возникать повторяющаяся ошибка. Это может быть любой сбой, который не устранится сам по себе.</span><span class="sxs-lookup"><span data-stu-id="db0b5-262">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="db0b5-263">Повторяющиеся ошибки включают в себя обычные условия ошибки, такие как недопустимые входные данные метода.</span><span class="sxs-lookup"><span data-stu-id="db0b5-263">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="db0b5-264">К ним также относятся необработанные исключения в коде приложения или сбой процесса.</span><span class="sxs-lookup"><span data-stu-id="db0b5-264">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="db0b5-265">При возникновении такой ошибки вся бизнес-транзакция должна быть отмечена как сбой.</span><span class="sxs-lookup"><span data-stu-id="db0b5-265">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="db0b5-266">Может потребоваться отменить другие шаги в той же транзакции, которые уже выполнены.</span><span class="sxs-lookup"><span data-stu-id="db0b5-266">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="db0b5-267">(См. раздел "Компенсирующие транзакции" ниже.)</span><span class="sxs-lookup"><span data-stu-id="db0b5-267">(See Compensating Transactions, below.)</span></span>

2. <span data-ttu-id="db0b5-268">В подчиненной службе может возникнуть временная ошибка, например истечение времени ожидания сети.</span><span class="sxs-lookup"><span data-stu-id="db0b5-268">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="db0b5-269">Эти ошибки часто можно решить, просто повторив вызов.</span><span class="sxs-lookup"><span data-stu-id="db0b5-269">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="db0b5-270">Если операция по-прежнему завершается сбоем после определенного количества попыток, такая ошибка считается повторяющейся.</span><span class="sxs-lookup"><span data-stu-id="db0b5-270">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span>

3. <span data-ttu-id="db0b5-271">В самой службе планировщика может возникнуть ошибка (например, из-за сбоя узла).</span><span class="sxs-lookup"><span data-stu-id="db0b5-271">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="db0b5-272">В этом случае Kubernetes предоставит новый экземпляр службы.</span><span class="sxs-lookup"><span data-stu-id="db0b5-272">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="db0b5-273">Однако любые транзакции, которые уже начали выполняться, должны быть возобновлены.</span><span class="sxs-lookup"><span data-stu-id="db0b5-273">However, any transactions that were already in progress must be resumed.</span></span>

## <a name="compensating-transactions"></a><span data-ttu-id="db0b5-274">Компенсирующие транзакции</span><span class="sxs-lookup"><span data-stu-id="db0b5-274">Compensating transactions</span></span>

<span data-ttu-id="db0b5-275">Если происходит повторяющаяся ошибка, текущая транзакция может находиться в состоянии *частичного сбоя*, когда один или несколько шагов уже завершены успешно.</span><span class="sxs-lookup"><span data-stu-id="db0b5-275">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="db0b5-276">Например, если служба дронов уже запланировала доставку с помощью дрона, она должна быть отменена.</span><span class="sxs-lookup"><span data-stu-id="db0b5-276">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="db0b5-277">В этом случае приложение должно отменить успешно выполненные шаги с помощью [компенсирующей транзакции](../patterns/compensating-transaction.md).</span><span class="sxs-lookup"><span data-stu-id="db0b5-277">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="db0b5-278">В некоторых случаях это нужно выполнить во внешней системе или даже с использованием операции в ручном режиме.</span><span class="sxs-lookup"><span data-stu-id="db0b5-278">In some cases, this must be done by an external system or even by a manual process.</span></span>

<span data-ttu-id="db0b5-279">Если логика компенсирующих транзакций сложна, можно создать отдельную службу, которая отвечает за этот процесс.</span><span class="sxs-lookup"><span data-stu-id="db0b5-279">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="db0b5-280">В приложении доставки с помощью дронов служба планировщика ставит неудачные операции в выделенную очередь.</span><span class="sxs-lookup"><span data-stu-id="db0b5-280">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="db0b5-281">Отдельная микрослужба, называемая контролером, выполняет чтение из этой очереди и вызывает API отмены для служб, которые необходимо компенсировать.</span><span class="sxs-lookup"><span data-stu-id="db0b5-281">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="db0b5-282">Это разновидность [шаблона "планировщик, агент, контролер"][scheduler-agent-supervisor].</span><span class="sxs-lookup"><span data-stu-id="db0b5-282">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="db0b5-283">Служба "Контролер" может выполнять и другие действия, такие как уведомление пользователя с помощью текстового сообщения или электронной почты или отправка предупреждения на панель управления операций.</span><span class="sxs-lookup"><span data-stu-id="db0b5-283">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span>

![Схема микрослужбы "Контролер"](./images/supervisor.png)

## <a name="idempotent-vs-non-idempotent-operations"></a><span data-ttu-id="db0b5-285">Идемпотентные и неидемпотентные операции</span><span class="sxs-lookup"><span data-stu-id="db0b5-285">Idempotent vs non-idempotent operations</span></span>

<span data-ttu-id="db0b5-286">Чтобы избежать потери каких-либо запросов, служба планировщика должна гарантировать, что все сообщения обрабатываются хотя бы один раз.</span><span class="sxs-lookup"><span data-stu-id="db0b5-286">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="db0b5-287">Центры событий могут обеспечить по крайней мере однократную доставку, если клиент создает контрольные точки надлежащим образом.</span><span class="sxs-lookup"><span data-stu-id="db0b5-287">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="db0b5-288">Если служба планировщика завершается сбоем, она может остановиться в процессе обработки одного или нескольких клиентских запросов.</span><span class="sxs-lookup"><span data-stu-id="db0b5-288">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="db0b5-289">Эти сообщения повторно обработает другой экземпляр планировщика.</span><span class="sxs-lookup"><span data-stu-id="db0b5-289">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="db0b5-290">Что произойдет, если запрос будет обработан дважды?</span><span class="sxs-lookup"><span data-stu-id="db0b5-290">What happens if a request is processed twice?</span></span> <span data-ttu-id="db0b5-291">Важно предотвратить дублирование какой-либо работы.</span><span class="sxs-lookup"><span data-stu-id="db0b5-291">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="db0b5-292">В конце концов, мы не хотим, чтобы система отправляла два дрона для одного и того же груза.</span><span class="sxs-lookup"><span data-stu-id="db0b5-292">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="db0b5-293">Один из подходов состоит в том, чтобы сделать все операции идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="db0b5-293">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="db0b5-294">Операция является идемпотентной, если ее можно вызвать несколько раз, не создавая дополнительных побочных эффектов после первого вызова.</span><span class="sxs-lookup"><span data-stu-id="db0b5-294">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="db0b5-295">Другими словами, клиент может вызывать операцию один, два или много раз, и результат будет таким же.</span><span class="sxs-lookup"><span data-stu-id="db0b5-295">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="db0b5-296">По сути, служба должна игнорировать повторяющиеся вызовы.</span><span class="sxs-lookup"><span data-stu-id="db0b5-296">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="db0b5-297">Чтобы метод с побочными эффектами был идемпотентным, служба должна иметь возможность обнаруживать повторяющиеся вызовы.</span><span class="sxs-lookup"><span data-stu-id="db0b5-297">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="db0b5-298">Например, можно настроить так, чтобы вызывающий объект присваивал идентификатор, вместо того, чтобы служба генерировала новый идентификатор.</span><span class="sxs-lookup"><span data-stu-id="db0b5-298">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="db0b5-299">Затем служба может проверить наличие дубликатов идентификаторов.</span><span class="sxs-lookup"><span data-stu-id="db0b5-299">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="db0b5-300">Согласно спецификации HTTP методы GET, PUT и DELETE должны быть идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="db0b5-300">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="db0b5-301">Методы POST не обязательно должны быть идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="db0b5-301">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="db0b5-302">Если метод POST создает новый ресурс, обычно это не гарантирует, что эта операция является идемпотентной.</span><span class="sxs-lookup"><span data-stu-id="db0b5-302">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span>

<span data-ttu-id="db0b5-303">Не всегда просто написать идемпотентный метод.</span><span class="sxs-lookup"><span data-stu-id="db0b5-303">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="db0b5-304">Другой вариант — планировщик должен отслеживать ход каждой транзакции в надежном хранилище.</span><span class="sxs-lookup"><span data-stu-id="db0b5-304">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="db0b5-305">Всякий раз, когда он обрабатывает сообщение, он будет искать состояние в надежном хранилище.</span><span class="sxs-lookup"><span data-stu-id="db0b5-305">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="db0b5-306">После каждого шага он записывает результат в хранилище.</span><span class="sxs-lookup"><span data-stu-id="db0b5-306">After each step, it would write the result to the store.</span></span> <span data-ttu-id="db0b5-307">Такой подход может оказать влияние на производительность.</span><span class="sxs-lookup"><span data-stu-id="db0b5-307">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="db0b5-308">Пример: Идемпотентные операции</span><span class="sxs-lookup"><span data-stu-id="db0b5-308">Example: Idempotent operations</span></span>

<span data-ttu-id="db0b5-309">Спецификация HTTP указывает, что методы PUT должны быть идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="db0b5-309">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="db0b5-310">Спецификация определяет идемпотентность следующим образом.</span><span class="sxs-lookup"><span data-stu-id="db0b5-310">The specification defines idempotent this way:</span></span>

> <span data-ttu-id="db0b5-311">Метод запроса считается идемпотентным, если предполагаемый эффект на сервере с несколькими идентичными запросами с этим методом совпадает с эффектом для одного такого запроса.</span><span class="sxs-lookup"><span data-stu-id="db0b5-311">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the same as the effect for a single such request.</span></span> <span data-ttu-id="db0b5-312">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span><span class="sxs-lookup"><span data-stu-id="db0b5-312">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="db0b5-313">Важно понимать разницу между семантикой PUT и POST при создании новой сущности.</span><span class="sxs-lookup"><span data-stu-id="db0b5-313">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="db0b5-314">В обоих случаях клиент отправляет представление сущности в тексте запроса.</span><span class="sxs-lookup"><span data-stu-id="db0b5-314">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="db0b5-315">Значения URI при этом разные.</span><span class="sxs-lookup"><span data-stu-id="db0b5-315">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="db0b5-316">Для метода POST URI представляет родительский ресурс новой сущности, такой как коллекция.</span><span class="sxs-lookup"><span data-stu-id="db0b5-316">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="db0b5-317">Например, чтобы создать новую доставку, можно использовать URI `/api/deliveries`.</span><span class="sxs-lookup"><span data-stu-id="db0b5-317">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="db0b5-318">Сервер создает сущность и назначает ей новый URI, например `/api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="db0b5-318">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="db0b5-319">Этот URI возвращается в заголовке Location ответа.</span><span class="sxs-lookup"><span data-stu-id="db0b5-319">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="db0b5-320">Каждый раз, когда клиент отправляет запрос, сервер создает новый объект с новым URI.</span><span class="sxs-lookup"><span data-stu-id="db0b5-320">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="db0b5-321">Для метода PUT URI определяет сущность.</span><span class="sxs-lookup"><span data-stu-id="db0b5-321">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="db0b5-322">Если сущность с таким URI уже существует, сервер заменяет существующую сущность версией из запроса.</span><span class="sxs-lookup"><span data-stu-id="db0b5-322">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="db0b5-323">Если сущности с таким URI не существует, сервер создает ее.</span><span class="sxs-lookup"><span data-stu-id="db0b5-323">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="db0b5-324">Предположим, клиент отправляет запрос PUT к `api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="db0b5-324">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="db0b5-325">Предполагая, что доставки с этим URI не существует, сервер создает новую.</span><span class="sxs-lookup"><span data-stu-id="db0b5-325">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="db0b5-326">Теперь если клиент снова отправляет тот же запрос, сервер заменяет существующую сущность.</span><span class="sxs-lookup"><span data-stu-id="db0b5-326">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="db0b5-327">Ниже приведена реализация метода PUT в службе доставки.</span><span class="sxs-lookup"><span data-stu-id="db0b5-327">Here is the Delivery service's implementation of the PUT method.</span></span>

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="db0b5-328">Ожидается, что большинство запросов создадут новые сущности, поэтому метод вызывает `CreateAsync` в объекте репозитория, а затем обрабатывает все исключения дубликатов ресурсов, обновляя ресурс.</span><span class="sxs-lookup"><span data-stu-id="db0b5-328">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="db0b5-329">Шлюзы API</span><span class="sxs-lookup"><span data-stu-id="db0b5-329">API gateways</span></span>](./gateway.md)

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md