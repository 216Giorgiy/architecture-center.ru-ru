---
title: Прием данных и рабочий процесс в микрослужбах
description: Прием данных и рабочий процесс в микрослужбах
author: MikeWasson
ms.date: 10/23/2018
ms.topic: guide
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: microservices
ms.openlocfilehash: a36d2b4c7bfd2b26d5e1de44ddd8005fbce4bdd2
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/17/2019
ms.locfileid: "59640861"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="d1b07-103">Проектирование микрослужб. Прием данных и рабочий процесс</span><span class="sxs-lookup"><span data-stu-id="d1b07-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="d1b07-104">У микрослужб часто есть рабочий процесс, который охватывает несколько служб для одной транзакции.</span><span class="sxs-lookup"><span data-stu-id="d1b07-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="d1b07-105">Рабочий процесс должен быть надежным. Он не должен терять транзакции или оставлять их в частично завершенном состоянии.</span><span class="sxs-lookup"><span data-stu-id="d1b07-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="d1b07-106">Также важно управлять скоростью приема входящих запросов.</span><span class="sxs-lookup"><span data-stu-id="d1b07-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="d1b07-107">Когда большое количество небольших служб обмениваются данными друг с другом, большой пакет входящих запросов может вызвать перегрузку взаимодействия служб.</span><span class="sxs-lookup"><span data-stu-id="d1b07-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span>

![Схема рабочего процесса приема](./images/ingestion-workflow.png)

> [!NOTE]
> <span data-ttu-id="d1b07-109">Эта статья основана на вызове эталонную реализацию микрослужб [приложения доставки с помощью Дронов](./design/index.md).</span><span class="sxs-lookup"><span data-stu-id="d1b07-109">This article is based on a microservices reference implementation called the [Drone Delivery application](./design/index.md).</span></span>

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="d1b07-110">Рабочий процесс доставки с помощью дронов</span><span class="sxs-lookup"><span data-stu-id="d1b07-110">The drone delivery workflow</span></span>

<span data-ttu-id="d1b07-111">Чтобы запланировать доставку в приложении доставки с помощью дронов, необходимо выполнить следующие операции:</span><span class="sxs-lookup"><span data-stu-id="d1b07-111">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="d1b07-112">Проверьте состояние учетной записи пользователя (служба учетных записей).</span><span class="sxs-lookup"><span data-stu-id="d1b07-112">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="d1b07-113">Создайте сущность посылки (служба посылок).</span><span class="sxs-lookup"><span data-stu-id="d1b07-113">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="d1b07-114">Проверьте, требуется ли для этой доставки транспортировка сторонними лицами на основе местоположения для выемки и доставки (сторонняя служба транспортировки).</span><span class="sxs-lookup"><span data-stu-id="d1b07-114">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="d1b07-115">Запланируйте выемку с помощью дрона (служба дронов).</span><span class="sxs-lookup"><span data-stu-id="d1b07-115">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="d1b07-116">Создайте сущность доставки (служба доставки).</span><span class="sxs-lookup"><span data-stu-id="d1b07-116">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="d1b07-117">Это ядро ​​всего приложения, поэтому сквозной процесс должен быть эффективным и надежным.</span><span class="sxs-lookup"><span data-stu-id="d1b07-117">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="d1b07-118">Необходимо решить некоторые задачи:</span><span class="sxs-lookup"><span data-stu-id="d1b07-118">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="d1b07-119">**Выравнивание нагрузки.**</span><span class="sxs-lookup"><span data-stu-id="d1b07-119">**Load leveling**.</span></span> <span data-ttu-id="d1b07-120">Большое количество клиентских запросов может перегрузить систему сетевым трафиком между службами.</span><span class="sxs-lookup"><span data-stu-id="d1b07-120">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="d1b07-121">Это также может переполнять серверные зависимости, такие как службы хранения или удаленные службы.</span><span class="sxs-lookup"><span data-stu-id="d1b07-121">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="d1b07-122">Это может привести к регулированию вызывающих служб, что замедлит обратную реакцию в системе.</span><span class="sxs-lookup"><span data-stu-id="d1b07-122">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="d1b07-123">Поэтому важно загрузить уровни запросов, поступающих в систему, путем помещения их в буфер или очередь для обработки.</span><span class="sxs-lookup"><span data-stu-id="d1b07-123">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span>

- <span data-ttu-id="d1b07-124">**Гарантированная доставка.**</span><span class="sxs-lookup"><span data-stu-id="d1b07-124">**Guaranteed delivery**.</span></span> <span data-ttu-id="d1b07-125">Чтобы избежать удаления каких-либо клиентских запросов, компонент приема данных должен гарантировать по меньшей мере однократную доставку сообщений.</span><span class="sxs-lookup"><span data-stu-id="d1b07-125">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span>

- <span data-ttu-id="d1b07-126">**Обработка ошибок**.</span><span class="sxs-lookup"><span data-stu-id="d1b07-126">**Error handling**.</span></span> <span data-ttu-id="d1b07-127">Если какая-либо из служб возвращает код ошибки или происходит повторяющаяся ошибка, доставка не может быть запланирована.</span><span class="sxs-lookup"><span data-stu-id="d1b07-127">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="d1b07-128">Код ошибки может указывать на ожидаемое условие ошибки (например, учетная запись клиента заблокирована) или неожиданную ошибку сервера (HTTP 5xx).</span><span class="sxs-lookup"><span data-stu-id="d1b07-128">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="d1b07-129">Служба также может быть недоступна, в результате чего истекает время ожидания сетевого вызова.</span><span class="sxs-lookup"><span data-stu-id="d1b07-129">A service might also be unavailable, causing the network call to time out.</span></span>

<span data-ttu-id="d1b07-130">Сначала мы рассмотрим принимающую часть уравнения &mdash;, как система может принимать входящие запросы пользователей с высокой пропускной способностью.</span><span class="sxs-lookup"><span data-stu-id="d1b07-130">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="d1b07-131">Затем мы рассмотрим, как приложение доставки с помощью дронов может реализовать надежный рабочий процесс.</span><span class="sxs-lookup"><span data-stu-id="d1b07-131">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="d1b07-132">Оказывается, что архитектура подсистемы приема данных влияет на серверную часть рабочего процесса.</span><span class="sxs-lookup"><span data-stu-id="d1b07-132">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span>

## <a name="ingestion"></a><span data-ttu-id="d1b07-133">Прием</span><span class="sxs-lookup"><span data-stu-id="d1b07-133">Ingestion</span></span>

<span data-ttu-id="d1b07-134">С учетом бизнес-требований команда разработчиков определила следующие нефункциональные требования к приему данных:</span><span class="sxs-lookup"><span data-stu-id="d1b07-134">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="d1b07-135">Постоянная пропускная способность — 10 000 запросов в секунду.</span><span class="sxs-lookup"><span data-stu-id="d1b07-135">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="d1b07-136">Возможность обрабатывать пиковые нагрузки до 50 000 запросов/с без удаления клиентских запросов или превышения времени ожидания.</span><span class="sxs-lookup"><span data-stu-id="d1b07-136">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="d1b07-137">Задержка менее 500 мс на уровне 99-го процентиля.</span><span class="sxs-lookup"><span data-stu-id="d1b07-137">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="d1b07-138">Требования к обработке случайного пикового трафика представляют определенные трудности при проектировании.</span><span class="sxs-lookup"><span data-stu-id="d1b07-138">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="d1b07-139">Теоретически систему можно масштабировать для обработки максимального объема ожидаемого трафика.</span><span class="sxs-lookup"><span data-stu-id="d1b07-139">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="d1b07-140">Тем не менее, подготовка большого количества ресурсов будет очень неэффективной.</span><span class="sxs-lookup"><span data-stu-id="d1b07-140">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="d1b07-141">Большую часть времени приложение не будет нуждаться в такой емкости, поэтому основные компоненты будут простаивать, а оплата продолжит взиматься.</span><span class="sxs-lookup"><span data-stu-id="d1b07-141">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="d1b07-142">Рекомендуется поместить входящие запросы в буфер и позволить ему действовать как средство выравнивания уровня нагрузки.</span><span class="sxs-lookup"><span data-stu-id="d1b07-142">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="d1b07-143">При такой структуре служба приема должна быть способна обрабатывать максимальную скорость приема данных в течение коротких периодов времени, но серверные службы должны обрабатывать только максимальную длительную нагрузку.</span><span class="sxs-lookup"><span data-stu-id="d1b07-143">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="d1b07-144">При буферизации на стороне интерфейса серверным службам не нужно обрабатывать большие пиковые нагрузки трафика.</span><span class="sxs-lookup"><span data-stu-id="d1b07-144">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="d1b07-145">В масштабе, требуемом для приложения доставки с помощью дронов, для выравнивания нагрузки подходят [Центры событий Azure](/azure/event-hubs/).</span><span class="sxs-lookup"><span data-stu-id="d1b07-145">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="d1b07-146">Центры событий обеспечивают низкую задержку и высокую пропускную способность и являются экономически эффективным решением при высоких объемах приема данных.</span><span class="sxs-lookup"><span data-stu-id="d1b07-146">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span>

<span data-ttu-id="d1b07-147">В нашем тестировании мы использовали концентратор событий уровня "Стандартный" с 32 разделами и 100 единицами пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="d1b07-147">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="d1b07-148">Мы наблюдали прием около 32 000 событий в секунду с задержкой примерно 90 мс.</span><span class="sxs-lookup"><span data-stu-id="d1b07-148">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="d1b07-149">Сейчас ограничение по умолчанию составляет 20 единиц пропускной способности, но клиенты Azure могут запросить дополнительные единицы, отправив запрос в службу технической поддержки.</span><span class="sxs-lookup"><span data-stu-id="d1b07-149">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="d1b07-150">Дополнительные сведения см. в статье [Квоты на Центры событий](/azure/event-hubs/event-hubs-quotas).</span><span class="sxs-lookup"><span data-stu-id="d1b07-150">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="d1b07-151">Как и в случае со всеми метриками производительности, на производительность могут повлиять многие факторы, такие ​​как объем полезных данных сообщения, поэтому не рассматривайте эти числа в качестве эталона.</span><span class="sxs-lookup"><span data-stu-id="d1b07-151">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="d1b07-152">Если требуется более высокая пропускная способность, служба приема может сегментироваться между несколькими концентраторами событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-152">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="d1b07-153">Для более высокой пропускной способности [Центры событий ценовой категории "Выделенный"](/azure/event-hubs/event-hubs-dedicated-overview) предлагают развертывания с одним клиентом, которые могут принимать более 2 миллионов событий в секунду.</span><span class="sxs-lookup"><span data-stu-id="d1b07-153">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="d1b07-154">Важно понять, как Центры событий могут достичь такой высокой пропускной способности. Это влияет на то, как клиент должен потреблять сообщения от Центров событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-154">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="d1b07-155">В Центрах событий не используются *очереди*.</span><span class="sxs-lookup"><span data-stu-id="d1b07-155">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="d1b07-156">Вместо этого они используют *поток событий*.</span><span class="sxs-lookup"><span data-stu-id="d1b07-156">Rather, it implements an *event stream*.</span></span>

<span data-ttu-id="d1b07-157">Отдельный потребитель может удалить сообщение из очереди, и следующий потребитель не увидит его.</span><span class="sxs-lookup"><span data-stu-id="d1b07-157">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="d1b07-158">Таким образом, очереди позволяют использовать [шаблон конкурирующих потребителей](../patterns/competing-consumers.md) для обработки сообщений в параллельном режиме и повышения масштабируемости.</span><span class="sxs-lookup"><span data-stu-id="d1b07-158">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="d1b07-159">Для большей отказоустойчивости потребитель блокирует сообщение и снимает блокировку после его обработки.</span><span class="sxs-lookup"><span data-stu-id="d1b07-159">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="d1b07-160">Если происходит сбой потребителя, например, на узле, на котором он работает, возникает сбой, срок блокировки истекает и сообщение возвращается в очередь.</span><span class="sxs-lookup"><span data-stu-id="d1b07-160">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span>

![Схема семантики очереди](./images/queue-semantics.png)

<span data-ttu-id="d1b07-162">Центры событий, в свою очередь, используют потоковую семантику.</span><span class="sxs-lookup"><span data-stu-id="d1b07-162">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="d1b07-163">Потребители считывают поток независимо друг от друга в своем темпе.</span><span class="sxs-lookup"><span data-stu-id="d1b07-163">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="d1b07-164">Каждый потребитель отвечает за отслеживание своего текущего положения в потоке.</span><span class="sxs-lookup"><span data-stu-id="d1b07-164">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="d1b07-165">Потребитель должен записывать свою текущую позицию в постоянное хранилище с предопределенным интервалом.</span><span class="sxs-lookup"><span data-stu-id="d1b07-165">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="d1b07-166">Таким образом, если работа потребителя приостановлена (например, происходит сбой потребителя или сбой узла), то новый экземпляр может возобновить чтение потока с последней записанной позиции.</span><span class="sxs-lookup"><span data-stu-id="d1b07-166">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="d1b07-167">Этот процесс называется *установкой контрольных точек*.</span><span class="sxs-lookup"><span data-stu-id="d1b07-167">This process is called *checkpointing*.</span></span>

<span data-ttu-id="d1b07-168">Из соображений производительности потребитель обычно не создает контрольную точку после каждого сообщения.</span><span class="sxs-lookup"><span data-stu-id="d1b07-168">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="d1b07-169">Вместо этого он создает контрольные точки с фиксированным интервалом, например, после обработки *n* сообщений или каждые *n* секунд.</span><span class="sxs-lookup"><span data-stu-id="d1b07-169">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="d1b07-170">Как следствие, если происходит сбой потребителя, некоторые события могут обрабатываться дважды, потому что новый экземпляр всегда начинает с последней контрольной точки.</span><span class="sxs-lookup"><span data-stu-id="d1b07-170">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="d1b07-171">Но есть и компромисс. Частая установка контрольных точек может снизить производительность, а редкая установка повлечет повтор большего числа событий после сбоя.</span><span class="sxs-lookup"><span data-stu-id="d1b07-171">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>

![Схема семантики потока](./images/stream-semantics.png)

<span data-ttu-id="d1b07-173">Центры событий не предназначены для конкурирующих потребителей.</span><span class="sxs-lookup"><span data-stu-id="d1b07-173">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="d1b07-174">Хотя несколько потребителей могут считывать поток, каждый из них проходит поток независимо.</span><span class="sxs-lookup"><span data-stu-id="d1b07-174">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="d1b07-175">Вместо этого Центры событий используют шаблон секционированных потребителей.</span><span class="sxs-lookup"><span data-stu-id="d1b07-175">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="d1b07-176">Концентратор событий может иметь до 32 разделов.</span><span class="sxs-lookup"><span data-stu-id="d1b07-176">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="d1b07-177">Горизонтальное масштабирование достигается путем назначения отдельных потребителей для каждого раздела.</span><span class="sxs-lookup"><span data-stu-id="d1b07-177">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="d1b07-178">Что это значит для рабочего процесса доставки с помощью дрона?</span><span class="sxs-lookup"><span data-stu-id="d1b07-178">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="d1b07-179">Чтобы получить максимальную выгоду от использования Центров событий, планировщик доставки не может ожидать обработки каждого сообщения перед переходом к следующему.</span><span class="sxs-lookup"><span data-stu-id="d1b07-179">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="d1b07-180">Если это произойдет, он проведет большую часть своего времени, ожидая завершения сетевых вызовов.</span><span class="sxs-lookup"><span data-stu-id="d1b07-180">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="d1b07-181">Вместо этого он должен обрабатывать пакеты сообщений параллельно, используя асинхронные вызовы для серверных служб.</span><span class="sxs-lookup"><span data-stu-id="d1b07-181">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="d1b07-182">Как мы увидим, выбор правильной стратегии создания контрольных точек также важен.</span><span class="sxs-lookup"><span data-stu-id="d1b07-182">As we'll see, choosing the right checkpointing strategy is also important.</span></span>

## <a name="workflow"></a><span data-ttu-id="d1b07-183">Рабочий процесс</span><span class="sxs-lookup"><span data-stu-id="d1b07-183">Workflow</span></span>

<span data-ttu-id="d1b07-184">Мы рассмотрели три варианта чтения и обработки сообщений: с помощью узла обработчика событий, очередей служебной шины и библиотеки IoTHub React.</span><span class="sxs-lookup"><span data-stu-id="d1b07-184">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="d1b07-185">Мы выбрали IoTHub React, потому что она помогает начать работу с узлом обработчика событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-185">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span>

### <a name="event-processor-host"></a><span data-ttu-id="d1b07-186">Узел обработчика событий</span><span class="sxs-lookup"><span data-stu-id="d1b07-186">Event Processor Host</span></span>

<span data-ttu-id="d1b07-187">Узел обработчика событий предназначен для пакетной обработки сообщений.</span><span class="sxs-lookup"><span data-stu-id="d1b07-187">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="d1b07-188">Приложение реализует интерфейс `IEventProcessor`, а узел обработчика создает один экземпляр обработчика событий для каждого раздела в концентраторе событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-188">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="d1b07-189">Узел обработчика событий затем вызывает метод `ProcessEventsAsync` каждого обработчика событий с пакетами сообщений о событиях.</span><span class="sxs-lookup"><span data-stu-id="d1b07-189">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="d1b07-190">Приложение контролирует процесс создания контрольных точек внутри метода `ProcessEventsAsync`, а узел обработчика событий записывает контрольные точки в хранилище Azure.</span><span class="sxs-lookup"><span data-stu-id="d1b07-190">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span>

<span data-ttu-id="d1b07-191">Внутри раздела узел обработчика событий ожидает возврата `ProcessEventsAsync` перед вызовом следующего пакета.</span><span class="sxs-lookup"><span data-stu-id="d1b07-191">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="d1b07-192">Этот подход упрощает модель программирования, так как код обработки событий не должен быть реентерабельным.</span><span class="sxs-lookup"><span data-stu-id="d1b07-192">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="d1b07-193">Однако это также означает, что обработчик событий обрабатывает один пакет за раз, что приводит к ограничению скорости, с которой узел обработчика может передавать сообщения.</span><span class="sxs-lookup"><span data-stu-id="d1b07-193">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE]
> <span data-ttu-id="d1b07-194">Фактически узел обработчика не *ожидает* снятия блокировки потока.</span><span class="sxs-lookup"><span data-stu-id="d1b07-194">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="d1b07-195">Метод `ProcessEventsAsync` является асинхронным, поэтому узел обработчика может выполнять другую работу параллельно с выполнением метода.</span><span class="sxs-lookup"><span data-stu-id="d1b07-195">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="d1b07-196">Но пока метод не вернется, он не доставит другой пакет сообщений для этого раздела.</span><span class="sxs-lookup"><span data-stu-id="d1b07-196">But it won't deliver another batch of messages for that partition until the method returns.</span></span>

<span data-ttu-id="d1b07-197">В приложении дронов пакеты сообщений могут обрабатываться параллельно.</span><span class="sxs-lookup"><span data-stu-id="d1b07-197">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="d1b07-198">Но ожидание завершения обработки всего пакета по-прежнему может стать узким местом.</span><span class="sxs-lookup"><span data-stu-id="d1b07-198">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="d1b07-199">Обработка не может быть быстрее самого медленного сообщения в пакете.</span><span class="sxs-lookup"><span data-stu-id="d1b07-199">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="d1b07-200">Любое изменение времени отклика может создать длинный "хвост", когда несколько медленных ответов будут отягощать всю систему.</span><span class="sxs-lookup"><span data-stu-id="d1b07-200">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="d1b07-201">Наши тесты производительности показали, что при таком подходе мы не достигли целевой пропускной способности.</span><span class="sxs-lookup"><span data-stu-id="d1b07-201">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="d1b07-202">Это *не* означает, что вам следует избегать использования узла обработчика событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-202">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="d1b07-203">Для достижения высокой пропускной способности избегайте выполнения длительных задач внутри метода `ProcessEventsAsync`.</span><span class="sxs-lookup"><span data-stu-id="d1b07-203">But for high throughput, avoid doing any long-running tasks inside the `ProcessEventsAsync` method.</span></span> <span data-ttu-id="d1b07-204">Быстро обрабатывайте каждый пакет.</span><span class="sxs-lookup"><span data-stu-id="d1b07-204">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="d1b07-205">Библиотека IotHub React</span><span class="sxs-lookup"><span data-stu-id="d1b07-205">IotHub React</span></span>

<span data-ttu-id="d1b07-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) — это библиотека Akka Streams для чтения событий из концентратора событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="d1b07-207">Akka Streams — это платформа программирования на основе потоков, которая реализует спецификацию [реактивных потоков](https://www.reactive-streams.org/).</span><span class="sxs-lookup"><span data-stu-id="d1b07-207">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](https://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="d1b07-208">Она позволяет создавать эффективные потоковые конвейеры, где все потоковые операции выполняются асинхронно, а конвейер корректно обрабатывает обратную реакцию.</span><span class="sxs-lookup"><span data-stu-id="d1b07-208">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="d1b07-209">Замедленная обратная реакция возникает, когда источник событий генерирует события с более высокой скоростью, чем подчиненные потребители могут получить их. Это в точности соответствует ситуации, когда система доставки с помощью дронов создает пик трафика.</span><span class="sxs-lookup"><span data-stu-id="d1b07-209">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="d1b07-210">Если серверные службы работают медленнее, IoTHub React замедлит работу.</span><span class="sxs-lookup"><span data-stu-id="d1b07-210">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="d1b07-211">Если емкость увеличивается, IoTHub React отправляет больше сообщений по конвейеру.</span><span class="sxs-lookup"><span data-stu-id="d1b07-211">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="d1b07-212">Akka Streams также является очень естественной моделью программирования для потоковой передачи событий из Центров событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-212">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="d1b07-213">Вместо циклического перебора пакетов событий нужно определить набор операций, которые будут применяться к каждому событию, а обработку потоковой передачи выполняет Akka Streams.</span><span class="sxs-lookup"><span data-stu-id="d1b07-213">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="d1b07-214">Akka Streams определяет конвейер потоковой передачи, включающий в себя *источники*, *потоки* и *приемники*.</span><span class="sxs-lookup"><span data-stu-id="d1b07-214">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="d1b07-215">Источник генерирует поток вывода, поток обрабатывает входной поток и создает поток вывода, а приемник потребляет поток без каких-либо выходных данных.</span><span class="sxs-lookup"><span data-stu-id="d1b07-215">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="d1b07-216">Ниже приведен код в службе планировщика, который настраивает конвейер Akka Streams:</span><span class="sxs-lookup"><span data-stu-id="d1b07-216">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="d1b07-217">Этот код настраивает Центры событий в качестве источников.</span><span class="sxs-lookup"><span data-stu-id="d1b07-217">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="d1b07-218">Оператор `map` десериализует каждое сообщение о событии в класс Java, который представляет запрос на доставку.</span><span class="sxs-lookup"><span data-stu-id="d1b07-218">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="d1b07-219">Оператор `filter` удаляет любые объекты `null` из потока. Это предотвращает случаи, когда сообщение нельзя десериализовать.</span><span class="sxs-lookup"><span data-stu-id="d1b07-219">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="d1b07-220">Оператор `via` присоединяет источник к потоку, обрабатывающему каждый запрос на доставку.</span><span class="sxs-lookup"><span data-stu-id="d1b07-220">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="d1b07-221">Метод `to` соединяет поток с приемником контрольной точки, который встроен в IoTHub React.</span><span class="sxs-lookup"><span data-stu-id="d1b07-221">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="d1b07-222">IoTHub React использует другую стратегию установки контрольных точек, нежели процессор узла событий.</span><span class="sxs-lookup"><span data-stu-id="d1b07-222">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="d1b07-223">Контрольные точки записываются приемником контрольных точек, что является завершающим этапом в конвейере.</span><span class="sxs-lookup"><span data-stu-id="d1b07-223">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="d1b07-224">Структура Akka Streams позволяет конвейеру продолжать передавать данные, а приемник записывает контрольную точку.</span><span class="sxs-lookup"><span data-stu-id="d1b07-224">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="d1b07-225">Это означает, что вышестоящим стадиям обработки данных не нужно ждать создания контрольной точки.</span><span class="sxs-lookup"><span data-stu-id="d1b07-225">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="d1b07-226">Можно настроить так, чтобы контрольная точка создавалась после истечения времени ожидания или обработки определенного количества сообщений.</span><span class="sxs-lookup"><span data-stu-id="d1b07-226">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="d1b07-227">Метод `deliveryProcessor` создает поток Akka Streams:</span><span class="sxs-lookup"><span data-stu-id="d1b07-227">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(),
                        delivery.getMessageFromDevice().properties());

        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }

        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="d1b07-228">Поток вызывает статический метод `processDeliveryRequestAsync`, который выполняет фактическую обработку каждого сообщения.</span><span class="sxs-lookup"><span data-stu-id="d1b07-228">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="d1b07-229">Масштабирование с IoTHub React</span><span class="sxs-lookup"><span data-stu-id="d1b07-229">Scaling with IoTHub React</span></span>

<span data-ttu-id="d1b07-230">Служба планировщика разработана таким образом, что каждый экземпляр контейнера считывает данные из одного раздела.</span><span class="sxs-lookup"><span data-stu-id="d1b07-230">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="d1b07-231">Например, если концентратор событий содержит 32 раздела, служба планировщика развертывается с 32 репликами.</span><span class="sxs-lookup"><span data-stu-id="d1b07-231">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="d1b07-232">Это обеспечивает большую гибкость с точки зрения горизонтального масштабирования.</span><span class="sxs-lookup"><span data-stu-id="d1b07-232">This allows for a lot of flexibility in terms of horizontal scaling.</span></span>

<span data-ttu-id="d1b07-233">В зависимости от размера кластера на узле кластера может выполняться несколько модулей pod службы планировщика.</span><span class="sxs-lookup"><span data-stu-id="d1b07-233">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="d1b07-234">Но если службе планировщика требуется больше ресурсов, кластер можно развернуть, чтобы распределить модули pod между большим количеством узлов.</span><span class="sxs-lookup"><span data-stu-id="d1b07-234">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="d1b07-235">Наши тесты производительности показали, что служба планировщика связана с памятью и потоками, поэтому производительность сильно зависит от размера виртуальной машины и количества модулей pod на каждом узле.</span><span class="sxs-lookup"><span data-stu-id="d1b07-235">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="d1b07-236">Каждый экземпляр должен знать, из какого раздела концентратора событий следует выполнять чтение.</span><span class="sxs-lookup"><span data-stu-id="d1b07-236">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="d1b07-237">Чтобы настроить номер раздела, воспользуемся типом ресурса [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) в Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="d1b07-237">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="d1b07-238">Модули pod в StatefulSet имеют постоянный идентификатор, который содержит числовой индекс.</span><span class="sxs-lookup"><span data-stu-id="d1b07-238">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="d1b07-239">В частности, имя модуля — `<statefulset name>-<index>`, и это значение доступно контейнеру через [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/) Kubernetes.</span><span class="sxs-lookup"><span data-stu-id="d1b07-239">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="d1b07-240">Во время выполнения служба планировщика считывает имя модуля pod и использует его индекс в качестве идентификатора раздела.</span><span class="sxs-lookup"><span data-stu-id="d1b07-240">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="d1b07-241">Если вам нужно еще больше масштабировать службу планировщика, вы можете назначить несколько модулей pod для каждого раздела концентратора событий, чтобы несколько модулей считывали каждый раздел.</span><span class="sxs-lookup"><span data-stu-id="d1b07-241">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="d1b07-242">Однако в этом случае каждый экземпляр будет считывать все события в назначенном разделе.</span><span class="sxs-lookup"><span data-stu-id="d1b07-242">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="d1b07-243">Чтобы избежать дублирования обработки, нужно использовать алгоритм хэширования, чтобы каждый экземпляр пропускал часть сообщений.</span><span class="sxs-lookup"><span data-stu-id="d1b07-243">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="d1b07-244">Таким образом, несколько модулей чтения могут получать поток, но каждое сообщение обрабатывается только одним экземпляром.</span><span class="sxs-lookup"><span data-stu-id="d1b07-244">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span>

![Схема хэширования концентратора событий](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="d1b07-246">Очереди служебной шины</span><span class="sxs-lookup"><span data-stu-id="d1b07-246">Service Bus queues</span></span>

<span data-ttu-id="d1b07-247">Третий вариант, который мы рассмотрели, заключался в копировании сообщений из Центров событий в очередь служебной шины, а затем настройке службы планировщика для чтения сообщений через служебную шину.</span><span class="sxs-lookup"><span data-stu-id="d1b07-247">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="d1b07-248">Может показаться странным записывать входящие запросы в Центры событий только для того, чтобы скопировать их в служебную шину.</span><span class="sxs-lookup"><span data-stu-id="d1b07-248">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="d1b07-249">Но идея заключалась в том, чтобы использовать различные преимущества каждой службы — Центры событий для выравнивания пиков интенсивного трафика, а семантику очереди в служебной шине для обработки рабочей нагрузки с использованием шаблона конкурирующих потребителей.</span><span class="sxs-lookup"><span data-stu-id="d1b07-249">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="d1b07-250">Помните, что приоритет устойчивой пропускной способности меньше чем ожидаемой максимальной нагрузки, поэтому для обработки очереди служебной шины не требуется такая же скорость, как для приема сообщений.</span><span class="sxs-lookup"><span data-stu-id="d1b07-250">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>

<span data-ttu-id="d1b07-251">При таком подходе в результате нашей экспериментальной концепции удалось достичь показателя — 4000 операций в секунду.</span><span class="sxs-lookup"><span data-stu-id="d1b07-251">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="d1b07-252">Для тестов использовались макеты сервисных служб, которые не выполняли никакой реальной работы, а просто добавляли фиксированную задержку для каждой службы.</span><span class="sxs-lookup"><span data-stu-id="d1b07-252">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="d1b07-253">Обратите внимание, что наши показатели производительности намного меньше теоретических максимальных значений для служебной шины.</span><span class="sxs-lookup"><span data-stu-id="d1b07-253">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="d1b07-254">Возможные причины расхождения:</span><span class="sxs-lookup"><span data-stu-id="d1b07-254">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="d1b07-255">Отсутствие оптимальных значений для различных параметров клиента, таких как ограничение пула подключений, степень параллелизации, количество предварительной выборки и размер пакета.</span><span class="sxs-lookup"><span data-stu-id="d1b07-255">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="d1b07-256">Узкие места сетевых операций ввода-вывода.</span><span class="sxs-lookup"><span data-stu-id="d1b07-256">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="d1b07-257">Использование режима [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) вместо [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), что необходимо для обеспечения по меньшей мере однократной доставки сообщений.</span><span class="sxs-lookup"><span data-stu-id="d1b07-257">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="d1b07-258">Последующие тесты производительности помогли бы обнаружить первопричину и решить эти проблемы.</span><span class="sxs-lookup"><span data-stu-id="d1b07-258">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="d1b07-259">Тем не менее, библиотека IotHub React помогла нам достичь целевых показателей, поэтому мы выбрали этот вариант.</span><span class="sxs-lookup"><span data-stu-id="d1b07-259">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="d1b07-260">С другой стороны, служебная шина также приемлема для этого сценария.</span><span class="sxs-lookup"><span data-stu-id="d1b07-260">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="d1b07-261">Обработка сбоев</span><span class="sxs-lookup"><span data-stu-id="d1b07-261">Handling failures</span></span>

<span data-ttu-id="d1b07-262">Существует три общих класса сбоя, которые следует учитывать.</span><span class="sxs-lookup"><span data-stu-id="d1b07-262">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="d1b07-263">В подчиненной службе может возникать повторяющаяся ошибка. Это может быть любой сбой, который не устранится сам по себе.</span><span class="sxs-lookup"><span data-stu-id="d1b07-263">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="d1b07-264">Повторяющиеся ошибки включают в себя обычные условия ошибки, такие как недопустимые входные данные метода.</span><span class="sxs-lookup"><span data-stu-id="d1b07-264">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="d1b07-265">К ним также относятся необработанные исключения в коде приложения или сбой процесса.</span><span class="sxs-lookup"><span data-stu-id="d1b07-265">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="d1b07-266">При возникновении такой ошибки вся бизнес-транзакция должна быть отмечена как сбой.</span><span class="sxs-lookup"><span data-stu-id="d1b07-266">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="d1b07-267">Может потребоваться отменить другие шаги в той же транзакции, которые уже выполнены.</span><span class="sxs-lookup"><span data-stu-id="d1b07-267">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="d1b07-268">(См. раздел "Компенсирующие транзакции" ниже.)</span><span class="sxs-lookup"><span data-stu-id="d1b07-268">(See Compensating Transactions, below.)</span></span>

2. <span data-ttu-id="d1b07-269">В подчиненной службе может возникнуть временная ошибка, например истечение времени ожидания сети.</span><span class="sxs-lookup"><span data-stu-id="d1b07-269">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="d1b07-270">Эти ошибки часто можно решить, просто повторив вызов.</span><span class="sxs-lookup"><span data-stu-id="d1b07-270">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="d1b07-271">Если операция по-прежнему завершается сбоем после определенного количества попыток, такая ошибка считается повторяющейся.</span><span class="sxs-lookup"><span data-stu-id="d1b07-271">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span>

3. <span data-ttu-id="d1b07-272">В самой службе планировщика может возникнуть ошибка (например, из-за сбоя узла).</span><span class="sxs-lookup"><span data-stu-id="d1b07-272">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="d1b07-273">В этом случае Kubernetes предоставит новый экземпляр службы.</span><span class="sxs-lookup"><span data-stu-id="d1b07-273">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="d1b07-274">Однако любые транзакции, которые уже начали выполняться, должны быть возобновлены.</span><span class="sxs-lookup"><span data-stu-id="d1b07-274">However, any transactions that were already in progress must be resumed.</span></span>

## <a name="compensating-transactions"></a><span data-ttu-id="d1b07-275">Компенсирующие транзакции</span><span class="sxs-lookup"><span data-stu-id="d1b07-275">Compensating transactions</span></span>

<span data-ttu-id="d1b07-276">Если происходит повторяющаяся ошибка, текущая транзакция может находиться в состоянии *частичного сбоя*, когда один или несколько шагов уже завершены успешно.</span><span class="sxs-lookup"><span data-stu-id="d1b07-276">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="d1b07-277">Например, если служба дронов уже запланировала доставку с помощью дрона, она должна быть отменена.</span><span class="sxs-lookup"><span data-stu-id="d1b07-277">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="d1b07-278">В этом случае приложение должно отменить успешно выполненные шаги с помощью [компенсирующей транзакции](../patterns/compensating-transaction.md).</span><span class="sxs-lookup"><span data-stu-id="d1b07-278">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="d1b07-279">В некоторых случаях это нужно выполнить во внешней системе или даже с использованием операции в ручном режиме.</span><span class="sxs-lookup"><span data-stu-id="d1b07-279">In some cases, this must be done by an external system or even by a manual process.</span></span>

<span data-ttu-id="d1b07-280">Если логика компенсирующих транзакций сложна, можно создать отдельную службу, которая отвечает за этот процесс.</span><span class="sxs-lookup"><span data-stu-id="d1b07-280">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="d1b07-281">В приложении доставки с помощью дронов служба планировщика ставит неудачные операции в выделенную очередь.</span><span class="sxs-lookup"><span data-stu-id="d1b07-281">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="d1b07-282">Отдельная микрослужба, называемая контролером, выполняет чтение из этой очереди и вызывает API отмены для служб, которые необходимо компенсировать.</span><span class="sxs-lookup"><span data-stu-id="d1b07-282">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="d1b07-283">Это разновидность [шаблона "планировщик, агент, контролер"][scheduler-agent-supervisor].</span><span class="sxs-lookup"><span data-stu-id="d1b07-283">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="d1b07-284">Служба "Контролер" может выполнять и другие действия, такие как уведомление пользователя с помощью текстового сообщения или электронной почты или отправка предупреждения на панель управления операций.</span><span class="sxs-lookup"><span data-stu-id="d1b07-284">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span>

![Схема микрослужбы "Контролер"](./images/supervisor.png)

## <a name="idempotent-versus-non-idempotent-operations"></a><span data-ttu-id="d1b07-286">Идемпотентные и неидемпотентные операции</span><span class="sxs-lookup"><span data-stu-id="d1b07-286">Idempotent versus non-idempotent operations</span></span>

<span data-ttu-id="d1b07-287">Чтобы избежать потери каких-либо запросов, служба планировщика должна гарантировать, что все сообщения обрабатываются хотя бы один раз.</span><span class="sxs-lookup"><span data-stu-id="d1b07-287">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="d1b07-288">Центры событий могут обеспечить по крайней мере однократную доставку, если клиент создает контрольные точки надлежащим образом.</span><span class="sxs-lookup"><span data-stu-id="d1b07-288">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="d1b07-289">Если служба планировщика завершается сбоем, она может остановиться в процессе обработки одного или нескольких клиентских запросов.</span><span class="sxs-lookup"><span data-stu-id="d1b07-289">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="d1b07-290">Эти сообщения повторно обработает другой экземпляр планировщика.</span><span class="sxs-lookup"><span data-stu-id="d1b07-290">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="d1b07-291">Что произойдет, если запрос будет обработан дважды?</span><span class="sxs-lookup"><span data-stu-id="d1b07-291">What happens if a request is processed twice?</span></span> <span data-ttu-id="d1b07-292">Важно предотвратить дублирование какой-либо работы.</span><span class="sxs-lookup"><span data-stu-id="d1b07-292">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="d1b07-293">В конце концов, мы не хотим, чтобы система отправляла два дрона для одного и того же груза.</span><span class="sxs-lookup"><span data-stu-id="d1b07-293">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="d1b07-294">Один из подходов состоит в том, чтобы сделать все операции идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="d1b07-294">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="d1b07-295">Операция является идемпотентной, если ее можно вызвать несколько раз, не создавая дополнительных побочных эффектов после первого вызова.</span><span class="sxs-lookup"><span data-stu-id="d1b07-295">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="d1b07-296">Другими словами, клиент может вызывать операцию один, два или много раз, и результат будет таким же.</span><span class="sxs-lookup"><span data-stu-id="d1b07-296">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="d1b07-297">По сути, служба должна игнорировать повторяющиеся вызовы.</span><span class="sxs-lookup"><span data-stu-id="d1b07-297">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="d1b07-298">Чтобы метод с побочными эффектами был идемпотентным, служба должна иметь возможность обнаруживать повторяющиеся вызовы.</span><span class="sxs-lookup"><span data-stu-id="d1b07-298">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="d1b07-299">Например, можно настроить так, чтобы вызывающий объект присваивал идентификатор, вместо того, чтобы служба генерировала новый идентификатор.</span><span class="sxs-lookup"><span data-stu-id="d1b07-299">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="d1b07-300">Затем служба может проверить наличие дубликатов идентификаторов.</span><span class="sxs-lookup"><span data-stu-id="d1b07-300">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="d1b07-301">Согласно спецификации HTTP методы GET, PUT и DELETE должны быть идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="d1b07-301">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="d1b07-302">Методы POST не обязательно должны быть идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="d1b07-302">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="d1b07-303">Если метод POST создает новый ресурс, обычно это не гарантирует, что эта операция является идемпотентной.</span><span class="sxs-lookup"><span data-stu-id="d1b07-303">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span>

<span data-ttu-id="d1b07-304">Не всегда просто написать идемпотентный метод.</span><span class="sxs-lookup"><span data-stu-id="d1b07-304">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="d1b07-305">Другой вариант — планировщик должен отслеживать ход каждой транзакции в надежном хранилище.</span><span class="sxs-lookup"><span data-stu-id="d1b07-305">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="d1b07-306">Всякий раз, когда он обрабатывает сообщение, он будет искать состояние в надежном хранилище.</span><span class="sxs-lookup"><span data-stu-id="d1b07-306">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="d1b07-307">После каждого шага он записывает результат в хранилище.</span><span class="sxs-lookup"><span data-stu-id="d1b07-307">After each step, it would write the result to the store.</span></span> <span data-ttu-id="d1b07-308">Такой подход может оказать влияние на производительность.</span><span class="sxs-lookup"><span data-stu-id="d1b07-308">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="d1b07-309">Пример: Идемпотентные операции</span><span class="sxs-lookup"><span data-stu-id="d1b07-309">Example: Idempotent operations</span></span>

<span data-ttu-id="d1b07-310">Спецификация HTTP указывает, что методы PUT должны быть идемпотентными.</span><span class="sxs-lookup"><span data-stu-id="d1b07-310">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="d1b07-311">Спецификация определяет идемпотентность следующим образом.</span><span class="sxs-lookup"><span data-stu-id="d1b07-311">The specification defines idempotent this way:</span></span>

> <span data-ttu-id="d1b07-312">Метод запроса считается идемпотентным, если предполагаемый эффект на сервере с несколькими идентичными запросами с этим методом совпадает с эффектом для одного такого запроса.</span><span class="sxs-lookup"><span data-stu-id="d1b07-312">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the same as the effect for a single such request.</span></span> <span data-ttu-id="d1b07-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span><span class="sxs-lookup"><span data-stu-id="d1b07-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="d1b07-314">Важно понимать разницу между семантикой PUT и POST при создании новой сущности.</span><span class="sxs-lookup"><span data-stu-id="d1b07-314">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="d1b07-315">В обоих случаях клиент отправляет представление сущности в тексте запроса.</span><span class="sxs-lookup"><span data-stu-id="d1b07-315">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="d1b07-316">Значения URI при этом разные.</span><span class="sxs-lookup"><span data-stu-id="d1b07-316">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="d1b07-317">Для метода POST URI представляет родительский ресурс новой сущности, такой как коллекция.</span><span class="sxs-lookup"><span data-stu-id="d1b07-317">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="d1b07-318">Например, чтобы создать новую доставку, можно использовать URI `/api/deliveries`.</span><span class="sxs-lookup"><span data-stu-id="d1b07-318">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="d1b07-319">Сервер создает сущность и назначает ей новый URI, например `/api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="d1b07-319">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="d1b07-320">Этот URI возвращается в заголовке Location ответа.</span><span class="sxs-lookup"><span data-stu-id="d1b07-320">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="d1b07-321">Каждый раз, когда клиент отправляет запрос, сервер создает новый объект с новым URI.</span><span class="sxs-lookup"><span data-stu-id="d1b07-321">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="d1b07-322">Для метода PUT URI определяет сущность.</span><span class="sxs-lookup"><span data-stu-id="d1b07-322">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="d1b07-323">Если сущность с таким URI уже существует, сервер заменяет существующую сущность версией из запроса.</span><span class="sxs-lookup"><span data-stu-id="d1b07-323">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="d1b07-324">Если сущности с таким URI не существует, сервер создает ее.</span><span class="sxs-lookup"><span data-stu-id="d1b07-324">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="d1b07-325">Предположим, клиент отправляет запрос PUT к `api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="d1b07-325">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="d1b07-326">Предполагая, что доставки с этим URI не существует, сервер создает новую.</span><span class="sxs-lookup"><span data-stu-id="d1b07-326">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="d1b07-327">Теперь если клиент снова отправляет тот же запрос, сервер заменяет существующую сущность.</span><span class="sxs-lookup"><span data-stu-id="d1b07-327">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="d1b07-328">Ниже приведена реализация метода PUT в службе доставки.</span><span class="sxs-lookup"><span data-stu-id="d1b07-328">Here is the Delivery service's implementation of the PUT method.</span></span>

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="d1b07-329">Ожидается, что большинство запросов создадут новые сущности, поэтому метод вызывает `CreateAsync` в объекте репозитория, а затем обрабатывает все исключения дубликатов ресурсов, обновляя ресурс.</span><span class="sxs-lookup"><span data-stu-id="d1b07-329">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span>

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md