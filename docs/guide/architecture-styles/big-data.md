---
title: Стиль архитектуры для обработки больших данных
description: В этой статье описаны преимущества и недостатки архитектур для обработки больших данных в Azure, а также рекомендации по работе с ними.
author: MikeWasson
ms.openlocfilehash: 4e8b58d5fa0f6a441d70e05ec7d6a0e668712563
ms.sourcegitcommit: b0482d49aab0526be386837702e7724c61232c60
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/14/2017
ms.locfileid: "24540894"
---
# <a name="big-data-architecture-style"></a><span data-ttu-id="30c61-103">Стиль архитектуры для обработки больших данных</span><span class="sxs-lookup"><span data-stu-id="30c61-103">Big data architecture style</span></span>

<span data-ttu-id="30c61-104">Архитектура для обработки больших данных позволяет принимать, обрабатывать и анализировать данные, которые являются слишком объемными или слишком сложными для традиционных систем баз данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-104">A big data architecture is designed to handle the ingestion, processing, and analysis of data that is too large or complex for traditional database systems.</span></span>

![](./images/big-data-logical.svg)

 <span data-ttu-id="30c61-105">Решения для обработки больших данных обычно предназначены для одного или нескольких из следующих типов рабочей нагрузки:</span><span class="sxs-lookup"><span data-stu-id="30c61-105">Big data solutions typically involve one or more of the following types of workload:</span></span>

- <span data-ttu-id="30c61-106">пакетная обработка источников неактивных больших данных;</span><span class="sxs-lookup"><span data-stu-id="30c61-106">Batch processing of big data sources at rest.</span></span>
- <span data-ttu-id="30c61-107">обработка больших данных в динамике в режиме реального времени;</span><span class="sxs-lookup"><span data-stu-id="30c61-107">Real-time processing of big data in motion.</span></span>
- <span data-ttu-id="30c61-108">интерактивное изучение больших данных;</span><span class="sxs-lookup"><span data-stu-id="30c61-108">Interactive exploration of big data.</span></span>
- <span data-ttu-id="30c61-109">прогнозная аналитика и машинное обучение.</span><span class="sxs-lookup"><span data-stu-id="30c61-109">Predictive analytics and machine learning.</span></span>

<span data-ttu-id="30c61-110">Большинство архитектур для обработки больших данных включают некоторые или все перечисленные ниже компоненты.</span><span class="sxs-lookup"><span data-stu-id="30c61-110">Most big data architectures include some or all of the following components:</span></span>

- <span data-ttu-id="30c61-111">**Источники данных.** Все решения для обработки больших данных начинаются с одного или нескольких источников данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-111">**Data sources**: All big data solutions start with one or more data sources.</span></span> <span data-ttu-id="30c61-112">Примеры приведены ниже.</span><span class="sxs-lookup"><span data-stu-id="30c61-112">Examples include:</span></span>

    - <span data-ttu-id="30c61-113">Хранилища данных приложений, например реляционные базы данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-113">Application data stores, such as relational databases.</span></span>
    - <span data-ttu-id="30c61-114">Статические файлы, которые создаются приложениями, например файлы журнала веб-сервера.</span><span class="sxs-lookup"><span data-stu-id="30c61-114">Static files produced by applications, such as web server log files.</span></span>
    - <span data-ttu-id="30c61-115">Источники данных с передачей в режиме реального времени, например устройства Интернета вещей.</span><span class="sxs-lookup"><span data-stu-id="30c61-115">Real-time data sources, such as IoT devices.</span></span>

- <span data-ttu-id="30c61-116">**Хранилище данных.** Данные для пакетной обработки обычно хранятся в распределенном хранилище файлов, где могут содержаться значительные объемы больших файлов в различных форматах.</span><span class="sxs-lookup"><span data-stu-id="30c61-116">**Data storage**: Data for batch processing operations is typically stored in a distributed file store that can hold high volumes of large files in various formats.</span></span> <span data-ttu-id="30c61-117">Этот тип хранилища часто называют *озером данных*.</span><span class="sxs-lookup"><span data-stu-id="30c61-117">This kind of store is often called a *data lake*.</span></span> <span data-ttu-id="30c61-118">Такое хранилище можно реализовать с помощью Azure Data Lake Store или контейнеров больших двоичных объектов в службе хранилища Azure.</span><span class="sxs-lookup"><span data-stu-id="30c61-118">Options for implementing this storage include Azure Data Lake Store or blob containers in Azure Storage.</span></span> 

- <span data-ttu-id="30c61-119">**Пакетная обработка.** Так как наборы данных очень велики, часто в решении обрабатываются длительные пакетные задания. Для них выполняется фильтрация, статистическая обработка и другие процессы подготовки данных к анализу.</span><span class="sxs-lookup"><span data-stu-id="30c61-119">**Batch processing**: Because the data sets are so large, often a big data solution must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="30c61-120">Обычно в эти задания входит чтение исходных файлов, их обработка и запись выходных данных в новые файлы.</span><span class="sxs-lookup"><span data-stu-id="30c61-120">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> <span data-ttu-id="30c61-121">Варианты: выполнение заданий U-SQL в Azure Data Lake Analytics, использование пользовательских заданий Hive, Pig или Map/Reduce в кластере HDInsight Hadoop и применение программ Java, Scala или Python в кластере HDInsight Spark.</span><span class="sxs-lookup"><span data-stu-id="30c61-121">Options include running U-SQL jobs in Azure Data Lake Analytics, using Hive, Pig, or custom Map/Reduce jobs in an HDInsight Hadoop cluster, or using Java, Scala, or Python programs in an HDInsight Spark cluster.</span></span>

- <span data-ttu-id="30c61-122">**Прием сообщений в режиме реального времени.** Если решение содержит источники в режиме реального времени, в архитектуре должен быть предусмотрен способ сбора и сохранения сообщений в режиме реального времени для потоковой обработки.</span><span class="sxs-lookup"><span data-stu-id="30c61-122">**Real-time message ingestion**: If the solution includes real-time sources, the architecture must include a way to capture and store real-time messages for stream processing.</span></span> <span data-ttu-id="30c61-123">Это может быть простое хранилище данных с папкой, в которую входящие сообщения помещаются для обработки.</span><span class="sxs-lookup"><span data-stu-id="30c61-123">This might be a simple data store, where incoming messages are dropped into a folder for processing.</span></span> <span data-ttu-id="30c61-124">Но для приема сообщений многим решениям требуется хранилище, которое можно использовать в качестве буфера. Такое хранилище должно поддерживать обработку с горизонтальным масштабированием, надежную доставку и другую семантику очереди сообщений.</span><span class="sxs-lookup"><span data-stu-id="30c61-124">However, many solutions need a message ingestion store to act as a buffer for messages, and to support scale-out processing, reliable delivery, and other message queuing semantics.</span></span> <span data-ttu-id="30c61-125">Варианты: концентраторы событий Azure, Центры Интернета вещей и Kafka.</span><span class="sxs-lookup"><span data-stu-id="30c61-125">Options include Azure Event Hubs, Azure IoT Hubs, and Kafka.</span></span>

- <span data-ttu-id="30c61-126">**Потоковый обмен сообщениями.** После записи сообщений в режиме реального времени в решении нужно выполнить их фильтрацию, статистическую обработку и другие процессы подготовки данных к анализу.</span><span class="sxs-lookup"><span data-stu-id="30c61-126">**Stream processing**: After capturing real-time messages, the solution must process them by filtering, aggregating, and otherwise preparing the data for analysis.</span></span> <span data-ttu-id="30c61-127">Затем обработанные потоковые данные записываются в выходной приемник.</span><span class="sxs-lookup"><span data-stu-id="30c61-127">The processed stream data is then written to an output sink.</span></span> <span data-ttu-id="30c61-128">Azure Stream Analytics предоставляет управляемую службу потоковой обработки на основе постоянного выполнения запросов SQL для непривязанных потоков.</span><span class="sxs-lookup"><span data-stu-id="30c61-128">Azure Stream Analytics provides a managed stream processing service based on perpetually running SQL queries that operate on unbounded streams.</span></span> <span data-ttu-id="30c61-129">Кроме того, для потоковой передачи можно использовать технологии Apache с открытым кодом, например Storm и Spark Streaming в кластере HDInsight.</span><span class="sxs-lookup"><span data-stu-id="30c61-129">You can also use open source Apache streaming technologies like Storm and Spark Streaming in an HDInsight cluster.</span></span>

- <span data-ttu-id="30c61-130">**Хранилище аналитических данных.** Во многих решениях для обработки больших данных данные подготавливаются к анализу. Затем обработанные данные структурируются в соответствии с форматом запросов для средств аналитики.</span><span class="sxs-lookup"><span data-stu-id="30c61-130">**Analytical data store**: Many big data solutions prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> <span data-ttu-id="30c61-131">Хранилище аналитических данных, используемое для обработки таких запросов, может быть реляционной базой данных типа Kimball, как можно увидеть в большинстве традиционных решений бизнес-аналитики (BI).</span><span class="sxs-lookup"><span data-stu-id="30c61-131">The analytical data store used to serve these queries can be a Kimball-style relational data warehouse, as seen in most traditional business intelligence (BI) solutions.</span></span> <span data-ttu-id="30c61-132">Кроме того, данные можно представить с помощью технологии NoSQL с низкой задержкой, такой как HBase или интерактивная база данных Hive, которая предоставляет абстракцию метаданных для файлов данных в распределенном хранилище.</span><span class="sxs-lookup"><span data-stu-id="30c61-132">Alternatively, the data could be presented through a low-latency NoSQL technology such as HBase, or an interactive Hive database that provides a metadata abstraction over data files in the distributed data store.</span></span> <span data-ttu-id="30c61-133">Хранилище данных SQL Azure предоставляет управляемую службу для хранения больших объемов данных в облаке.</span><span class="sxs-lookup"><span data-stu-id="30c61-133">Azure SQL Data Warehouse provides a managed service for large-scale, cloud-based data warehousing.</span></span> <span data-ttu-id="30c61-134">HDInsight поддерживает Interactive Hive, HBase и Spark SQL, которые также можно использовать, чтобы предоставлять данные для анализа.</span><span class="sxs-lookup"><span data-stu-id="30c61-134">HDInsight supports Interactive Hive, HBase, and Spark SQL, which can also be used to serve data for analysis.</span></span>

- <span data-ttu-id="30c61-135">**Анализ и создание отчетов.** Большинство решений для обработки больших данных позволяют получить представление о данных при помощи анализа и отчетов.</span><span class="sxs-lookup"><span data-stu-id="30c61-135">**Analysis and reporting**: The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> <span data-ttu-id="30c61-136">Чтобы расширить возможности анализа данных, можно включить в архитектуру слой моделирования, например модель таблицы или многомерного куба OLAP в Azure Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="30c61-136">To empower users to analyze the data, the architecture may include a data modeling layer, such as a multidimensional OLAP cube or tabular data model in Azure Analysis Services.</span></span> <span data-ttu-id="30c61-137">Также можно включить поддержку самостоятельной бизнес-аналитики с использованием технологий моделирования и визуализации в Microsoft Power BI или Microsoft Excel.</span><span class="sxs-lookup"><span data-stu-id="30c61-137">It might also support self-service BI, using the modeling and visualization technologies in Microsoft Power BI or Microsoft Excel.</span></span> <span data-ttu-id="30c61-138">Анализ и создание отчетов также может выполняться путем интерактивного изучения данных специалистами по их анализу и обработке.</span><span class="sxs-lookup"><span data-stu-id="30c61-138">Analysis and reporting can also take the form of interactive data exploration by data scientists or data analysts.</span></span> <span data-ttu-id="30c61-139">Для таких сценариев многие службы Azure поддерживают функции аналитического блокнота, например Jupyter, который позволяет пользователям применять свои навыки работы с Python или R. Для крупномасштабного изучения данных можно использовать Microsoft R Server (отдельно или со Spark).</span><span class="sxs-lookup"><span data-stu-id="30c61-139">For these scenarios, many Azure services support analytical notebooks, such as Jupyter, enabling these users to leverage their existing skills with Python or R. For large-scale data exploration, you can use Microsoft R Server, either standalone or with Spark.</span></span>

- <span data-ttu-id="30c61-140">**Оркестрация.** Большинство решений для обработки больших данных состоят из повторяющихся рабочих процессов, во время которых преобразуются исходные данные, данные перемещаются между несколькими источниками и приемниками, обработанные данные загружаются в хранилища аналитических данных либо же результаты передаются непосредственно в отчет или на панель мониторинга.</span><span class="sxs-lookup"><span data-stu-id="30c61-140">**Orchestration**: Most big data solutions consist of repeated data processing operations, encapsulated in workflows, that transform source data, move data between multiple sources and sinks, load the processed data into an analytical data store, or push the results straight to a report or dashboard.</span></span> <span data-ttu-id="30c61-141">Чтобы автоматизировать эти рабочие процессы, вы можете использовать технологию оркестрации, такую как фабрика данных Azure или Apache Oozie и Sqoop.</span><span class="sxs-lookup"><span data-stu-id="30c61-141">To automate these workflows, you can use an orchestration technology such Azure Data Factory or Apache Oozie and Sqoop.</span></span>

<span data-ttu-id="30c61-142">Azure предоставляет много служб, которые можно использовать в архитектуре для обработки больших данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-142">Azure includes many services that can be used in a big data architecture.</span></span> <span data-ttu-id="30c61-143">Их можно условно разделить на две категории:</span><span class="sxs-lookup"><span data-stu-id="30c61-143">They fall roughly into two categories:</span></span>

- <span data-ttu-id="30c61-144">управляемые службы, включая хранилище Azure Data Lake Store, Azure Data Lake Analytics, хранилище данных Azure, Azure Stream Analytics, концентратор событий Azure, Центр Интернета вещей и фабрика данных Azure;</span><span class="sxs-lookup"><span data-stu-id="30c61-144">Managed services, including Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub, and Azure Data Factory.</span></span>
- <span data-ttu-id="30c61-145">технологии с открытым кодом на платформе Apache Hadoop, включая HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop и Kafka.</span><span class="sxs-lookup"><span data-stu-id="30c61-145">Open source technologies based on the Apache Hadoop platform, including HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop, and Kafka.</span></span> <span data-ttu-id="30c61-146">Эти технологии доступны в Azure в службе Azure HDInsight.</span><span class="sxs-lookup"><span data-stu-id="30c61-146">These technologies are available on Azure in the Azure HDInsight service.</span></span>

<span data-ttu-id="30c61-147">Эти варианты не являются взаимоисключающими, и во многих решениях технологии с открытым объединяются со службами Azure.</span><span class="sxs-lookup"><span data-stu-id="30c61-147">These options are not mutually exclusive, and many solutions combine open source technologies with Azure services.</span></span>

## <a name="when-to-use-this-architecture"></a><span data-ttu-id="30c61-148">Когда следует использовать эту архитектуру</span><span class="sxs-lookup"><span data-stu-id="30c61-148">When to use this architecture</span></span>

<span data-ttu-id="30c61-149">Используйте эту архитектуру для следующих сценариев:</span><span class="sxs-lookup"><span data-stu-id="30c61-149">Consider this architecture style when you need to:</span></span>

- <span data-ttu-id="30c61-150">хранение и обработка данных в объемах, слишком больших для традиционной базы данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-150">Store and process data in volumes too large for a traditional database.</span></span>
- <span data-ttu-id="30c61-151">преобразование неструктурированных данных для анализа и создания отчетов;</span><span class="sxs-lookup"><span data-stu-id="30c61-151">Transform unstructured data for analysis and reporting.</span></span>
- <span data-ttu-id="30c61-152">запись, обработка и анализ непривязанных потоков данных в режиме реального времени или с низкой задержкой;</span><span class="sxs-lookup"><span data-stu-id="30c61-152">Capture, process, and analyze unbounded streams of data in real time, or with low latency.</span></span>
- <span data-ttu-id="30c61-153">использование службы "Машинное обучение Azure" или Microsoft Cognitive Services.</span><span class="sxs-lookup"><span data-stu-id="30c61-153">Use Azure Machine Learning or Microsoft Cognitive Services.</span></span>

## <a name="benefits"></a><span data-ttu-id="30c61-154">Преимущества</span><span class="sxs-lookup"><span data-stu-id="30c61-154">Benefits</span></span>

- <span data-ttu-id="30c61-155">**Возможность выбора технологий.**</span><span class="sxs-lookup"><span data-stu-id="30c61-155">**Technology choices**.</span></span> <span data-ttu-id="30c61-156">Можно комбинировать и сопоставлять управляемые службы Azure и технологии Apache в кластерах HDInsight, чтобы с максимальной выгодой применять существующие навыки и инвестировать в технологии.</span><span class="sxs-lookup"><span data-stu-id="30c61-156">You can mix and match Azure managed services and Apache technologies in HDInsight clusters, to capitalize on existing skills or technology investments.</span></span>
- <span data-ttu-id="30c61-157">**Повышение производительности с помощью параллелизма.**</span><span class="sxs-lookup"><span data-stu-id="30c61-157">**Performance through parallelism**.</span></span> <span data-ttu-id="30c61-158">В решениях для обработки больших данных используется преимущество параллелизма, что позволяет применять высокопроизводительные решения, которые могут масштабироваться для работы с большими объемами данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-158">Big data solutions take advantage of parallelism, enabling high-performance solutions that scale to large volumes of data.</span></span>
- <span data-ttu-id="30c61-159">**Эластичное масштабирование.**</span><span class="sxs-lookup"><span data-stu-id="30c61-159">**Elastic scale**.</span></span> <span data-ttu-id="30c61-160">Все компоненты архитектуры для обработки больших данных поддерживают горизонтальное масштабирование, чтобы вы могли адаптировать решение для малых и больших рабочих нагрузок и платить только за те ресурсы, которые используете.</span><span class="sxs-lookup"><span data-stu-id="30c61-160">All of the components in the big data architecture support scale-out provisioning, so that you can adjust your solution to small or large workloads, and pay only for the resources that you use.</span></span>
- <span data-ttu-id="30c61-161">**Взаимодействие с существующими решениями.**</span><span class="sxs-lookup"><span data-stu-id="30c61-161">**Interoperability with existing solutions**.</span></span> <span data-ttu-id="30c61-162">Компоненты архитектуры для обработки больших данных также используются в соответствующих решениях Интернета вещей и корпоративных решениях бизнес-аналитики, что позволяет создавать интегрированные средства для рабочих нагрузок обработки данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-162">The components of the big data architecture are also used for IoT processing and enterprise BI solutions, enabling you to create an integrated solution across data workloads.</span></span>

## <a name="challenges"></a><span data-ttu-id="30c61-163">Недостатки</span><span class="sxs-lookup"><span data-stu-id="30c61-163">Challenges</span></span>

- <span data-ttu-id="30c61-164">**Сложность.**</span><span class="sxs-lookup"><span data-stu-id="30c61-164">**Complexity**.</span></span> <span data-ttu-id="30c61-165">Решения для обработки больших данных могут быть очень сложными и содержать множество компонентов для приема данных из нескольких источников.</span><span class="sxs-lookup"><span data-stu-id="30c61-165">Big data solutions can be extremely complex, with numerous components to handle data ingestion from multiple data sources.</span></span> <span data-ttu-id="30c61-166">Создание, тестирование и устранение неполадок процессов обработки больших данных может стать непростой задачей.</span><span class="sxs-lookup"><span data-stu-id="30c61-166">It can be challenging to build, test, and troubleshoot big data processes.</span></span> <span data-ttu-id="30c61-167">Более того, в нескольких системах может существовать большое количество параметров конфигурации для оптимизации производительности.</span><span class="sxs-lookup"><span data-stu-id="30c61-167">Moreover, there may be a large number of configuration settings across multiple systems that must be used in order to optimize performance.</span></span>
- <span data-ttu-id="30c61-168">**Набор навыков.**</span><span class="sxs-lookup"><span data-stu-id="30c61-168">**Skillset**.</span></span> <span data-ttu-id="30c61-169">Многие технологии для обработки больших данных являются узкоспециализированными. В них используются платформы и языки, которые не являются стандартными для более общих архитектур приложений.</span><span class="sxs-lookup"><span data-stu-id="30c61-169">Many big data technologies are highly specialized, and use frameworks and languages that are not typical of more general application architectures.</span></span> <span data-ttu-id="30c61-170">С другой стороны, технологии для обработки больших данных способствуют развитию новых интерфейсов API на основе более традиционных языков.</span><span class="sxs-lookup"><span data-stu-id="30c61-170">On the other hand, big data technologies are evolving new APIs that build on more established languages.</span></span> <span data-ttu-id="30c61-171">Например, язык U-SQL в Azure Data Lake Analytics построен на комбинации Transact-SQL и C#.</span><span class="sxs-lookup"><span data-stu-id="30c61-171">For example, the U-SQL language in Azure Data Lake Analytics is based on a combination of Transact-SQL and C#.</span></span> <span data-ttu-id="30c61-172">Аналогичным образом, API на основе SQL доступны для Hive, HBase и Spark.</span><span class="sxs-lookup"><span data-stu-id="30c61-172">Similarly, SQL-based APIs are available for Hive, HBase, and Spark.</span></span>
- <span data-ttu-id="30c61-173">**Зрелость технологий.**</span><span class="sxs-lookup"><span data-stu-id="30c61-173">**Technology maturity**.</span></span> <span data-ttu-id="30c61-174">Многие из технологий, используемых для обработки больших данных, находятся в развитии.</span><span class="sxs-lookup"><span data-stu-id="30c61-174">Many of the technologies used in big data are evolving.</span></span> <span data-ttu-id="30c61-175">Основные технологии Hadoop, например Hive и Pig, уже сформированы. Но в новые технологии, такие как Spark, с каждым выпуском вносятся значительные изменения и усовершенствования.</span><span class="sxs-lookup"><span data-stu-id="30c61-175">While core Hadoop technologies such as Hive and Pig have stabilized, emerging technologies such as Spark introduce extensive changes and enhancements with each new release.</span></span> <span data-ttu-id="30c61-176">Управляемые службы, такие как Azure Data Lake Analytics и фабрика данных Azure, являются относительно молодыми по сравнению с другими службами Azure и, скорее всего, с течением времени будут изменяться.</span><span class="sxs-lookup"><span data-stu-id="30c61-176">Managed services such as Azure Data Lake Analytics and Azure Data Factory are relatively young, compared with other Azure services, and will likely evolve over time.</span></span>
- <span data-ttu-id="30c61-177">**Безопасность**.</span><span class="sxs-lookup"><span data-stu-id="30c61-177">**Security**.</span></span> <span data-ttu-id="30c61-178">В решениях для обработки больших данных все статические данные обычно хранятся в централизованном озере данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-178">Big data solutions usually rely on storing all static data in a centralized data lake.</span></span> <span data-ttu-id="30c61-179">Защита доступа к этим данным —непростая задача, особенно если данные должны приниматься и использоваться несколькими приложениями и платформами.</span><span class="sxs-lookup"><span data-stu-id="30c61-179">Securing access to this data can be challenging, especially when the data must be ingested and consumed by multiple applications and platforms.</span></span>

## <a name="best-practices"></a><span data-ttu-id="30c61-180">Рекомендации</span><span class="sxs-lookup"><span data-stu-id="30c61-180">Best practices</span></span>

- <span data-ttu-id="30c61-181">**Использование параллелизма.**</span><span class="sxs-lookup"><span data-stu-id="30c61-181">**Leverage parallelism**.</span></span> <span data-ttu-id="30c61-182">В большинстве технологий для обработки больших данных рабочая нагрузка распределяется между несколькими единицами обработки.</span><span class="sxs-lookup"><span data-stu-id="30c61-182">Most big data processing technologies distribute the workload across multiple processing units.</span></span> <span data-ttu-id="30c61-183">Поэтому статические файлы данных создаются и хранятся в формате, доступном для разбивки.</span><span class="sxs-lookup"><span data-stu-id="30c61-183">This requires that static data files are created and stored in a splittable format.</span></span> <span data-ttu-id="30c61-184">Распределенные файловые системы, такие как HDFS, могут обеспечить оптимизацию производительности чтения и записи. При этом фактическая обработка параллельно выполняется на нескольких узлах кластера. Это сокращает общее время выполнения заданий.</span><span class="sxs-lookup"><span data-stu-id="30c61-184">Distributed file systems such as HDFS can optimize read and write performance, and the actual processing is performed by multiple cluster nodes in parallel, which reduces overall job times.</span></span>

- <span data-ttu-id="30c61-185">**Секционирование данных.**</span><span class="sxs-lookup"><span data-stu-id="30c61-185">**Partition data**.</span></span> <span data-ttu-id="30c61-186">Пакетная обработка обычно выполняется регулярно &mdash; например, еженедельно или ежемесячно.</span><span class="sxs-lookup"><span data-stu-id="30c61-186">Batch processing usually happens on a recurring schedule &mdash; for example, weekly or monthly.</span></span> <span data-ttu-id="30c61-187">Секционированные файлы и структуры данных, такие как таблицы, основаны на темпоральных периодах, которые соответствуют расписанию обработки.</span><span class="sxs-lookup"><span data-stu-id="30c61-187">Partition data files, and data structures such as tables, based on temporal periods that match the processing schedule.</span></span> <span data-ttu-id="30c61-188">Это упрощает прием данных, планирование заданий и устранение ошибок.</span><span class="sxs-lookup"><span data-stu-id="30c61-188">That simplifies data ingestion and job scheduling, and makes it easier to troubleshoot failures.</span></span> <span data-ttu-id="30c61-189">Кроме того, таблицы разделов, которые используются в запросах Hive, U-SQL или SQL, могут значительно повысить их производительность.</span><span class="sxs-lookup"><span data-stu-id="30c61-189">Also, partitioning tables that are used in Hive, U-SQL, or SQL queries can significantly improve query performance.</span></span>

- <span data-ttu-id="30c61-190">**Применение семантики схемы при считывании.**</span><span class="sxs-lookup"><span data-stu-id="30c61-190">**Apply schema-on-read semantics**.</span></span> <span data-ttu-id="30c61-191">Озеро данных позволяет объединять в хранилище файлы в разных форматах — структурированные, частично структурированные и неструктурированные.</span><span class="sxs-lookup"><span data-stu-id="30c61-191">Using a data lake lets you to combine storage for files in multiple formats, whether structured, semi-structured, or unstructured.</span></span> <span data-ttu-id="30c61-192">Используйте семантику *схемы при считывании*, которая проецирует схему на данные при обработке, а не при хранении.</span><span class="sxs-lookup"><span data-stu-id="30c61-192">Use *schema-on-read* semantics, which project a schema onto the data when the data is processing, not when the data is stored.</span></span> <span data-ttu-id="30c61-193">Это повышает гибкость решения и предотвращает образование узких мест во время приема данных в результате проверки данных и типов.</span><span class="sxs-lookup"><span data-stu-id="30c61-193">This builds flexibility into the solution, and prevents bottlenecks during data ingestion caused by data validation and type checking.</span></span>

- <span data-ttu-id="30c61-194">**Обработка данных на месте.**</span><span class="sxs-lookup"><span data-stu-id="30c61-194">**Process data in-place**.</span></span> <span data-ttu-id="30c61-195">В традиционных решениях бизнес-аналитики для перемещения данных в хранилище часто используется процесс извлечения, преобразования и загрузки (ETL).</span><span class="sxs-lookup"><span data-stu-id="30c61-195">Traditional BI solutions often use an extract, transform, and load (ETL) process to move data into a data warehouse.</span></span> <span data-ttu-id="30c61-196">Для больших объемов данных и разнообразных форматов в решениях для обработки больших данных обычно используются различные вариации ETL, например преобразование, извлечение и загрузка (TEL).</span><span class="sxs-lookup"><span data-stu-id="30c61-196">With larger volumes data, and a greater variety of formats, big data solutions generally use variations of ETL, such as transform, extract, and load (TEL).</span></span> <span data-ttu-id="30c61-197">При таком подходе данные обрабатываются в распределенном хранилище. Они преобразуются в требуемую структуру перед перемещением в хранилище аналитических данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-197">With this approach, the data is processed within the distributed data store, transforming it to the required structure, before moving the transformed data into an analytical data store.</span></span>

- <span data-ttu-id="30c61-198">**Регулирование затрат при тарификации на основе объема и времени использования.**</span><span class="sxs-lookup"><span data-stu-id="30c61-198">**Balance utilization and time costs**.</span></span> <span data-ttu-id="30c61-199">Для заданий пакетной обработки очень важно учитывать два фактора: расходы на единицу вычислительных узлов и поминутная стоимость использования этих узлов для выполнения задания.</span><span class="sxs-lookup"><span data-stu-id="30c61-199">For batch processing jobs, it's important to consider two factors: The per-unit cost of the compute nodes, and the per-minute cost of using those nodes to complete the job.</span></span> <span data-ttu-id="30c61-200">Например, выполнение пакетного задания может занять восемь часов при использовании четырех узлов кластера.</span><span class="sxs-lookup"><span data-stu-id="30c61-200">For example, a batch job may take eight hours with four cluster nodes.</span></span> <span data-ttu-id="30c61-201">Но может оказаться, что все четыре узла используются для задания только в течение первых двух часов, а после этого достаточно двух узлов.</span><span class="sxs-lookup"><span data-stu-id="30c61-201">However, it might turn out that the job uses all four nodes only during the first two hours, and after that, only two nodes are required.</span></span> <span data-ttu-id="30c61-202">В таком случае выполнение всего задания на двух узлах увеличит общее время, но не удвоит его. Поэтому совокупная стоимость будет меньше.</span><span class="sxs-lookup"><span data-stu-id="30c61-202">In that case, running the entire job on two nodes would increase the total job time, but would not double it, so the total cost would be less.</span></span> <span data-ttu-id="30c61-203">В некоторых бизнес-сценариях длительное время обработки предпочтительнее, чем более высокая цена на применение ресурсов кластера с низкими показателями использования.</span><span class="sxs-lookup"><span data-stu-id="30c61-203">In some business scenarios, a longer processing time may be preferable to the higher cost of using under-utilized cluster resources.</span></span>

- <span data-ttu-id="30c61-204">**Разделение кластерных ресурсов.**</span><span class="sxs-lookup"><span data-stu-id="30c61-204">**Separate cluster resources**.</span></span> <span data-ttu-id="30c61-205">При развертывании кластеров HDInsight обычно можно повысить производительность, подготовив отдельные кластерные ресурсы для каждого типа рабочей нагрузки.</span><span class="sxs-lookup"><span data-stu-id="30c61-205">When deploying HDInsight clusters, you will normally achieve better performance by provisioning separate cluster resources for each type of workload.</span></span> <span data-ttu-id="30c61-206">Например, кластеры Spark включают Hive, но при масштабной обработке с использованием Hive и Spark рекомендуем развернуть отдельные выделенные кластеры Spark и Hadoop.</span><span class="sxs-lookup"><span data-stu-id="30c61-206">For example, although Spark clusters include Hive, if you need to perform extensive processing with both Hive and Spark, you should consider deploying separate dedicated Spark and Hadoop clusters.</span></span> <span data-ttu-id="30c61-207">Аналогичным образом, при использовании HBase и Storm для потоковой обработки с низкой задержкой и Hive для пакетной обработки рекомендуем развернуть отдельные кластеры для Storm, HBase и Hadoop.</span><span class="sxs-lookup"><span data-stu-id="30c61-207">Similarly, if you are using HBase and Storm for low latency stream processing and Hive for batch processing, consider separate clusters for Storm, HBase, and Hadoop.</span></span>

- <span data-ttu-id="30c61-208">**Оркестрация приема данных.**</span><span class="sxs-lookup"><span data-stu-id="30c61-208">**Orchestrate data ingestion**.</span></span> <span data-ttu-id="30c61-209">Иногда существующие бизнес-приложения могут записывать файлы данных для пакетной обработки непосредственно в контейнеры больших двоичных объектов в хранилище Azure, где они могут использоваться службами HDInsight или Azure Data Lake Analytics.</span><span class="sxs-lookup"><span data-stu-id="30c61-209">In some cases, existing business applications may write data files for batch processing directly into Azure storage blob containers, where they can be consumed by HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="30c61-210">Тем не менее часто требуется выполнять оркестрацию приема данных из локального или внешнего источника в озере данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-210">However, you will often need to orchestrate the ingestion of data from on-premises or external data sources into the data lake.</span></span> <span data-ttu-id="30c61-211">Наиболее прогнозируемый и централизованно управляемый подход для этого — рабочий процесс или конвейер оркестрации, например поддерживаемый фабрикой данных Azure или Oozie.</span><span class="sxs-lookup"><span data-stu-id="30c61-211">Use an orchestration workflow or pipeline, such as those supported by Azure Data Factory or Oozie, to achieve this in a predictable and centrally manageable fashion.</span></span>

- <span data-ttu-id="30c61-212">**Очистка конфиденциальных данных на ранней стадии.**</span><span class="sxs-lookup"><span data-stu-id="30c61-212">**Scrub sensitive data early**.</span></span> <span data-ttu-id="30c61-213">При приеме данных необходимо очищать конфиденциальные данные на ранней стадии, чтобы они не сохранялись в озере данных.</span><span class="sxs-lookup"><span data-stu-id="30c61-213">The data ingestion workflow should scrub sensitive data early in the process, to avoid storing it in the data lake.</span></span>
