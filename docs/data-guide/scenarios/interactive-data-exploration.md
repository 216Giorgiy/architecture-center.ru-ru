---
title: "Интерактивное исследование данных"
description: 
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: a9e72f4cf88c9082fe79f854dd79e98bfaa918f5
ms.sourcegitcommit: 90cf2de795e50571d597cfcb9b302e48933e7f18
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 02/14/2018
---
# <a name="interactive-data-exploration"></a>Интерактивное исследование данных

Во многих корпоративных решениях бизнес-аналитики (BI) специалисты по бизнес-аналитике централизованно создают отчеты и управляют ими. Но организации все чаще хотят предоставить пользователям возможность принимать решения на основе данных. Кроме того, все большее число организаций привлекают *специалистов по анализу данных* или *аналитиков*, в задачи которых входит интерактивный просмотр данных с применением статистических моделей и аналитических методов для поиска тенденций и закономерностей. Для интерактивного просмотра данных нужны инструменты и платформы, которые обеспечивают обработку специализированных запросов и визуализаций данных с низкой задержкой.

![](./images/data-exploration.png)

## <a name="self-service-bi"></a>Бизнес-аналитика с поддержкой самообслуживания

Бизнес-аналитика с поддержкой самообслуживания обозначает современный подход к принятию бизнес-решений, при котором пользователи получают возможность в масштабах всего предприятия находить, изучать и совместно использовать результаты анализа данных. Для поддержки этого подхода решение должно соответствовать нескольким требованиям:

* обнаружение источников бизнес-данных через каталог данных;
* управление основными данными для обеспечения согласованности определений и значений для сущностей данных;
* применение инструментов для интерактивного моделирования и визуализации данных для бизнес-пользователей.

В типичном решении бизнес-аналитики с поддержкой самообслуживания бизнес-пользователи могут находить и использовать источники данных, имеющие отношение к конкретной предметной области, а также получают интуитивно удобные средства и повышающие эффективность приложения, позволяющие определять модели данных и отчеты, а также совместно использовать их с коллегами.

Соответствующие службы Azure:

- [Каталог данных Azure](/azure/data-catalog/data-catalog-what-is-data-catalog)
- [Microsoft Power BI](https://powerbi.microsoft.com/)

## <a name="data-science-experimentation"></a>Экспериментирование для обработки и анализа данных
Если организации требуется расширенная аналитика и прогнозное моделирование, задачи предварительной подготовки обычно выполняют специалисты по обработке и анализу данных. Специалист по обработке и анализу данных изучает данные и применяет методы статистического анализа для поиска связей между *признаками* данных и требуемыми *метками* прогнозирования. Просмотр данных обычно выполняется с помощью языков программирования, например Python или R, которые имеют встроенную поддержку статистического моделирования и визуализации. Используемые для просмотра данных скрипты обычно размещаются в специализированных средах, например Jupyter Notebook. Эти средства позволяют специалистам по обработке и анализу данных с помощью программных средств просматривать данные, а также документировать и совместно использовать обнаруженные закономерности.

Соответствующие службы Azure:

- [Azure Notebooks](https://notebooks.azure.com/);
- [Студия машинного обучения Azure](/azure/machine-learning/studio/what-is-ml-studio)
- [службы типа "Экспериментирование в Машинном обучении Azure"](/azure/machine-learning/preview/experimentation-service-configuration);
- [виртуальная машина для обработки и анализа данных](/azure/machine-learning/data-science-virtual-machine/overview).

## <a name="challenges"></a>Сложности

- **Соответствие требованиям к конфиденциальности данных.** Необходимо соблюдать осторожность при передаче пользователям персональных данных для самостоятельного анализа и составления отчетов. Почти наверняка придется принять дополнительные меры для соответствия политикам организации и нормативным требованиям. 

- **Объем данных.** Предоставления пользователям полного доступа к источнику данных может принести некоторую пользу, но одновременно приведет к увеличению длительности операций в Excel или Power BI или объема ресурсов кластера для обработки запросов Spark SQL.

- **Опыт и знания пользователей**. Пользователи создают собственные запросы и статистические функции для принятия бизнес-решений. Есть ли у вас гарантии того, что их навыков по аналитической обработке и составлению запросов достаточно для получения точных результатов?

- **Совместное использование результатов**. Если пользователи могут создавать и совместно использовать отчеты и визуализации данных, возникают дополнительные требования к обеспечению безопасности.

## <a name="architecture"></a>Архитектура

Несмотря на то, что основной задачей в этом сценарии является поддержка интерактивного анализа данных, обработка и анализ данных неизбежно сопряжены с процессами очистки, выборки и структурирования данных, которые часто требуют много времени. Это означает, что разумно применить архитектуру [пакетной обработки](./batch-processing.md).

## <a name="technology-choices"></a>Выбор технологий

Мы рекомендуем применять следующие технологии для интерактивного просмотра данных в Azure.

### <a name="data-storage"></a>Хранилище данных

- **Контейнеры хранилища BLOB-объектов Azure** или **Azure Data Lake Store**. Специалисты по обработке и анализу данных обычно начинают работу с необработанных исходных данных, чтобы получить доступ ко всем возможным признакам, выбросам и ошибкам в этих данных. При работе с большими данными это чаще всего файлы в хранилище данных.

Дополнительные сведения см. в статье о [хранилище данных](../technology-choices/data-storage.md).

### <a name="batch-processing"></a>Пакетная обработка

- **R Server** или **Spark**. Большинство специалистов по обработке и анализу данных используют языки программирования с эффективной поддержкой математических и статистических пакетов, например R или Python. При работе с большими объемами данных задержку можно снизить путем использования платформ, позволяющих применять в этих языках распределенную обработку. R Server (отдельно или в сочетании со Spark) позволяет масштабировать функции обработки R, а Spark предоставляет встроенную поддержку для аналогичных возможностей масштабирования на языке Python.
- **Hive**. Hive лучше всего подходит для преобразования данных с помощью языка запросов с семантикой SQL. Пользователи могут создавать и загружать таблицы с помощью инструкций HiveQL, семантически близких к SQL.

Дополнительные сведения см. в статье о [пакетной обработке](../technology-choices/batch-processing.md).

### <a name="analytical-data-store"></a>Хранилище аналитических данных

- **Spark SQL**. Spark SQL представляет собой API на базе Spark, позволяющий создавать блоки данных и таблицы, к которым можно обращаться через запросы с синтаксисом SQL. Независимо от того, какие файлы данных предоставлены для анализа — необработанные исходные файлы или новые файлы, очищенные и подготовленные в процессе пакетной обработки — пользователи могут определить на их основе таблицы Spark SQL и применять для них запросы и аналитические операции. 
- **Hive**. Помимо пакетной обработки необработанных данных Hive позволяет создавать базу данных Hive с таблицами и представлениями Hive, основанными на папках с данными, а также поддерживает интерактивные запросы для аналитики и отчетности. HDInsight включает тип кластера Interactive Hive, который использует кэширование в памяти, чтобы уменьшить время отклика на запросы Hive. Пользователи, хорошо знакомые с синтаксисом SQL, смогут применить Interactive Hive для изучения данных.

Дополнительные сведения см. в статье о [хранилищах аналитических данных](../technology-choices/analytical-data-stores.md).

### <a name="analytics-and-reporting"></a>Аналитика и отчетность

- **Jupyter**. Служба Jupyter Notebooks предоставляет браузерный интерфейс для выполнения кода на разных языках, например R, Python или Scala. Если вы используете R Server или Spark для пакетной обработки данных или Spark SQL для определения схемы таблиц для запросов, Jupyter станет хорошим инструментом для запроса этих данных. В Spark вы сможете применить стандартный API Spark для кадров данных или API Spark SQL, а также внедренные инструкции SQL для запроса данных и создания визуализаций.
- **Клиенты Interactive Hive**. Если вы используете кластер Interactive Hive для запроса данных, вам доступны представления Hive на панели мониторинга для кластера Ambari, средство командной строки Beeline и любые средства на основе ODBC (с применением драйвера Hive ODBC), такие как Microsoft Excel и Power BI.

Дополнительные сведения см. в статье [о технологиях аналитики данных и отчетности](../technology-choices/analysis-visualizations-reporting.md).