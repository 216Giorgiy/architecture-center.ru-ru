---
title: Производительность, устранение неполадок для Azure Databricks с помощью Azure Monitor
titleSuffix: ''
description: Использование панелей мониторинга Grafana для диагностики проблем с производительностью в Azure Databricks.
author: petertaylor9999
ms.date: 04/02/2019
ms.topic: ''
ms.service: ''
ms.subservice: ''
ms.openlocfilehash: 49ec63d0c45ab388ca83b3ab0562428327539619
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/03/2019
ms.locfileid: "58888110"
---
# <a name="troubleshoot-performance-bottlenecks-in-azure-databricks"></a>Устранение узких мест производительности в Azure Databricks.

В этой статье описывается использование панелей мониторинга, чтобы найти узкие места производительности в заданий Spark в Azure Databricks.

[Azure Databricks](/azure/azure-databricks/) — [Apache Spark](https://spark.apache.org/)— на основе Служба аналитики, которая позволяет легко разрабатывать и развертывать аналитику больших данных. Мониторинг и устранение проблем с производительностью важно при работе в производственных рабочих нагрузок Azure Databricks. Для выявления общих проблем с производительностью, желательно использовать мониторинга визуализации на основе данных телеметрии.

## <a name="prerequisites"></a>Технические условия

Настройка панели мониторинга Grafana, показанные в этой статье:

- Настройте свой кластер Databricks для отправки данных телеметрии в рабочую область Log Analytics, с помощью библиотеки мониторинга Azure Databricks. Дополнительные сведения см. в разделе [настроить Azure Databricks для отправки метрик в Azure Monitor](./configure-cluster.md).

- Развертывание Grafana на виртуальной машине. См. в разделе [Использование панелей мониторинга для визуализации метрик Azure Databricks](./dashboards.md).

Панели мониторинга Grafana, которое развертывается с набором визуализации временных рядов. Каждый граф — метрики, связанные с задания Apache Spark, этапы задания и задачи, составляющие каждый этап блочная диаграмма временных рядов.

## <a name="azure-databricks-performance-overview"></a>Общие сведения о производительности Azure Databricks

Azure Databricks основан на Apache Spark, общего назначения распределенная вычислительная система. Код приложения, известный как **задания**, выполняется в кластере Apache Spark, координируемых с помощью диспетчера кластеров. Как правило задание — наивысшего уровня единицы вычисления. Задание представляет собой завершения операции, выполняемой приложением Spark. Типичные операции включает в себя чтение данных из источника, применения преобразований данных и запись результатов в хранилище или другое место назначения.

Задания разбиваются на **этапы**. Задание перемещает через этапы последовательно, что означает, что более поздних стадиях необходимо дождаться более ранних этапах для выполнения. Этапы содержат группы идентичных **задачи** , могут выполняться параллельно на нескольких узлах кластера Spark. Задачи являются наиболее детальную единицы выполнения происходящих на подмножестве данных.

В следующих разделах описываются некоторые визуализации панели мониторинга, которые полезны для устранения неполадок производительности.

## <a name="job-and-stage-latency"></a>Задержка задания и рабочей области

Задержку задания — это продолжительность выполнения задания из при запуске до завершения этой операции. Отображается как процент выполнения задания в кластер и идентификатор приложения, чтобы разрешить визуализацию выбросы. На следующей диаграмме показано журнал заданий где 90-й процентиль достигнут 50 секунд, несмотря на то, что 50-й процентиль согласованно было около 10 секунд.

![Диаграмма, показывающая задержку задания](./_images/grafana-job-latency.png)

Проверьте выполнение задания, кластера и приложения поиска пиками задержки. После определения кластеров и приложений с высокой задержкой перейти к исследовать задержки рабочей области.

Задержка рабочей области также отображается как процентили разрешить визуализацию выбросы. Этап задержки, разбитое по кластера, приложения и имя рабочей области. Определите пики задержка задачи в графе, чтобы определить, какие задачи препятствующие завершения этапа.

![Диаграмма, показывающая задержки рабочей области](./_images/grafana-stage-latency.png)

Диаграмма пропускной способности кластер показывает количество заданий, этапы и задачи выполнены в минуту. Это поможет вам понять рабочей нагрузки с точки зрения относительное количество этапов и задач на задание. Здесь вы увидите, что количество заданий в минуту варьируется в диапазоне от 2 и 6, а число уровней — около 12 &ndash; 24 в минуту.

![Пропускная способность кластера отображение Graph](./_images/grafana-cluster-throughput.png)

## <a name="sum-of-task-execution-latency"></a>Сумма задержек выполнения задачи

Эта визуализация показывает сумму задержка выполнения задачи для каждого узла в кластере. Используя эту диаграмму, чтобы определить задачи, которые выполняются медленно из-за замедляет узла в кластере или misallocation задач на каждый исполнитель. На следующей диаграмме большинство узлов имеют сумму около 30 секунд. Тем не менее двух узлов имеют сумм, наведите указатель мыши около 10 минут. На узлах выполняется медленно, либо misallocated число задач на каждый исполнитель.

![Sum отображение диаграммы выполнения задачи каждого узла](./_images/grafana-sum-task-exec.png)

Число задач на каждый исполнитель показывает, что два исполнителей присвоен непропорционально большое количество задач, причиной возникновения узкого места.

![Диаграмма, показывающая задач на каждый исполнитель](./_images/grafana-tasks-per-exec.png)

## <a name="task-metrics-per-stage"></a>Метрики задач каждого этапа

Визуализация метрик задач дает детализация затрат для выполнения задачи. Используется см. в разделе относительное время, затраченное на задачи, например сериализации и десериализации. Эти данные могут показать возможности для оптимизации &mdash; к примеру, с помощью [передайте переменные](https://spark.apache.org/docs/2.2.0/rdd-programming-guide.html#broadcast-variables) во избежание доставки данных. Метрики задач также показывают размер данных смешения для задачи и случайном порядке чтения и записи времени. Если высоки эти значения, это означает, что большие объемы данных передаются по сети.

Другой задачи метрика задержки планировщика, который измеряет время, необходимое для планирования задач. В идеальном случае это значение должно быть низкой по сравнению с исполнителя вычислительное время, то есть время, затраченное на фактического выполнения задачи.

Ниже graph планировщика время задержки (3.7 s), превышает время вычислений исполнителя (1.1 s). Это означает, что больше времени тратится на ожидание задачи планироваться, чем на выполнение реальной работы.

![Диаграмма, показывающая метрик задач каждого этапа](./_images/grafana-metrics-per-stage.png)

В этом случае причина слишком большое число секций, которые вызывали массу системных издержек. Уменьшение числа секций уменьшается время задержки планировщика. Далее показывает график, в большинстве случаев затраченное на выполнение задачи.

![Диаграмма, показывающая метрик задач каждого этапа](./_images/grafana-metrics-per-stage2.png)

## <a name="streaming-throughput-and-latency"></a>Потоковая передача пропускной способности и задержки

Потоковая передача пропускной способности непосредственно связано с структурированной потоковой передачи. Существует две важные метрики, связанные с пропускную способность потоковой передачи: Входные строки на второй и обработанных строк в секунду. Если входных строк в секунду outpaces строк, обработанных в секунду, значит, успевают системы обработки потоковых данных. Кроме того Если входные данные поступают из концентраторов событий или Kafka, затем входных строк в секунду должен соответствовать скорость приема данных во внешнем интерфейсе.

Два задания может иметь аналогичные пропускной способности кластер, но очень разные метрики потоковой передачи. На следующем рисунке показаны два разных рабочих нагрузок. Они аналогичны с точки зрения пропускной способности кластер (задания, этапы и задачи в минуту). Но второго запуска обрабатывает 12 000 строк/сек против 4 000 строк в секунду.

![Пропускную способность потоковой передачи отображение Graph](./_images/grafana-streaming-throughput.png)

Пропускную способность потоковой передачи часто является лучшим бизнес-метрики, чем пропускная способность кластера, так как он измеряет количество записей данных, которые обрабатываются.

## <a name="resource-consumption-per-executor"></a>Потребление ресурсов на каждый исполнитель

Эти метрики помогают понять работу, которая выполняет каждого исполнителя.

**Процентных показателей** измерения, сколько раз, когда исполнитель тратит на различные вещи, выраженное как доля времени, и общую исполнителя вычислительное время, затраченное на. Ниже приведены метрики.

- % Времени сериализации
- % Время десериализации
- % Исполнителя времени ЦП
- % Времени виртуальной машины Java

Эти представления показывают, какой объем каждой метрики позволяет общую выполнения обработки.

![Диаграмма, показывающая процентных показателей](./_images/grafana-percentage.png)

**Метрики в случайном порядке** , метрик, связанных с данными, перетасовывания между исполнителями.

- Ввод-вывод в случайном порядке
- Память в случайном порядке
- Использование файловой системы
- Использование диска

## <a name="common-performance-bottlenecks"></a>Общие узкие места производительности

Два распространенных узких мест производительности в Spark, *задач других ошибок* и *количество разделов не является оптимальным shuffle*.

### <a name="task-stragglers"></a>Задача других ошибок

Этапы задания выполняются последовательно, с помощью более ранних этапах, блокировки более поздних стадиях. Если одна задача выполняет секции shuffle медленнее, чем другие задачи, все задачи в кластере необходимо дождаться медленных задачах отследить, прежде чем могут быть сохранены в рабочей области. Это может произойти по следующим причинам:

1. Для узла или группы узлов выполняется медленно. Симптомы: Высокий уровень задач, рабочей области, или задержку задания и кластера с низкой пропускной способности. Суммирование задержки задачи каждого узла не распределены неравномерно. Тем не менее потребление ресурсов будут равномерно распределены между исполнителями.

1. Задачи иметь дорогостоящие агрегат для выполнения (искажения данных). Симптомы: Распределяется равномерно высокого уровня задачи, рабочей области, или задания и кластера с низкой пропускной способности, но также суммирование задержки для каждого узла. Потребление ресурсов будут равномерно распределены между исполнителями.

1. Если разделы размера не равны, увеличенный раздел может привести к несбалансированное задачи выполнения (наклон секции). Симптомы: Потребление ресурсов исполнителя велико по сравнению с другими исполнителей, запущенных в кластере. Все задачи, выполняемые на этого исполнителя запускается медленно и хранения выполнения этапа в конвейере. Эти этапы, называются *этап барьеры*.

### <a name="non-optimal-shuffle-partition-count"></a>Число секций неоптимальная смешения

Во время запросов структурированной потоковой передачи присваивания задачи исполнитель — ресурсоемкая операция, для кластера. Если данные shuffle не самым оптимальным, продолжительность задержки для задачи может негативно отразиться на пропускной способности и задержки. При наличии слишком мало секций, ядер в кластере будет недостаточно загружены приемом которых может привести к обработке эффективности. И наоборот Если существует слишком много секций, есть немало накладных расходов на небольшое количество задач.

Использование показателей потребления ресурсов для устранения неполадок наклон секции и misallocation из исполнителей в кластере. Если раздел синхронизована, будут повышены ресурсы исполнителя по сравнению с другими исполнителей, запущенных в кластере.

Например приведенный ниже график показывает, что объем памяти, используемой перетасовывания на первых двух исполнители — 90 X больше, чем другие исполнители:

![Диаграмма, показывающая процентных показателей](./_images/grafana-shuffle-memory.png)