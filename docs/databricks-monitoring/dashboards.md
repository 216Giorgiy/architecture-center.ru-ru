---
title: Использование панелей мониторинга для визуализации метрик Azure Databricks
description: Развертывание панели мониторинга Grafana для наблюдения за производительностью в Azure Databricks.
author: petertaylor9999
ms.date: 03/26/2019
ms.openlocfilehash: 36fcd93f6ca757e8e750d0fcbbdf0311c08560b0
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887834"
---
# <a name="use-dashboards-to-visualize-azure-databricks-metrics"></a>Использование панелей мониторинга для визуализации метрик Azure Databricks

В этой статье показано, как настроить панели мониторинга Grafana для мониторинга задания Azure Databricks для проблем с производительностью.

[Azure Databricks](/azure/azure-databricks/) — это Быстрая, эффективные и совместной работы [Apache Spark](https://spark.apache.org/)— на основе Служба аналитики, которая позволяет легко разрабатывать и развертывать аналитику больших данных и решений искусственного интеллекта (ИИ). Мониторинг — это важная составляющая операционных рабочих нагрузок Azure Databricks в рабочей среде. Первым делом для сбора метрик в рабочую область для анализа. В Azure является лучшим решением для управления данными журнала [Azure Monitor](/azure/azure-monitor/). Azure Databricks не встроена поддержка отправке данных журнала в Azure monitor, но [библиотеки для использования этой функции](https://github.com/mspnp/spark-monitoring) доступен в [Github](https://github.com).

Эта библиотека позволяет ведение журнала метрик службы Azure Databricks, а также структуру Apache Spark, потоковая передача событий метрики запросов. После успешного развертывания этой библиотеки в кластер Azure Databricks, Дополнительно можно развернуть набор [Grafana](https://granfana.com) панелей мониторинга, которые можно развернуть как часть рабочей среды.

![Снимок экрана панели мониторинга](./_images/dashboard-screenshot.png)

## <a name="prequisites"></a>Предварительные требования

Клон [репозиторий Github](https://github.com/mspnp/spark-monitoring) и [следовать инструкциям по развертыванию](./configure-cluster.md) для создания и настройки ведения журнала Azure Monitor для библиотеки Azure Databricks для отправки журналов в рабочей области Azure Log Analytics.

## <a name="deploy-the-azure-log-analytics-workspace"></a>Развертывание рабочей области Azure Log Analytics

Чтобы развернуть рабочую область Azure Log Analytics, выполните следующие действия.

1. Перейдите к `/perftools/deployment/loganalytics` каталога.
1. Развертывание **logAnalyticsDeploy.json** шаблона Azure Resource Manager. Дополнительные сведения о развертывании шаблонов Resource Manager, см. в разделе [развертывание ресурсов с использованием шаблонов Resource Manager и Azure CLI][rm-cli]. Шаблон имеет следующие параметры:

    * **location**: Регион, где развернуты рабочей области Log Analytics и панели мониторинга.
    * **serviceTier**: Заливки Ценовая категория рабочей области. См. в разделе [здесь] [ sku] список допустимых значений.
    * **dataRetention** (необязательно): Количество дней данные журнала сохраняются в рабочей области Log Analytics. Значение по умолчанию — 30 дней. Если ценовая `Free`, срок хранения данных должен быть 7 дней.
    * **WorkspaceName** (необязательно): Имя рабочей области. Если не указан, шаблон создает имя.

    ```bash
    az group deployment create --resource-group <resource-group-name> --template-file logAnalyticsDeploy.json --parameters location='East US' serviceTier='Standalone'
    ```

Этот шаблон создает рабочую область, а также создает набор предопределенных запросов, используемые панелью мониторинга.

## <a name="deploy-grafana-in-a-virtual-machine"></a>Развертывание на виртуальной машине Grafana

Grafana — это проект с открытым исходным кодом, которые можно развернуть для визуализации метрик ряда времени, хранящиеся в рабочей области Azure Log Analytics, с помощью Grafana подключаемый модуль для Azure Monitor. Grafana выполняется на виртуальной машине (VM) и требует учетной записи хранения, виртуальная сеть и другие ресурсы. Для развертывания виртуальной машины с помощью bitnami сертифицированных Grafana изображения и связанные с ней ресурсы, выполните следующие действия:

1. Используйте Azure CLI, чтобы принять условия образа Azure Marketplace для Grafana.

    ```bash
    az vm image accept-terms --publisher bitnami --offer grafana --plan default
    ```

1. Перейдите к `/spark-monitoring/perftools/deployment/grafana` каталог в локальной копии репозитория GitHub.
1. Развертывание **grafanaDeploy.json** шаблона Resource Manager следующим образом:

    ```bash
    export DATA_SOURCE="https://raw.githubusercontent.com/mspnp/spark-monitoring/master/perftools/deployment/grafana/AzureDataSource.sh"
    az group deployment create \
        --resource-group <resource-group-name> \
        --template-file grafanaDeploy.json \
        --parameters adminPass='<vm password>' dataSource=$DATA_SOURCE
    ```

После завершения развертывания образа bitnami Grafana устанавливается на виртуальной машине.

## <a name="update-the-grafana-password"></a>Обновить пароль Grafana

Как часть процесса установки, сценарий установки Grafana выводит временный пароль для **администратора** пользователя. Требуется этот временный пароль для входа. Чтобы получить временный пароль, выполните следующие действия.  

1. Войдите на портал Azure.  
1. Выберите группу ресурсов, где были развернуты ресурсы.
1. Выберите виртуальную Машину, в котором была установлена Grafana. Если вы использовали имя параметра по умолчанию в шаблоне развертывания, имя виртуальной Машины предшествовало **sparkmonitoring-vm-grafana**.
1. В **поддержка и устранение неполадок** щелкните **диагностику загрузки** чтобы открыть страницу диагностики загрузки.
1. Нажмите кнопку **журнал последовательного вывода** на странице диагностики загрузки.
1. Найдите следующую строку: «Задать пароль приложений Bitnami».
1. Скопируйте пароль в безопасном месте.

Затем измените пароль администратора Grafana, выполнив следующие действия:

1. На портале Azure выберите виртуальную Машину и нажмите кнопку **Обзор**.
1. Скопируйте общедоступный IP-адрес.
1. Откройте веб-браузер и перейдите к следующему URL-АДРЕСУ: `http://<IP addresss>:3000`.
1. На экране входа Grafana, введите **администратора** для имени пользователя и используйте пароль Grafana из предыдущих шагов.
1. После входа в систему, выберите **конфигурации** (значок шестеренки).
1. Выберите **администратора сервера**.
1. На **пользователей** выберите **администратора** имени входа.
1. Обновите пароль.

## <a name="create-an-azure-monitor-data-source"></a>Создание источника данных Azure Monitor

1. Создание службы субъекта, который позволяет Grafana для управления доступом к рабочей области Log Analytics. Дополнительные сведения см. в разделе [Создание субъекта-службы Azure с помощью Azure CLI](/cli/azure/create-an-azure-service-principal-azure-cli?view=azure-cli-latest)

    ```bash
    az ad sp create-for-rbac --name http://<service principal name> --role "Log Analytics Reader"
    ```

1. Обратите внимание на значения appId, password и tenant в выходных данных этой команды:

    ```json
    {
        "appId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
        "displayName": "azure-cli-2019-03-27-00-33-39",
        "name": "http://<service principal name>",
        "password": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
        "tenant": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
    }
    ```

1. Войдите на Grafana, описанных ранее. Выберите **конфигурации** (значок шестеренки) и затем **источников данных**.
1. В **источников данных** щелкните **добавить источник данных**.
1. Выберите **Azure Monitor** в качестве типа источника данных.
1. В **параметры** введите имя источника данных в **имя** текстового поля.
1. В **сведения об интерфейсе API Azure Monitor** введите следующие сведения:

    * Идентификатор подписки: идентификатор подписки Azure;
    * Идентификатор клиента: Идентификатор клиента из ранее.
    * Идентификатор клиента: Значение «appId» выше.
    * Секрет клиента: Значение «password» выше.

1. В **сведения об интерфейсе API Azure Log Analytics** установите флажок **и те же сведения, как Azure Monitor API** флажок.
1. Нажмите кнопку **сохранить и протестировать**. Если источник данных Log Analytics настроена правильно, отображается сообщение об успешном выполнении.

## <a name="create-the-dashboard"></a>Создание панели мониторинга

Создание панелей мониторинга в Grafana, выполнив следующие действия:

1. Перейдите к `/perftools/dashboards/grafana` каталог в локальной копии репозитория GitHub.
1. Выполните следующий скрипт:

    ```bash
    export WORKSPACE=<your Azure Log Analytics workspace ID>
    export LOGTYPE=SparkListenerEvent_CL

    sh DashGen.sh
    ```

    Выходные данные этого сценария — это файл с именем **SparkMonitoringDash.json**.

1. Вернитесь к панели мониторинга Grafana и выберите **создать** (значок плюса).
1. Выберите **Импортировать**.
1. Нажмите кнопку **отправить JSON-файл**.
1. Выберите **SparkMonitoringDash.json** файл, созданный на шаге 2.
1. В **параметры** раздела **АЛА**, выберите источник данных монитора Azure, созданной ранее.
1. Щелкните **Импорт**.

## <a name="visualizations-in-the-dashboards"></a>Визуализации на панелях мониторинга

Панели мониторинга Grafana и Azure Log Analytics содержат набор визуализации временных рядов. Каждый граф — график временных рядов данных метрики, связанные с Apache Spark [задания](https://spark.apache.org/docs/latest/job-scheduling.html), этапы задания и задачи, составляющие каждый этап.

Визуализация — следующим образом:

### <a name="job-latency"></a>Задание задержки

Эта визуализация показывает задержка выполнения для задания, которые грубое представление на общую производительность задания. Отображает время выполнения задания от начала до конца. Обратите внимание, что время запуска задания не является таким же, как время отправки задания. Задержка представляется в виде процентилей (10%, 30%, 50%, 90%) выполнения задания, индексированных по идентификатор кластера и идентификатор приложения.

### <a name="stage-latency"></a>Задержка рабочей области

Визуализация показывает задержку каждого этапа, на кластер, каждое приложение и каждого отдельного этапа. Эта визуализация используется для идентификации определенного этапа, на котором выполняется медленно.

### <a name="task-latency"></a>Задержка задачи

Эта визуализация показывает задержка выполнения задачи. Задержка представляется как процент выполнения задачи для каждого кластера, имя рабочей области и приложения.

### <a name="sum-task-execution-per-host"></a>Выполнение задач сумма для каждого узла

Эта визуализация показывает сумму задержка выполнения задачи для каждого узла в кластере. Просмотр задержка выполнения задачи каждого узла определяет узлы, которые имеют гораздо более длительных задержек задач общую, чем другие узлы. Это может означать, что задачи были неэффективно или неравномерно распространены на узлы.

### <a name="task-metrics"></a>Метрики задач

Эта визуализация отображается набор метрик выполнения для выполнения данной задачи. Это может быть размер и продолжительность смешения данных, продолжительность операций сериализации и десериализации и другие. Для полного набора метрик просмотрите запрос Log Analytics для панели. Эта визуализация полезно для понимания операции, которые составляют задачи и идентифицирующий потребление ресурсов каждой операции. Пики на графике представляют затратных операций, которые необходимо изучить.

### <a name="cluster-throughput"></a>Пропускная способность кластера

Эта визуализация — это общая схема рабочих элементов, индексированных по кластера и приложения для представления объем работы каждого кластера и приложения. Он показывает количество заданий, задач и этапов, выполнить для каждого кластера, приложения и рабочей области с шагом в одну минуту. 

### <a name="streaming-throughputlatency"></a>Потоковой передачи пропускной способности и задержки

Этот visualzation связана с метрики, связанные с запросом структурированный потоковой передачи. На графах представлены количество входных строк в секунду и количество строк, обрабатываемых за секунду. Метрики потоковой передачи также представлены каждого приложения. Эти метрики отправляются при возникновении события OnQueryProgress структурированной потоковой передачи запрос обрабатывается, и представляет визуализацию в миллисекундах, потоковая передача задержка, как время, затраченное на выполнение в пакетном запросе.

### <a name="resource-consumption-per-executor"></a>Потребление ресурсов на каждый исполнитель

Далее — это набор визуализации для отображения панели мониторинга определенного типа ресурса и его потребления на исполнителя для каждого кластера. Эти представления помогают идентифицировать выбросы потребления ресурсов на каждый исполнитель. Например если распределение работы для конкретного исполнителя неравномерно, потребление ресурсов будут повышены относительно других исполнителей, запущенных в кластере. Это можно определить, пики потребления ресурсов для исполнителя.

### <a name="executor-compute-time-metrics"></a>Метрики времени вычислений исполнителя

Далее — это набор визуализаций для панели мониторинга, Показать отношение исполнителя сериализации время десериализации время, время ЦП и общую исполнителя вычислительное время время виртуальной машины Java. Этот пример демонстрирует визуально каждого из этих четырех показателей вносят вклад в общую выполнения обработки.

### <a name="shuffle-metrics"></a>Метрики в случайном порядке

Окончательный набор данных метрик, связанных с помощью структурированной потоковой передачи запроса между всеми исполнителями в случайном порядке Показать визуализации. К ним относятся случайном порядке байтов, чтение, байтов, записанных в случайном порядке, в случайном порядке памяти и использования диска в запросах использования файловой системы.

## <a name="next-steps"></a>Дальнейшие действия

> [!div class="nextstepaction"]
> [Устранение узких мест производительности](./performance-troubleshooting.md)

<!-- links -->

[rm-cli]: /azure/azure-resource-manager/resource-group-template-deploy-cli
[sku]: /azure/templates/Microsoft.OperationalInsights/2015-11-01-preview/workspaces#sku-object